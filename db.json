{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/matery/source/yteng.jpg","path":"yteng.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my.css","path":"css/my.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/gitment.css","path":"css/gitment.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/matery.css","path":"css/matery.css","modified":1,"renderable":1},{"_id":"themes/matery/source/js/matery.js","path":"js/matery.js","modified":1,"renderable":1},{"_id":"themes/matery/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/yteng.jpg","path":"medias/yteng.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","path":"libs/codeBlock/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/explosion.min.js","path":"libs/others/explosion.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/text.js","path":"libs/others/text.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/snow.js","path":"libs/others/snow.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/fireworks.js","path":"libs/others/fireworks.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/golang.jpeg","path":"medias/files/golang.jpeg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/kafka-topic-partition.jpg","path":"medias/files/kafka-topic-partition.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/wsl.jpg","path":"medias/files/wsl.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","path":"libs/jquery/jquery-2.2.0.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","path":"medias/avatars/myzhihu.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/24.jpg","path":"medias/featureimages/24.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/28.jpg","path":"medias/featureimages/28.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/linked-list.png","path":"medias/files/linked-list.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/ovn.jpg","path":"medias/files/ovn.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/ovs_vlan.jpg","path":"medias/files/ovs_vlan.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/alipay.jpg","path":"medias/reward/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","path":"libs/awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/25.jpg","path":"medias/featureimages/25.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/27.jpg","path":"medias/featureimages/27.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","path":"medias/music/avatars/tiantangdemogui.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","path":"medias/music/avatars/yequ.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","path":"medias/music/avatars/yiluxiangbei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/kafka-producer-consumer.png","path":"medias/files/kafka-producer-consumer.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","path":"libs/awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","path":"libs/awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/algorithm-dp.jpg","path":"medias/files/algorithm-dp.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/files/hexo.png","path":"medias/files/hexo.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","path":"libs/awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","path":"libs/awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","path":"libs/awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/26.jpg","path":"medias/featureimages/26.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","path":"medias/music/avatars/daoshu.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/3q.jpg","path":"medias/banner/3q.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","path":"libs/awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/404.md","hash":"7e054c4ed489e0381e0f1ac91724ec5875bcc821","modified":1653189952101},{"_id":"source/CNAME","hash":"b8bda8a8a2b7d9895527115fab04a267cf53cc8e","modified":1653185597363},{"_id":"themes/matery/.gitignore","hash":"eaa3d84cb77d92a21b111fd1e37f53edc1ff9de0","modified":1653185597374},{"_id":"themes/matery/README_CN.md","hash":"a94324950e0299bcfcbc106cf2ca65c93e1fe843","modified":1653185597379},{"_id":"themes/matery/README.md","hash":"7ef16198a2c5ff580f006582286354caf160c7fe","modified":1653198189775},{"_id":"themes/matery/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1653185597374},{"_id":"themes/matery/_config.yml","hash":"97905be86433b4d13bc05533decd3b379e96a4a2","modified":1655643178735},{"_id":"source/about/index.md","hash":"c1ca8e88b3cee1bff6ea56338c5c72a830bb9de3","modified":1653194161945},{"_id":"source/archives/index.md","hash":"30a0e3a59be650ae34d7bb86ac7da53e21e9cf5b","modified":1653185597363},{"_id":"source/_data/musics.json","hash":"32bc061f34721b4ff55f880de1d0ec5787acd2f9","modified":1653185597363},{"_id":"source/categories/index.md","hash":"67687d3f908737f7c680f096b3e80d9412f23b0e","modified":1653185597374},{"_id":"source/_posts/algorithm-dp.md","hash":"8b9d55ac3b401c52867926580edc4695e3dac5c2","modified":1675567706612},{"_id":"source/_data/friends.json","hash":"39dd1a22df5fa66e439adb166cd4186a23a7fc8a","modified":1653192199625},{"_id":"source/_posts/algorithm-linked-list.md","hash":"734b1769220e0e30fe8022cff5c7a7f35873fa59","modified":1681018045589},{"_id":"source/_posts/hello-go.md","hash":"5d169e2e1ced5b8c39cfcb81bfcc2afc5b0339ef","modified":1657030989893},{"_id":"source/_posts/hexo_new.md","hash":"4994dbbd999e8450fd3e8f9db8b16a697af8395a","modified":1656944715525},{"_id":"source/_posts/kafka-producer-consumer.md","hash":"53fb42656b700ee22e54ff0619dae744f28a21f7","modified":1667134998388},{"_id":"source/_posts/kafka-topic-and-partition.md","hash":"f81f8438e274f42dfaeb52d50cae69ceb06b7f4f","modified":1669533903759},{"_id":"source/_posts/ovn-ls-pipeline.md","hash":"f5403a28de9547f12fa4a698c690704456d975bf","modified":1665897068141},{"_id":"source/_posts/ovs-port-vlan.md","hash":"74a2f7c369077edbeefd8d18b7248d99d124fd6f","modified":1664289246756},{"_id":"source/_posts/win11_wsl.md","hash":"59c3baf0a6d1ea69b73ae387e1fca9f4610129db","modified":1656944705788},{"_id":"source/friends/index.md","hash":"0ad4aaf3467380fc8ec354fe2fe76b0331bfeead","modified":1653194981789},{"_id":"source/tags/index.md","hash":"fe3d7ecc91b81b062a6a60c06859dc24b9d704ac","modified":1653185597374},{"_id":"themes/matery/languages/default.yml","hash":"527c795b8c41fe62bf35603ffebfa6d4a7929a2c","modified":1653185597379},{"_id":"themes/matery/languages/zh-CN.yml","hash":"f31748601349fbc98166d8fae35f2fc24da787b6","modified":1653195443594},{"_id":"themes/matery/layout/404.ejs","hash":"f08a0f507b36f3652520a41381f71167488405c7","modified":1653185597379},{"_id":"themes/matery/layout/about.ejs","hash":"e87752e59f021b5139b1155a264da11ab469a9aa","modified":1653185597395},{"_id":"themes/matery/layout/categories.ejs","hash":"c431e772d0f7700592228bbd9502793bdc28a893","modified":1653185597403},{"_id":"themes/matery/layout/archive.ejs","hash":"1b5023571894404d75caffa28128fc9c49f9095d","modified":1653185597403},{"_id":"themes/matery/layout/contact.ejs","hash":"1513c5a40b7cc0b6e5854cf8c3253958bcb486cb","modified":1653185597403},{"_id":"themes/matery/layout/friends.ejs","hash":"895e40a864796680fbef581e4b09f252fbdd963a","modified":1653185597403},{"_id":"themes/matery/layout/layout.ejs","hash":"e5533430177407e67c7531207651095170f01d96","modified":1653197897839},{"_id":"themes/matery/layout/category.ejs","hash":"2d421e10c3b8fd2c4f725e5eaa967c4a1429c707","modified":1653185597403},{"_id":"themes/matery/layout/index.ejs","hash":"7fc5a6c4f0229c0be43b7d1315524c468346fbb8","modified":1653185597403},{"_id":"themes/matery/layout/tag.ejs","hash":"5cdf3a1d72f54285ee9cb826fd0e4a0449093215","modified":1653185597403},{"_id":"themes/matery/layout/tags.ejs","hash":"851c0ee599e91e7b1d657673859e8b6ff79cf50b","modified":1653185597403},{"_id":"themes/matery/layout/post.ejs","hash":"f1a35f32e5901e167ae9a750e7cb3635549cea2e","modified":1653185597403},{"_id":"themes/matery/source/yteng.jpg","hash":"4f8490d1cee76eb0a3bccf880e26f2adcbf617f5","modified":1653184810238},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030212257.png","hash":"ebbbd5f0885318022ecd78b833722db72478b0ee","modified":1667136177347},{"_id":"source/_posts/ovs-port-vlan/img-20220705225523.png","hash":"4b4d268733022d0ea4a2ee30d3f1c2e087fef42a","modified":1657032923935},{"_id":"source/_posts/ovs-port-vlan/img-20220707222806.png","hash":"498a37bc50797be4b8e08ffe1b894827d533d887","modified":1657204086472},{"_id":"source/_posts/ovs-port-vlan/img-20220707222722.png","hash":"86d15213dc6c452f4bbe35936427d11e77a65fcc","modified":1657204042608},{"_id":"source/_posts/ovs-port-vlan/img-20220707221449.png","hash":"45078a420e2d1f408844c1d615c7a38ccc129e06","modified":1657203289274},{"_id":"source/_posts/ovs-port-vlan/img-20220707222905.png","hash":"9cc10ec38e416a1c0c381e7ce89681b36ca07a03","modified":1657204145598},{"_id":"source/_posts/ovs-port-vlan/img-20220707223104.png","hash":"f15a174ad0e2f4401f972e320768c2bdeef663ac","modified":1657204264884},{"_id":"source/_posts/ovs-port-vlan/img-20220710223431.png","hash":"b44167fd66e7dd71f9ec1302ee9129008dcc54d5","modified":1657463671376},{"_id":"source/_posts/ovs-port-vlan/img-20220710223519.png","hash":"9061ee7dc15f29010ada1d4ea033bc0ea70e6d2e","modified":1657463720012},{"_id":"source/_posts/ovs-port-vlan/img-20220711222607.png","hash":"c85ecfcd76b20da59e2b6da8de59bf6705ac572d","modified":1657549567442},{"_id":"source/_posts/win11_wsl/img-20220625215308.png","hash":"31123ccda88538e64176b25a785418d013ac8bb9","modified":1656165189151},{"_id":"source/_posts/win11_wsl/img-20220625215633.png","hash":"b1d99c6214115e647748ac031a9897828dec50c1","modified":1656165394840},{"_id":"source/_posts/win11_wsl/img-20220625221705.png","hash":"b00c6bcbb6951e578eb8dc92bff52dd1a4ddd67b","modified":1656166626055},{"_id":"themes/matery/layout/_partial/back-top.ejs","hash":"cb99dc352397ec5d0765794d7b8884972e61973b","modified":1653185597379},{"_id":"themes/matery/layout/_partial/bg-cover.ejs","hash":"d5a7b9bb96e04c0a3485dd873748f19c50a6a04f","modified":1653185597383},{"_id":"themes/matery/layout/_partial/bg-cover-content.ejs","hash":"a408fc9f815c56a25ec3dbfdb492a774418cddb4","modified":1653485354153},{"_id":"themes/matery/layout/_partial/disqus.ejs","hash":"42dda8e67f7f09d148347887e52f18aea546df26","modified":1653185597383},{"_id":"themes/matery/layout/_partial/footer.ejs","hash":"ffabca73db835b2324d7fc20c02e09f2cafed29b","modified":1653195190701},{"_id":"themes/matery/layout/_partial/gitalk.ejs","hash":"a3a140e6aeeb6f289e4b821a577ef548267f3de1","modified":1653185597385},{"_id":"themes/matery/layout/_partial/gitment.ejs","hash":"d8c40dbc8106b5bc53ceb727ad968c1d8f234261","modified":1653185597386},{"_id":"themes/matery/layout/_partial/google-analytics.ejs","hash":"890c8f04c1f4905dfceb3ea9fd6efdd040d79c01","modified":1653185597387},{"_id":"themes/matery/layout/_partial/github-link.ejs","hash":"fd4034bca2eb3987dcf113e6477260bee97eb1e7","modified":1653185597386},{"_id":"themes/matery/layout/_partial/head.ejs","hash":"fb572df037b5a6eb563912caa1f1967ca835a70a","modified":1653185597387},{"_id":"themes/matery/layout/_partial/index-cover.ejs","hash":"d4042e5521ceb5f3255cd4455ac7ccd227fee6df","modified":1653185597387},{"_id":"themes/matery/layout/_partial/mobile-nav.ejs","hash":"e761f0104fbf431671bbe6bebc91ca82f737f4d2","modified":1653185597387},{"_id":"themes/matery/layout/_partial/header.ejs","hash":"821e1af65990521c9e0288178d8e5b18c73a9cab","modified":1653185597387},{"_id":"themes/matery/layout/_partial/livere.ejs","hash":"42728561c09589f79b698eb059ab4def53ed3642","modified":1653185597387},{"_id":"themes/matery/layout/_partial/navigation.ejs","hash":"3a82fcb6f31d69971cb564985842c14ac02cdca0","modified":1653185597387},{"_id":"themes/matery/layout/_partial/post-statis.ejs","hash":"3b42900247d5ea4ea5b68e2be44420a0d54785ad","modified":1653185597387},{"_id":"themes/matery/layout/_partial/paging.ejs","hash":"dfdeea9c59d157acb851d4bf44bf95f81787523c","modified":1653185597387},{"_id":"themes/matery/layout/_partial/post-detail.ejs","hash":"3f208f33e4e12becdb8323e6e64e20ad60c3fb2a","modified":1653185597387},{"_id":"themes/matery/layout/_partial/post-cover.ejs","hash":"166c0b9753f3f913bd801e82ad5b268004be198d","modified":1653185597387},{"_id":"themes/matery/layout/_partial/post-detail-toc.ejs","hash":"82cb8090cde663fa7ad67418a802997b3057e957","modified":1653185597387},{"_id":"themes/matery/layout/_partial/search.ejs","hash":"e859fe6e0259e0c123cb7ceda6e4cac836318ffc","modified":1653185597387},{"_id":"themes/matery/layout/_partial/prev-next.ejs","hash":"4e73f10eacb5d00a0681cb44fe5c039cd8ab03cd","modified":1653185597387},{"_id":"themes/matery/layout/_partial/share.ejs","hash":"0f2e1e27d21492cf228e786daead985b1e1dcea4","modified":1653185597387},{"_id":"themes/matery/layout/_partial/reward.ejs","hash":"73624d9db81e87ff0c12310bb873fbd0b5221021","modified":1653185597387},{"_id":"themes/matery/layout/_partial/reprint-statement.ejs","hash":"f85a222ec3f9bc27eb7978015e63a16514b38791","modified":1653185597387},{"_id":"themes/matery/layout/_partial/valine.ejs","hash":"c3039180ddb2eb17e724b8441e5f93e79859aef7","modified":1653185597395},{"_id":"themes/matery/layout/_widget/dream.ejs","hash":"6ae58a57b83a5999d0b6a737ec868f084d208f89","modified":1653185597395},{"_id":"themes/matery/layout/_partial/social-link.ejs","hash":"e2865b3003ec07892e9112692e7ec786ee926ae8","modified":1653185597395},{"_id":"themes/matery/layout/_widget/category-cloud.ejs","hash":"b2b22d4fc4e46b051f67216c391f629f4ff552b5","modified":1653185597395},{"_id":"themes/matery/layout/_widget/category-radar.ejs","hash":"5284712d84bbaa4f0d88026ac3ec5a8c13e00056","modified":1653185597395},{"_id":"themes/matery/layout/_widget/my-gallery.ejs","hash":"9ea672db65f1e5b8fad1ffafb1614f25adc97e63","modified":1653185597395},{"_id":"themes/matery/layout/_widget/music.ejs","hash":"fc50cb4bbc1f4d0e4c9f5941f1c3c74bea742db7","modified":1653185597395},{"_id":"themes/matery/layout/_widget/my-projects.ejs","hash":"785cb588a31215876f6737213054ba0e8552fff0","modified":1653185597395},{"_id":"themes/matery/layout/_widget/post-calendar.ejs","hash":"4608af6151f0e32f668c89f09343748340021478","modified":1653185597395},{"_id":"themes/matery/layout/_widget/my-skills.ejs","hash":"c6f713316ce75ad08ac5d1587bd8ce42e894e9ae","modified":1653185597395},{"_id":"themes/matery/layout/_widget/recommend.ejs","hash":"d439d86818de179d64965d4f7f5fa56147fd9221","modified":1653185597395},{"_id":"themes/matery/layout/_widget/post-charts.ejs","hash":"0aaf0a111b9aa07ff37f6286eeac5506283f47f8","modified":1653185597395},{"_id":"themes/matery/layout/_widget/video.ejs","hash":"05f5e2acace5730cdf7bed650375ad88f6b5d1b7","modified":1653185597395},{"_id":"themes/matery/layout/_widget/tag-wordcloud.ejs","hash":"bf604fe9c435f0fb9a559cac9c35772579b590e8","modified":1653185597395},{"_id":"themes/matery/layout/_widget/tag-cloud.ejs","hash":"6310903eb0e434d6f9a59ca669aab7fae38d4797","modified":1653185597395},{"_id":"themes/matery/source/css/my.css","hash":"37683a9f11c68903a53e2b8593ca8c095a721896","modified":1653185597403},{"_id":"themes/matery/source/css/gitment.css","hash":"d5ef623065d1fbc897119f7b70ccf7563e329917","modified":1653185597403},{"_id":"themes/matery/source/css/my-gitalk.css","hash":"4e3e855767ac5a48b13af1d6a42df13d8975e03f","modified":1653185597403},{"_id":"themes/matery/source/css/matery.css","hash":"0d345a72318fd7aadcb6fcaa6f3abac94b91001c","modified":1653185597403},{"_id":"themes/matery/source/js/matery.js","hash":"208b7806caa943c115aa0825c9c72a0781404775","modified":1653185597411},{"_id":"themes/matery/source/js/search.js","hash":"77ecae23dd3edd8ad962c5b12954652bb2f7a1b6","modified":1653185597411},{"_id":"source/_posts/kafka-producer-consumer/producer-structure.jpg","hash":"32789c2d2297fde14c33a08c1e4803579d8e7f48","modified":1653180574746},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030211533.png","hash":"fc490ac8378fe775bc659c5bda3903994ae62ab2","modified":1667135734051},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106230222.png","hash":"7212f702cb2b2c851c5ba240d537766204810d5e","modified":1667746943076},{"_id":"source/_posts/ovs-port-vlan/img-20220710224012.png","hash":"66d869d27bdd2053c11c2ae9edfcde0562f3efeb","modified":1657464012675},{"_id":"source/_posts/ovs-port-vlan/img-20220710231542.png","hash":"aa056e7b4114d24a2a8b36aef6ea049a56ee6ef7","modified":1657466143049},{"_id":"source/_posts/ovs-port-vlan/img-20220710231215.png","hash":"36ced1ab27c3e25ef2bd73d3201bf8975b9efb24","modified":1657465935621},{"_id":"source/_posts/ovs-port-vlan/img-20220713213515.png","hash":"a8f4dbb7ce18dfdcf0c047ff22baa2ec9dfce4d5","modified":1657719316048},{"_id":"source/_posts/ovs-port-vlan/img-20220713213553.png","hash":"9be52bf4e9049eba81dd2797679e8e482c7c07bd","modified":1657719353920},{"_id":"source/_posts/ovs-port-vlan/img-20220713213626.png","hash":"83ee4f0c8cff42908a8222429abf1a55ec7b28bf","modified":1657719387052},{"_id":"source/_posts/ovs-port-vlan/img-20220713213656.png","hash":"ddf26a07d857955983eca96803b1e33a82952fc8","modified":1657719416683},{"_id":"source/_posts/ovs-port-vlan/img-20220713215316.png","hash":"7f8b1e00266c29cb0eb259e19a3a2be290e6a8f1","modified":1657720396715},{"_id":"source/_posts/ovs-port-vlan/img-20220713220442.png","hash":"4a92dcb110fa37ddb8b847e112f7d0d8007eb997","modified":1657721083228},{"_id":"source/_posts/win11_wsl/img-20220625220129.png","hash":"af09b7098035dd29134e0c267086a50800974164","modified":1656165690896},{"_id":"source/_posts/win11_wsl/img-20220625220014.png","hash":"40235697f87b378ba6e13c745e6b925d0ada0545","modified":1656165615829},{"_id":"source/_posts/kafka-producer-consumer/img-20221030201350.png","hash":"e94ba813448992501f1b097d2a42a5e84450258d","modified":1667132031002},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222336.png","hash":"04dc71ad3155c7e8733ac145f0647afdd7404a2e","modified":1667744616796},{"_id":"themes/matery/source/medias/yteng.jpg","hash":"4f8490d1cee76eb0a3bccf880e26f2adcbf617f5","modified":1653184810238},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222544.png","hash":"bb23f4692dd9488e7cc4e3be1dea1e41d7837ddc","modified":1667744745207},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106230140.png","hash":"c5f1b22fd7c5fd773c26b1045e980940eb74381e","modified":1667746900961},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106223639.png","hash":"da4fe4b016a25ed9ff18951efb7ab56cd8916384","modified":1667745399686},{"_id":"source/_posts/ovs-port-vlan/img-20220710224207.png","hash":"875d13ff86905e68fcb2427045801f6f56cec7a9","modified":1657464127262},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","hash":"7f4f8913f2d46ade2def5134e2cc8684a4b87939","modified":1653185597411},{"_id":"themes/matery/source/libs/aos/aos.css","hash":"ded9739f803d114c9168d3351fded72b3b478b4c","modified":1653185597411},{"_id":"themes/matery/source/libs/aos/aos.js","hash":"5a8e6d07ffa55642418ab3fd4b263aa08284b77a","modified":1653185597411},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","hash":"70c0c4a9bf698747b7c058c21287ad617355e5dd","modified":1653185597411},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1653185597427},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","hash":"b74a381adf6ef8404d6a0452c2b9f44b47219c80","modified":1653185597427},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","hash":"ea8b51e4d75e7b2cd63e4d5bcb8db2cf7f23f5db","modified":1653185597427},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","hash":"215910dc8f63fd50b97957e5fcdc8480aa2728cb","modified":1653185597427},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","hash":"9cd57c67fbd3e3067f80793ef8445f5ff7783563","modified":1653185597427},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","hash":"33810b2b757fc4327bc1d3b83bb5e0d3dc1fec5b","modified":1653185597427},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","hash":"a0625d8b432af8bdc820f8768d36cde439e7257c","modified":1653185597435},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","hash":"5d52d3b34fceb9d7e11f1beaf7ed380b4249dec4","modified":1653185597427},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","hash":"021898a16279ac2ffe75af4f902fab2a0a39f11a","modified":1653185597435},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"26849509f196a2d21bbfd15696e5d5153163b8f1","modified":1653185597443},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","hash":"4e6538c8312aeeab845d361c37a8c1a0931241f0","modified":1653185597443},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1653185597451},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","hash":"f81cd7bfcf7aa2d043bd3e6077df42656fc44b82","modified":1653185597451},{"_id":"themes/matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1653185597451},{"_id":"themes/matery/source/libs/others/explosion.min.js","hash":"417b68e2cf2c6de2119c57626f4412105a8457f5","modified":1653185597451},{"_id":"themes/matery/source/libs/others/text.js","hash":"1791782cde0d1e4197f2ed58ecb7dd6aefddd169","modified":1653185597459},{"_id":"themes/matery/source/libs/others/snow.js","hash":"b393f069781eef788a0ae66b2681cece8fea2851","modified":1653185597459},{"_id":"themes/matery/source/libs/others/fireworks.js","hash":"53981959bc6def4a85bbbb41b07e4b1474a2124d","modified":1653185597451},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1653185597459},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","hash":"f646f2bb75bcd1eb65b2788ac7bf15d4fd243ce9","modified":1653185597459},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1653185597459},{"_id":"themes/matery/source/medias/files/golang.jpeg","hash":"6c49a9400a0c8a237714e7f93a8497ae590e38d5","modified":1653180574698},{"_id":"themes/matery/source/medias/files/kafka-topic-partition.jpg","hash":"864fdaca662f6e70734061d165553e7c86f7a147","modified":1667134923752},{"_id":"source/_posts/kafka-producer-consumer/img-20221016191323.png","hash":"1e7fd3dc563c83019b01c845f2b76348d570db64","modified":1665918804428},{"_id":"themes/matery/source/medias/files/wsl.jpg","hash":"6700d64cc0e1f48d2936343bacd1d6b45e286e9d","modified":1656162914108},{"_id":"source/_posts/kafka-producer-consumer/img-20221030190716.png","hash":"30838f3ebdebc696af26fd152e840871e9603282","modified":1667128037055},{"_id":"themes/matery/source/medias/reward/wechat.png","hash":"61eb27bc4ec65f4f116d34740903fb5af75bf561","modified":1653185597607},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030211753.png","hash":"9424440a19510245f397f153d1d2622d572e1265","modified":1667135873640},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030211824.png","hash":"6d1f6abcd328c251ebe56e84caff18b3d4cfea67","modified":1667135905024},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222348.png","hash":"24ea616af61bad505ce043ba52462ca59f87ac3d","modified":1667744628451},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222536.png","hash":"56e2b82b4176bb29373e2595e545e4262b2ba8d9","modified":1667744736413},{"_id":"source/_posts/ovs-port-vlan/img-20220710225805.png","hash":"478c0e1179a2e7ec5c3d7a1f77f437a6b461c5ff","modified":1657465085502},{"_id":"source/_posts/ovs-port-vlan/img-20220710230349.png","hash":"8f7df7bef01464205e538ff4130b7130eba2e223","modified":1657465429573},{"_id":"source/_posts/ovs-port-vlan/img-20220711222511.png","hash":"b0edb816180027f8fefbae6c5e4c7ce67097cd75","modified":1657549511366},{"_id":"source/_posts/ovs-port-vlan/img-20220713200925.png","hash":"3fe26afff4cb389053ee5de02bb3306e29462c6e","modified":1657714165566},{"_id":"source/_posts/ovs-port-vlan/img-20220713203933.png","hash":"1bd14a7a4ea1cfca6d9fb0e9769b04ae5b112486","modified":1657715973922},{"_id":"source/_posts/ovs-port-vlan/img-20220713205845.png","hash":"8416236ef384b52c8ba4c7a914534d38ade20a47","modified":1657717125501},{"_id":"source/_posts/ovs-port-vlan/img-20220713212741.png","hash":"17f8eb5409c1bc5ea6df298c2123a8b731dc7e46","modified":1657718861554},{"_id":"source/_posts/ovs-port-vlan/img-20220713220011.png","hash":"144ea6bb113907c903fd546db137a0e00f241d82","modified":1657720812079},{"_id":"themes/matery/source/libs/animate/animate.min.css","hash":"5dfcbcee866e9dc564916416281885f3e320871e","modified":1653185597411},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","hash":"82276be41d2001e820020a219b90ad5b026302d1","modified":1653185597427},{"_id":"themes/matery/source/libs/gitment/gitment.js","hash":"5a13983930b019450e4fe01a407c64b3dd316be4","modified":1653185597443},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","hash":"7a551393b8360731104fdef1af36a6f3638f5855","modified":1653185597443},{"_id":"themes/matery/source/libs/valine/Valine.min.js","hash":"f1558f12d96a352e490166d543a8e821dd3bb2bc","modified":1653185597467},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","hash":"992e0d803160d2ae867be5eb0032d324d1cedffb","modified":1653185597500},{"_id":"themes/matery/source/medias/featureimages/24.jpg","hash":"a09e23a33704d69aed155b0fdd866f69931ca3eb","modified":1653488431372},{"_id":"themes/matery/source/medias/featureimages/28.jpg","hash":"e5c69d25a305c82c5c822b04d4bc47a27e275137","modified":1653488372417},{"_id":"themes/matery/source/medias/files/linked-list.png","hash":"e6f496cdf7c1a2130a4436622d0a22428e345602","modified":1681011922876},{"_id":"themes/matery/source/medias/files/ovn.jpg","hash":"4fc733f74fe469662ed459cc9f0ca8c1418135dd","modified":1664290011490},{"_id":"themes/matery/source/medias/files/ovs_vlan.jpg","hash":"c93c6a69ee2eb36e4b0061da0aaf2ea46db260e2","modified":1657723854672},{"_id":"source/_posts/kafka-producer-consumer/img-20221030200350.png","hash":"5a693b82b62e3d2298f253a97cdf9e3d4d110f72","modified":1667131430543},{"_id":"themes/matery/source/medias/reward/alipay.jpg","hash":"9bade255a1918cfb3c3bcefbbbc8f163bf2e19e3","modified":1653185597607},{"_id":"source/_posts/kafka-producer-consumer/img-20221030193459.png","hash":"da903612b53a73611464f929f469fa03ab2f4e67","modified":1667129699355},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222237.png","hash":"16db2f5a64d7898c649b4534987a063fe678af0c","modified":1667744558137},{"_id":"source/_posts/ovs-port-vlan/img-20220710225731.png","hash":"b4d0af8811816f888492d28dcb6d690d1fcb28f9","modified":1657465051942},{"_id":"source/_posts/ovs-port-vlan/img-20220710231015.png","hash":"45d7054c387a69e9a8bfba681b469cd7f1c13770","modified":1657465816050},{"_id":"source/_posts/ovs-port-vlan/img-20220713201315.png","hash":"a1cd4d61e7c2134c53d92bd0f76f241d189dffa2","modified":1657714395581},{"_id":"source/_posts/ovs-port-vlan/img-20220713203212.png","hash":"4c584e8f819326c746f350a7bddddd91c44809a5","modified":1657715533161},{"_id":"source/_posts/ovs-port-vlan/img-20220713210138.png","hash":"d7b79b72910bae9b96fb9146dda4c75ac6ca95d4","modified":1657717298762},{"_id":"source/_posts/ovs-port-vlan/img-20220713211909.png","hash":"ed5cf5be96616c90d69f16e7744cfec7c46aa50a","modified":1657718349590},{"_id":"source/_posts/ovs-port-vlan/img-20220713212414.png","hash":"972a6c3796773f2b54872e0c6fbfeab930432acb","modified":1657718654812},{"_id":"source/_posts/ovs-port-vlan/img-20220713212418.png","hash":"972a6c3796773f2b54872e0c6fbfeab930432acb","modified":1657718659162},{"_id":"source/_posts/ovs-port-vlan/img-20220713213027.png","hash":"8107fa83e08e70903ec1ba3f22db3e055e89cf55","modified":1657719027300},{"_id":"source/_posts/ovs-port-vlan/img-20220713214218.png","hash":"3b015182168beb574bb68e5694fe2bc6b0b211fc","modified":1657719738410},{"_id":"source/_posts/ovs-port-vlan/img-20220713214451.png","hash":"8301d9c7738687dfa8364d9a401f8bca1eddabd6","modified":1657719891771},{"_id":"source/_posts/ovs-port-vlan/img-20220713214945.png","hash":"fb5f15f4d52443d4c86956bf4b3197aaf4a1459c","modified":1657720185351},{"_id":"source/_posts/ovs-port-vlan/img-20220713215748.png","hash":"2ab17b8c64149a9ee2edf60991f347e52276ae13","modified":1657720669131},{"_id":"source/_posts/ovs-port-vlan/img-20220713220356.png","hash":"638499883e82cfa74f6b516d1227220bcad9488b","modified":1657721036434},{"_id":"source/_posts/ovs-port-vlan/img-20220713221021.png","hash":"03e6776723544b10933f395228edfba3809eeb64","modified":1657721421792},{"_id":"source/_posts/ovs-port-vlan/img-20220713221726.png","hash":"1fbec75334905e14848ee74036599aa60571953a","modified":1657721846905},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1653185597411},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","hash":"3480f00d284c812d623ed16a9e0ead3fb964c72e","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1653185597443},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1653185597451},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","hash":"2c27939768606603bee3b5e6c8a722596a667e60","modified":1653185597451},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","hash":"c843f0dc497314574c608ca28cc742bb041786d5","modified":1653185597451},{"_id":"themes/matery/source/libs/share/css/share.min.css","hash":"7126de5cec8371e580b7b1f22512da0985cc39e5","modified":1653185597459},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1653185597459},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1653185597459},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1653185597459},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1653185597459},{"_id":"themes/matery/source/libs/valine/av-min.js","hash":"04c6b2782ce4610c429563110f6a20a47432fc4c","modified":1653185597467},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1653185597459},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1653185597459},{"_id":"themes/matery/source/medias/featureimages/12.jpg","hash":"75edf09467fc3d79467c69f904575651b124efce","modified":1653488110949},{"_id":"themes/matery/source/medias/featureimages/25.jpg","hash":"f8018c34b4769407d52464d3fee178706e63aed0","modified":1653488424352},{"_id":"themes/matery/source/medias/featureimages/27.jpg","hash":"dd1ba110867c7e842e4f9008d5f2d0ef147c2df8","modified":1653488406225},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","hash":"f005578ddb4d3d731838db89a708f39f18d50e60","modified":1653185597599},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","hash":"103beb9ab33434b434fa37a30aecdb29db633024","modified":1653185597607},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","hash":"01b12e3aca7385a88412c12539e1a608a78896fa","modified":1653185597607},{"_id":"themes/matery/source/medias/files/kafka-producer-consumer.png","hash":"586f21688206ba8e04d96906bbc641ebb3db359d","modified":1665898622680},{"_id":"source/_posts/ovs-port-vlan/img-20220710231738.png","hash":"45755047e1da23e4206d54afb04082f90dbb5720","modified":1657466258304},{"_id":"source/_posts/ovs-port-vlan/img-20220711222809.png","hash":"1e8efec4b66dddd6b3adac9a3660f3639199b6fc","modified":1657549690206},{"_id":"source/_posts/ovs-port-vlan/img-20220713212047.png","hash":"49e96fcd36e2c43a9babf6d961b45a39b9671d47","modified":1657718447833},{"_id":"source/_posts/ovs-port-vlan/img-20220713212213.png","hash":"5ccb1d8fdaab33f1fd60c1a565e9970028b05a06","modified":1657718533521},{"_id":"source/_posts/ovs-port-vlan/img-20220713213800.png","hash":"9de3ce9642cdb0a91c1a89ca1e83fa96d5c62211","modified":1657719481021},{"_id":"source/_posts/ovs-port-vlan/img-20220713214125.png","hash":"9aadea49c3f59adbf98422458def5ceaa45f26ae","modified":1657719685388},{"_id":"source/_posts/ovs-port-vlan/img-20220713215625.png","hash":"afa7d05e734e8eb99c57e08ace11dc4849aad1c4","modified":1657720585954},{"_id":"source/_posts/ovs-port-vlan/img-20220713220741.png","hash":"f5a76d7fb7d25d73e63d0587c82a4cefa0f4b600","modified":1657721261563},{"_id":"source/_posts/ovs-port-vlan/img-20220713220933.png","hash":"b79f1399a14b710e4a27b9f1c4fb35e1b6ef3c4c","modified":1657721373268},{"_id":"source/_posts/ovs-port-vlan/img-20220713220829.png","hash":"33bac3da99d2d9d50fca7d3b39b3581b804c7a80","modified":1657721309714},{"_id":"source/_posts/ovs-port-vlan/img-20220713221252.png","hash":"a74da9698cf922182b082d6c1b01de21677506f5","modified":1657721572962},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1653185597427},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1653185597427},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","hash":"f63c7c489524ccb5d95e74fcd6618116c58fb305","modified":1653185597435},{"_id":"themes/matery/source/medias/banner/0.jpg","hash":"ee3486808fac6e0fd3ccd43d626e28534c5a3c97","modified":1653485022116},{"_id":"themes/matery/source/medias/banner/6.jpg","hash":"ac7ce1a888385a9fddcfefd843c9ced601653acf","modified":1653485108846},{"_id":"themes/matery/source/medias/featureimages/21.jpg","hash":"d003307aa45b2ffd4d10a963ae768aeffe88dd1b","modified":1653488467096},{"_id":"themes/matery/source/medias/files/algorithm-dp.jpg","hash":"b8101d4675572b95d4a1d03dd4245689e9c8492a","modified":1669534470878},{"_id":"themes/matery/source/medias/files/hexo.png","hash":"e98edbfd094d4fb41d1277a96eb8fd04ee4e26d4","modified":1653485720333},{"_id":"source/_posts/kafka-producer-consumer/img-20221030202942.png","hash":"8b00c63ce44dcb55e24611278e5408444cb376a2","modified":1667132983270},{"_id":"source/_posts/ovs-port-vlan/img-20220713210045.png","hash":"fb32bd5a34149fd5fa593a9784c253ad3e9fbcde","modified":1657717246124},{"_id":"source/_posts/ovs-port-vlan/img-20220713214019.png","hash":"422c56fdda77582f3e48b4aa509989580f8b022f","modified":1657719620251},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1653185597419},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1653185597419},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1653185597419},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"f8cd48e1fff82ecd54a7ce3e69de8dba7c92d113","modified":1653185597451},{"_id":"themes/matery/source/medias/featureimages/23.jpg","hash":"181cadfbb92b58b4bd4c7c112500088159e8197f","modified":1653488448002},{"_id":"themes/matery/source/medias/featureimages/26.jpg","hash":"65569a4ac6ecf706cc0a52e28115cc12a8aa8126","modified":1653488417693},{"_id":"themes/matery/source/medias/featureimages/3.jpg","hash":"ddbf5b36aa5f14dbe109e579ec4ec6b33176db25","modified":1653488218256},{"_id":"themes/matery/source/medias/featureimages/9.jpg","hash":"ff2f70a0e9646c7ab5cc331ec1f538bc651c3a4c","modified":1653488139922},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222301.png","hash":"dfed1a2811afe3c4d54c41052d7d57aa77fb9e35","modified":1667744581687},{"_id":"source/_posts/ovs-port-vlan/img-20220713204049.png","hash":"5ebeb3ec5ae97c66cd0a67005f1c9420df6ba0d1","modified":1657716049679},{"_id":"source/_posts/ovs-port-vlan/img-20220713213923.png","hash":"83a7f3331285e04e215397aebf3f555fcee358dd","modified":1657719564154},{"_id":"source/_posts/ovs-port-vlan/img-20220713215402.png","hash":"f5b4bd454173fcad38aedeb89e12cefb7bb9bc96","modified":1657720443158},{"_id":"source/_posts/ovs-port-vlan/img-20220706221734.png","hash":"54b062f55c1fce60af1bff4eb6dad31066f6c330","modified":1657117054424},{"_id":"source/_posts/ovs-port-vlan/img-20220713201940.png","hash":"17527470ed55b895a603dba54d5882b2d41296b2","modified":1657714780841},{"_id":"source/_posts/ovs-port-vlan/img-20220713215454.png","hash":"5232b8509e029d1d6cb92766ab243614bf393983","modified":1657720495150},{"_id":"source/_posts/ovs-port-vlan/img-20220713220628.png","hash":"50db610a669e5a94b8d0890b7d6f8c028f905cf0","modified":1657721188650},{"_id":"themes/matery/source/medias/featureimages/15.jpg","hash":"0534bd1ceedf1512d5e697553a3839799c1198ac","modified":1653488266154},{"_id":"themes/matery/source/medias/featureimages/18.jpg","hash":"841de4ec83ce9a2ca5c9c0a57a825554e8c16b8e","modified":1653488523085},{"_id":"themes/matery/source/medias/featureimages/8.jpg","hash":"e6ab6a3147453ffcc3ab7d8791b59d3449e0e21c","modified":1653488153265},{"_id":"source/_posts/kafka-producer-consumer/img-20221030202957.png","hash":"22ac7600700830772149f7c3478ac863e83c9eb0","modified":1667132997597},{"_id":"source/_posts/ovs-port-vlan/img-20220713204647.png","hash":"4bfe2c6f61421e4b5d9ada91481a912075f9340e","modified":1657716407995},{"_id":"themes/matery/source/medias/featureimages/14.jpg","hash":"eac3bb4684f357de01a88f7e8ee9727f01a6f068","modified":1653488011575},{"_id":"themes/matery/source/medias/featureimages/16.jpg","hash":"325f0aa5eb1947fb02064342deefab12c7606a80","modified":1653488512164},{"_id":"themes/matery/source/medias/featureimages/19.jpg","hash":"6b2d217ea4cb929a9797aa4c88807f619bed4adc","modified":1653488488067},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","hash":"eee120fdf5ccbe86aa7d51826c4c773e76e6357f","modified":1653185597599},{"_id":"source/_posts/ovs-port-vlan/img-20220713214834.png","hash":"42850463a40f6aec3601bc690b4ec9a6c1566c15","modified":1657720114474},{"_id":"themes/matery/source/medias/banner/3q.jpg","hash":"dc499c951e4ad76fc7449ee71188c16ec76a0f99","modified":1653485080692},{"_id":"themes/matery/source/medias/featureimages/2.jpg","hash":"c032d72219fa458a9390e0e744cf66634df5c53a","modified":1653488248131},{"_id":"themes/matery/source/medias/featureimages/4.jpg","hash":"368385fe4b5364cf55b83f38784cf2e9aa307d07","modified":1653488210584},{"_id":"themes/matery/source/medias/featureimages/6.jpg","hash":"1d2656b9d1236ba0a79543d1ef0e046852223575","modified":1653488182544},{"_id":"source/_posts/ovs-port-vlan/img-20220713204432.png","hash":"0d64c7ca853ba146f74f58d0e98c35db62656ef8","modified":1657716272634},{"_id":"source/_posts/ovs-port-vlan/img-20220713212843.png","hash":"cbdd2708e628a3eaabb65c23a78545f5a325dd8b","modified":1657718923920},{"_id":"source/_posts/ovs-port-vlan/img-20220713214701.png","hash":"c9e011d32fdfe622cd6847d146d241456d122acf","modified":1657720021861},{"_id":"source/_posts/ovs-port-vlan/img-20220713220151.png","hash":"2e1cb1aac668395247aa73710bfdf4dfc3a43c1a","modified":1657720912216},{"_id":"source/_posts/ovs-port-vlan/img-20220713221610.png","hash":"6728f366c68086eab1639401cff0ad380510dede","modified":1657721771034},{"_id":"themes/matery/source/medias/banner/4.jpg","hash":"ddcf1fe5d837156262fa2b42a376ec75d7f1803a","modified":1653485089451},{"_id":"themes/matery/source/medias/banner/5.jpg","hash":"a74865a5f99f6bfc3ce94ccbd1c32b1dbe47bec8","modified":1653485098503},{"_id":"themes/matery/source/medias/featureimages/0.jpg","hash":"81b456baf62adf30b6a8f6275636b079e9aaecb4","modified":1653488259335},{"_id":"themes/matery/source/medias/featureimages/7.jpg","hash":"d6b18e98a2391588bf7ef5e0e36139c43ba61bb1","modified":1653488172255},{"_id":"source/_posts/ovs-port-vlan/img-20220711223215.png","hash":"c8506a8bdd0a016a85aaf246fc6e1c45c4f50d09","modified":1657549936227},{"_id":"themes/matery/source/medias/featureimages/17.jpg","hash":"6255009817cd91a2978741bc9b3cc74521c8eaf1","modified":1653488489712},{"_id":"source/_posts/ovs-port-vlan/img-20220713221436.png","hash":"97e84bcff363dd621a679de9e418e2580b236db4","modified":1657721676573},{"_id":"themes/matery/source/medias/featureimages/1.jpg","hash":"274a79b99183cedf2f91f89b55c7cc74daf3e8d5","modified":1653487752343},{"_id":"themes/matery/source/medias/featureimages/20.jpg","hash":"59523c31eaf1b78ced6401039624639a858f8ede","modified":1653488480818},{"_id":"themes/matery/source/medias/featureimages/22.jpg","hash":"1f2a81912efda8ff591be1729657ebbcbc7d3c0a","modified":1653488453125},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1653185597419},{"_id":"themes/matery/source/medias/banner/3.jpg","hash":"bc1661941c4528838e2d7dba4ca8c3c2d43c0777","modified":1653485471845},{"_id":"source/_posts/ovs-port-vlan/img-20220713203016.png","hash":"5186fa065c644e5d8cee06be8c4dce11d827a367","modified":1657715416614},{"_id":"themes/matery/source/medias/featureimages/5.jpg","hash":"08196944c4ee4233d02564f7d71251f39a12a1ad","modified":1653488191134},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","hash":"8789b5e4daf0029a6c88f238f10e54d01c4fce82","modified":1653185597435},{"_id":"themes/matery/source/medias/featureimages/10.jpg","hash":"a44b0c2825664bf6d0758e6a0c17b91e386c2815","modified":1653488129756},{"_id":"themes/matery/source/medias/banner/1.jpg","hash":"21049be0572739d5cd35a47aafe475ff223dd24d","modified":1653485029482},{"_id":"themes/matery/source/medias/banner/2.jpg","hash":"d6a389f2e63d952b39d446ecee1cf19c4036fac7","modified":1653485036389},{"_id":"themes/matery/source/medias/featureimages/11.jpg","hash":"36499835a9a3a4e22757e7abc3f8fce685a93364","modified":1653488116771},{"_id":"themes/matery/source/medias/featureimages/13.jpg","hash":"24b87e59d8b606fe819964bc0769d8a580d6f945","modified":1653488104661}],"Category":[{"name":"随笔","_id":"clg8yre9h0005agvtyeznptzk"},{"name":"学习笔记","_id":"clg8yre9x000iagvt1ntrjqsl"},{"name":"算法","parent":"clg8yre9h0005agvtyeznptzk","_id":"clg8yre9x000oagvt9y9za8fo"},{"name":"Network","_id":"clg8yre9x000wagvt1i4objj8"},{"name":"工具","_id":"clg8yread0011agvtsathc0lj"},{"name":"NetWork","_id":"clg8yread0017agvtrxqmv4xx"}],"Data":[{"_id":"musics","data":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]},{"_id":"friends","data":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}],"Page":[{"title":"404","date":"2019-07-19T08:41:10.000Z","type":"404","layout":"404","description":"Not Found","_content":"","source":"404.md","raw":"---\ntitle: 404\ndate: 2019-07-19 16:41:10\ntype: \"404\"\nlayout: \"404\"\ndescription: \"Not Found\"\n---\n","updated":"2022-05-22T03:25:52.101Z","path":"404.html","comments":1,"_id":"clg8yre7b0000agvtfbcazqmx","content":"<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":""},{"title":"about","date":"2019-07-19T08:41:10.000Z","type":"about","layout":"about","mathjax":true,"_content":"\n\n## 2019\n\n首先，我的第一个网站是`www.yteng3456.xyz`，这是一个基于ThinkPHP5.0框架搭建的个人博客，具有完整的前后端，功能还算齐全，但是因为现在域名到期，云虚拟主机到期，经费不足以支持。\n\n所以我找到了Github + Hexo 的搭建方式。有了前面的搭建经验，也很容易上手了Hexo，没有数据库的加持，虽然少了几分技术特色，但是更快的提交静态页面也未尝不可。\n\n以后，我将永久使用此网站作为自己的发源地，继续前行。\n\n`https://xiaoyixiaoyang.github.io/`\n\n\n## 2020\n\n这一年博客输出量很少，原因是前一年在准备求职，所以重新读了很多书，把书上的重要内容都做了笔记，虽然笔记做的不好，但是对自己也还算有些帮助。\n\n疫情期间也是浪费了很多时间，在家没有学习，毕设做的也没有很完美，最终成绩平平毕业。\n\n进入工作，就打起精神，认真做好每一件事，学习职场的一些技能，也学习项目工程开发的一些技能，进步不少，金钱也拿了不少，还了上学期间的助学贷款，下一步期望就是挣更多的钱、学更多的知识，掌握更多的技能。\n\n\n\n## 2021\n\n目标：\n\n1.整理之前的博客，将内容补充完成，条理清楚。\n\n2.输出新的博客，虚拟网络相关。\n\n## 联系方式\n* <b>电子邮箱</b>\n1409026014@qq.com\n* <b>微信</b>\nyteng3456\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-07-19 16:41:10\ntype: \"about\"\nlayout: \"about\"\nmathjax: true\n---\n\n\n## 2019\n\n首先，我的第一个网站是`www.yteng3456.xyz`，这是一个基于ThinkPHP5.0框架搭建的个人博客，具有完整的前后端，功能还算齐全，但是因为现在域名到期，云虚拟主机到期，经费不足以支持。\n\n所以我找到了Github + Hexo 的搭建方式。有了前面的搭建经验，也很容易上手了Hexo，没有数据库的加持，虽然少了几分技术特色，但是更快的提交静态页面也未尝不可。\n\n以后，我将永久使用此网站作为自己的发源地，继续前行。\n\n`https://xiaoyixiaoyang.github.io/`\n\n\n## 2020\n\n这一年博客输出量很少，原因是前一年在准备求职，所以重新读了很多书，把书上的重要内容都做了笔记，虽然笔记做的不好，但是对自己也还算有些帮助。\n\n疫情期间也是浪费了很多时间，在家没有学习，毕设做的也没有很完美，最终成绩平平毕业。\n\n进入工作，就打起精神，认真做好每一件事，学习职场的一些技能，也学习项目工程开发的一些技能，进步不少，金钱也拿了不少，还了上学期间的助学贷款，下一步期望就是挣更多的钱、学更多的知识，掌握更多的技能。\n\n\n\n## 2021\n\n目标：\n\n1.整理之前的博客，将内容补充完成，条理清楚。\n\n2.输出新的博客，虚拟网络相关。\n\n## 联系方式\n* <b>电子邮箱</b>\n1409026014@qq.com\n* <b>微信</b>\nyteng3456\n","updated":"2022-05-22T04:36:01.945Z","path":"about/index.html","comments":1,"_id":"clg8yre920001agvt4s7o90cl","content":"<h2 id=\"2019\"><a href=\"#2019\" class=\"headerlink\" title=\"2019\"></a>2019</h2><p>首先，我的第一个网站是<code>www.yteng3456.xyz</code>，这是一个基于ThinkPHP5.0框架搭建的个人博客，具有完整的前后端，功能还算齐全，但是因为现在域名到期，云虚拟主机到期，经费不足以支持。</p>\n<p>所以我找到了Github + Hexo 的搭建方式。有了前面的搭建经验，也很容易上手了Hexo，没有数据库的加持，虽然少了几分技术特色，但是更快的提交静态页面也未尝不可。</p>\n<p>以后，我将永久使用此网站作为自己的发源地，继续前行。</p>\n<p><code>https://xiaoyixiaoyang.github.io/</code></p>\n<h2 id=\"2020\"><a href=\"#2020\" class=\"headerlink\" title=\"2020\"></a>2020</h2><p>这一年博客输出量很少，原因是前一年在准备求职，所以重新读了很多书，把书上的重要内容都做了笔记，虽然笔记做的不好，但是对自己也还算有些帮助。</p>\n<p>疫情期间也是浪费了很多时间，在家没有学习，毕设做的也没有很完美，最终成绩平平毕业。</p>\n<p>进入工作，就打起精神，认真做好每一件事，学习职场的一些技能，也学习项目工程开发的一些技能，进步不少，金钱也拿了不少，还了上学期间的助学贷款，下一步期望就是挣更多的钱、学更多的知识，掌握更多的技能。</p>\n<h2 id=\"2021\"><a href=\"#2021\" class=\"headerlink\" title=\"2021\"></a>2021</h2><p>目标：</p>\n<p>1.整理之前的博客，将内容补充完成，条理清楚。</p>\n<p>2.输出新的博客，虚拟网络相关。</p>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li><b>电子邮箱</b><br><a href=\"mailto:1409026014@qq.com\" target=\"_blank\" rel=\"noopener\">1409026014@qq.com</a></li>\n<li><b>微信</b><br>yteng3456</li>\n</ul>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<h2 id=\"2019\"><a href=\"#2019\" class=\"headerlink\" title=\"2019\"></a>2019</h2><p>首先，我的第一个网站是<code>www.yteng3456.xyz</code>，这是一个基于ThinkPHP5.0框架搭建的个人博客，具有完整的前后端，功能还算齐全，但是因为现在域名到期，云虚拟主机到期，经费不足以支持。</p>\n<p>所以我找到了Github + Hexo 的搭建方式。有了前面的搭建经验，也很容易上手了Hexo，没有数据库的加持，虽然少了几分技术特色，但是更快的提交静态页面也未尝不可。</p>\n<p>以后，我将永久使用此网站作为自己的发源地，继续前行。</p>\n<p><code>https://xiaoyixiaoyang.github.io/</code></p>\n<h2 id=\"2020\"><a href=\"#2020\" class=\"headerlink\" title=\"2020\"></a>2020</h2><p>这一年博客输出量很少，原因是前一年在准备求职，所以重新读了很多书，把书上的重要内容都做了笔记，虽然笔记做的不好，但是对自己也还算有些帮助。</p>\n<p>疫情期间也是浪费了很多时间，在家没有学习，毕设做的也没有很完美，最终成绩平平毕业。</p>\n<p>进入工作，就打起精神，认真做好每一件事，学习职场的一些技能，也学习项目工程开发的一些技能，进步不少，金钱也拿了不少，还了上学期间的助学贷款，下一步期望就是挣更多的钱、学更多的知识，掌握更多的技能。</p>\n<h2 id=\"2021\"><a href=\"#2021\" class=\"headerlink\" title=\"2021\"></a>2021</h2><p>目标：</p>\n<p>1.整理之前的博客，将内容补充完成，条理清楚。</p>\n<p>2.输出新的博客，虚拟网络相关。</p>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li><b>电子邮箱</b><br><a href=\"mailto:1409026014@qq.com\" target=\"_blank\" rel=\"noopener\">1409026014@qq.com</a></li>\n<li><b>微信</b><br>yteng3456</li>\n</ul>\n"},{"title":"archives","date":"2019-07-19T08:39:20.000Z","type":"archives","layout":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-07-19 16:39:20\ntype: \"archives\"\nlayout: \"archives\"\n---","updated":"2022-05-22T02:13:17.363Z","path":"archives/index.html","comments":1,"_id":"clg8yre9h0003agvto24y8bi8","content":"<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":""},{"title":"categories","date":"2019-07-19T08:39:20.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-07-19 16:39:20\ntype: \"categories\"\nlayout: \"categories\"\n---","updated":"2022-05-22T02:13:17.374Z","path":"categories/index.html","comments":1,"_id":"clg8yre9h0007agvt98w5rltt","content":"<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":""},{"title":"friends","date":"2019-07-19T08:42:10.000Z","type":"friends","layout":"friends","_content":"\n# 友链\n格式\n* **名称：**博客名称\n* **地址：**博客地址\n* **简介：**一句话简介\n* **头像：**头像地址\n\n参考博客的友链：\n* **名称：**godweiyang\n* **地址：**https://godweiyang.com\n* **简介：**公众号【算法码上来】，分享深度学习与NLP算法\n* **头像：**https://godweiyang.com/medias/avatars/avatar.jpg\n","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2019-07-19 16:42:10\ntype: \"friends\"\nlayout: \"friends\"\n---\n\n# 友链\n格式\n* **名称：**博客名称\n* **地址：**博客地址\n* **简介：**一句话简介\n* **头像：**头像地址\n\n参考博客的友链：\n* **名称：**godweiyang\n* **地址：**https://godweiyang.com\n* **简介：**公众号【算法码上来】，分享深度学习与NLP算法\n* **头像：**https://godweiyang.com/medias/avatars/avatar.jpg\n","updated":"2022-05-22T04:49:41.789Z","path":"friends/index.html","comments":1,"_id":"clg8yre9h0009agvtxfmtp37p","content":"<h1 id=\"友链\"><a href=\"#友链\" class=\"headerlink\" title=\"友链\"></a>友链</h1><p>格式</p>\n<ul>\n<li><strong>名称：</strong>博客名称</li>\n<li><strong>地址：</strong>博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>头像地址</li>\n</ul>\n<p>参考博客的友链：</p>\n<ul>\n<li><strong>名称：</strong>godweiyang</li>\n<li><strong>地址：</strong><a href=\"https://godweiyang.com\" target=\"_blank\" rel=\"noopener\">https://godweiyang.com</a></li>\n<li><strong>简介：</strong>公众号【算法码上来】，分享深度学习与NLP算法</li>\n<li><strong>头像：</strong><a href=\"https://godweiyang.com/medias/avatars/avatar.jpg\" target=\"_blank\" rel=\"noopener\">https://godweiyang.com/medias/avatars/avatar.jpg</a></li>\n</ul>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<h1 id=\"友链\"><a href=\"#友链\" class=\"headerlink\" title=\"友链\"></a>友链</h1><p>格式</p>\n<ul>\n<li><strong>名称：</strong>博客名称</li>\n<li><strong>地址：</strong>博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>头像地址</li>\n</ul>\n<p>参考博客的友链：</p>\n<ul>\n<li><strong>名称：</strong>godweiyang</li>\n<li><strong>地址：</strong><a href=\"https://godweiyang.com\" target=\"_blank\" rel=\"noopener\">https://godweiyang.com</a></li>\n<li><strong>简介：</strong>公众号【算法码上来】，分享深度学习与NLP算法</li>\n<li><strong>头像：</strong><a href=\"https://godweiyang.com/medias/avatars/avatar.jpg\" target=\"_blank\" rel=\"noopener\">https://godweiyang.com/medias/avatars/avatar.jpg</a></li>\n</ul>\n"},{"title":"tags","date":"2019-07-19T08:40:27.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-07-19 16:40:27\ntype: \"tags\"\nlayout: \"tags\"\n---","updated":"2022-05-22T02:13:17.374Z","path":"tags/index.html","comments":1,"_id":"clg8yre9h000bagvt8fxwc06f","content":"<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":""}],"Post":[{"title":"动态规划算法详解","img":"/medias/files/algorithm-dp.jpg","summary":"动态规划三要素：重叠子问题、最优子结构、状态转移方程","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-11-27T07:32:05.000Z","password":null,"_content":"\n动态规划的核心问题是穷举，因为要求最值，肯定要把所有可行的答案都穷举出来，然后再其中找最值。\n\n首先，动态规划的问题存在**重叠子问题**，如果暴力穷举，效率会极其低下，所以需要“备忘录”或“DP table”来优化穷举过程。\n其次，动态规划的问题一定会具备**最优子结构**，这样才能通过子问题的最值得到原问题的最值\n最后，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解并不是一件容易的事情，只有列出正确的**状态转移方程**，才能正确的穷举。\n\n核心套路：状态、选择、dp数组的定义\n```\n# 初始化base case\ndp[0][0][...] = base case\n\n# 进行状态转移\nfor 状态1 in 状态1的所有取值：\n  for 状态2 in 状态2的所有取值：\n      for ...\n        dp[状态1][状态2][...] = 求最值(选择1， 选择2, ...)\n```\n\n# 经典题目\n\n## 斐波那契数列\n\n写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：\nF(0) = 0,   F(1) = 1\nF(N) = F(N - 1) + F(N - 2), 其中 N > 1.\n\n示例 1：\n输入：n = 2\n输出：1\n\n示例 2：\n输入：n = 5\n输出：5\n\n### 解答\n#### 递归：定义dp[i]为f(i)\n```golang\nfunc fib(n int) int {\n    dp := make([]int, n+1)\n    dp[0] = 0\n    dp[1] = 1\n    \n    return hepler(dp, n)\n}\n\nfunc hepler(dp []int, n int)int {\n    if n ==  0 {\n        return 0\n    }\n    if dp[n] != 0 {\n        return dp[n]\n    }\n    // 递归计算\n    dp[n] = hepler(dp, n-1) + hepler(dp, n-2)\n    return dp[n]\n}\n```\n\n#### dp table：定义dp[i]为f(i)\n```golang\nfunc fib(n int) int {\n    if n == 0 {\n        return 0\n    }\n    if n == 1{\n        return 1\n    }\n    \n    dp := make([]int, n+1)\n    // 初始化base case\n    dp[0] = 0\n    dp[1] = 1\n    \n    // 状态转移\n    for i := 2; i <= n; i++{\n        dp[i] = dp[i-1] + dp[i-2]\n    }\n\n    return dp[n]\n}\n```\n\n## 凑零钱\n给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。\n计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。\n你可以认为每种硬币的数量是无限的。\n\n示例 1：\n输入：coins = [1, 2, 5], amount = 11\n输出：3 \n解释：11 = 5 + 5 + 1\n\n示例 2：\n输入：coins = [2], amount = 3\n输出：-1\n\n示例 3：\n输入：coins = [1], amount = 0\n输出：0\n\n### 解答\n#### 递归，dp[i] = value  凑i需要最少value个硬币\n```golang\nfunc coinChange(coins []int, amount int) int {\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    return hepler(dp, coins, amount)\n}\n\nfunc hepler(dp, coins []int, amount int) int{\n    // 是否已经计算过dp[amount]\n    if amount == 0 {\n        return 0\n    }\n    if amount < 0 {\n        return -1\n    }\n    if dp[amount] != 0{\n        return dp[amount]\n    }\n\n    // 递归计算 dp[n] = min(dp(n-coin) + 1)\n    res := 100000\n    for _, coin := range coins {\n        subproblem := hepler(dp, coins, amount - coin)\n\n        // 子问题无解 跳过\n        if subproblem < 0 {\n            continue\n        }\n    \n        if subproblem < res {\n            res = 1 + subproblem\n        }\n    }\n    if res != 100000 {\n        dp[amount] = res\n    } else {\n        dp[amount] = -1\n    }\n    \n    return dp[amount]\n}\n```\n\n#### dp table，dp[i] = value  凑i需要最少value个硬币\n```golang\nfunc coinChange(coins []int, amount int) int {\n    if amount == 0 {\n        return 0\n    }\n    if amount < 0 {\n        return -1\n    }\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    for i := 1; i <= amount; i ++ {\n        // 初始化为很大\n        dp[i] = 10001\n        for _, coin := range coins {\n            if i - coin < 0 {\n                // 给的数组不一定是递增的，后面的还要测\n                continue\n            }\n            dp[i] = min(dp[i], dp[i - coin] + 1)\n        }\n    }\n\n    if dp[amount] == 10001 {\n        return -1\n    }\n\n    return dp[amount]\n}\n\nfunc min(a, b int) int {\n    if a < b {\n        return a\n    }\n\n    return b\n}\n```\n\n## 最长递增子序列\n给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。\n\n示例 1：\n输入：nums = [10,9,2,5,3,7,101,18]\n输出：4\n解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。\n\n示例 2：\n输入：nums = [0,1,0,3,2,3]\n输出：4\n\n示例 3：\n输入：nums = [7,7,7,7,7,7,7]\n输出：1\n\n### 解答\n\n#### dp table，dp[i]为表示以nums[i]为结尾的数组的最长递增子序列的长度\n```golang\nfunc lengthOfLIS(nums []int) int {\n    // dp[i] 表示以nums[i]为结尾的数组的最长递增子序列的长度\n    // 那么 dp[i] = 遍历小于i的dp[i-1]，当nums[i] > nums[i-1]  就加1\n    dp := make([]int, len(nums))\n    // 初始化数组的最大子序列长度\n    ret := -1\n    for i := 0; i < len(nums); i ++ {\n        // 初始化dp 每个位置 最长子序列至少是1\n        dp[i] = 1\n        // 计算dp[i]\n        for j := 0; j < i; j ++ {\n            if nums[i] > nums[j] {\n                dp[i] = max(dp[i], dp[j] + 1)\n            }\n        }\n        ret = max(ret, dp[i])\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a > b {\n        return a\n    }\n    return b\n}\n```\n\n## 最大子数组\n\n给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n子数组 是数组中的一个连续部分。\n\n示例 1：\n输入：nums = [-2,1,-3,4,-1,2,1,-5,4]\n输出：6\n解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。\n\n示例 2：\n输入：nums = [1]\n输出：1\n\n示例 3：\n输入：nums = [5,4,-1,7,8]\n输出：23\n\n### 解答\n\n#### dp table, dp[i]为以nums[i]结尾的最大子数组和\n```golang\nfunc maxSubArray(nums []int) int {\n    if len(nums) <= 0 {\n        return -1\n    }\n    // 定义dp数组，dp[i]为以nums[i]结尾的最大子数组和\n    dp := make([]int, len(nums))\n    dp[0] = nums[0]\n    ret := dp[0]\n    \n    // 状态转移\n    for i := 1; i < len(nums); i ++ {\n        dp[i] = max(nums[i], dp[i-1] + nums[i])\n        ret = max(ret, dp[i])  \n    }\n\n    return ret\n}\n\nfunc max(a, b int) int {\n    if a > b {\n        return a\n    }\n    return b\n}\n```\n\n## 最长公共子序列\n\n给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0 。\n一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。\n例如，\"ace\" 是 \"abcde\" 的子序列，但 \"aec\" 不是 \"abcde\" 的子序列。\n两个字符串的 公共子序列 是这两个字符串所共同拥有的子序列。\n\n示例 1：\n输入：text1 = \"abcde\", text2 = \"ace\" \n输出：3  \n解释：最长公共子序列是 \"ace\" ，它的长度为 3 。\n\n示例 2：\n输入：text1 = \"abc\", text2 = \"abc\"\n输出：3\n解释：最长公共子序列是 \"abc\" ，它的长度为 3 。\n\n示例 3：\n输入：text1 = \"abc\", text2 = \"def\"\n输出：0\n解释：两个字符串没有公共子序列，返回 0 。\n\n### 解答\n\n#### dp table，dp[i][j]为str1[0:i]和str2[0:j]最长公共子序列的长度\n```golang\nfunc longestCommonSubsequence(text1 string, text2 string) int {\n    if len(text1) == 0 || len(text2) == 0 {\n        return 0\n    }\n    // dp[i][j] 为text1[0:i] 和 text2[0:j]的最长公共自序列\n    // 默认初始化零\n    dp := make([][]int, (len(text1)+1))\n    for i := range dp {\n        dp[i] = make([]int, (len(text2)+1))\n    }\n\n    ret := -1\n    // 状态转移， 用dp[i+1][j+1]来替换dp[i][j]\n    for i := 0; i < len(text1); i ++ {\n        for j := 0; j < len(text2); j ++ {\n            if text1[i] == text2[j] {\n                // 相同 则等于text1[0:i] 和 text2[0:j]的公共子序列长度+1\n                dp[i+1][j+1] = dp[i][j] + 1\n            }else {\n                // 不相同则等于text1[0:i-1] 和 text2[0:j]中的公共子序列长度\n                // 与 text1[0:i] 和 text2[0:j-1]公共子序列长度较大的\n                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])\n            }\n            ret = max(ret, dp[i+1][j+1])\n       }\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a > b {\n        return a\n    }\n    return b\n}\n```\n\n## 编辑距离\n\n\n\n\n## 以插入最小次数构造回文串\n\n","source":"_posts/algorithm-dp.md","raw":"---\ntitle: 动态规划算法详解\nimg: /medias/files/algorithm-dp.jpg\nsummary: 动态规划三要素：重叠子问题、最优子结构、状态转移方程\ntags:\n  - 博客\n  - 算法\n  - 动态规划\ncategories:\n  - 随笔\n  - 算法\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-11-27 15:32:05\npassword:\n---\n\n动态规划的核心问题是穷举，因为要求最值，肯定要把所有可行的答案都穷举出来，然后再其中找最值。\n\n首先，动态规划的问题存在**重叠子问题**，如果暴力穷举，效率会极其低下，所以需要“备忘录”或“DP table”来优化穷举过程。\n其次，动态规划的问题一定会具备**最优子结构**，这样才能通过子问题的最值得到原问题的最值\n最后，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解并不是一件容易的事情，只有列出正确的**状态转移方程**，才能正确的穷举。\n\n核心套路：状态、选择、dp数组的定义\n```\n# 初始化base case\ndp[0][0][...] = base case\n\n# 进行状态转移\nfor 状态1 in 状态1的所有取值：\n  for 状态2 in 状态2的所有取值：\n      for ...\n        dp[状态1][状态2][...] = 求最值(选择1， 选择2, ...)\n```\n\n# 经典题目\n\n## 斐波那契数列\n\n写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：\nF(0) = 0,   F(1) = 1\nF(N) = F(N - 1) + F(N - 2), 其中 N > 1.\n\n示例 1：\n输入：n = 2\n输出：1\n\n示例 2：\n输入：n = 5\n输出：5\n\n### 解答\n#### 递归：定义dp[i]为f(i)\n```golang\nfunc fib(n int) int {\n    dp := make([]int, n+1)\n    dp[0] = 0\n    dp[1] = 1\n    \n    return hepler(dp, n)\n}\n\nfunc hepler(dp []int, n int)int {\n    if n ==  0 {\n        return 0\n    }\n    if dp[n] != 0 {\n        return dp[n]\n    }\n    // 递归计算\n    dp[n] = hepler(dp, n-1) + hepler(dp, n-2)\n    return dp[n]\n}\n```\n\n#### dp table：定义dp[i]为f(i)\n```golang\nfunc fib(n int) int {\n    if n == 0 {\n        return 0\n    }\n    if n == 1{\n        return 1\n    }\n    \n    dp := make([]int, n+1)\n    // 初始化base case\n    dp[0] = 0\n    dp[1] = 1\n    \n    // 状态转移\n    for i := 2; i <= n; i++{\n        dp[i] = dp[i-1] + dp[i-2]\n    }\n\n    return dp[n]\n}\n```\n\n## 凑零钱\n给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。\n计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。\n你可以认为每种硬币的数量是无限的。\n\n示例 1：\n输入：coins = [1, 2, 5], amount = 11\n输出：3 \n解释：11 = 5 + 5 + 1\n\n示例 2：\n输入：coins = [2], amount = 3\n输出：-1\n\n示例 3：\n输入：coins = [1], amount = 0\n输出：0\n\n### 解答\n#### 递归，dp[i] = value  凑i需要最少value个硬币\n```golang\nfunc coinChange(coins []int, amount int) int {\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    return hepler(dp, coins, amount)\n}\n\nfunc hepler(dp, coins []int, amount int) int{\n    // 是否已经计算过dp[amount]\n    if amount == 0 {\n        return 0\n    }\n    if amount < 0 {\n        return -1\n    }\n    if dp[amount] != 0{\n        return dp[amount]\n    }\n\n    // 递归计算 dp[n] = min(dp(n-coin) + 1)\n    res := 100000\n    for _, coin := range coins {\n        subproblem := hepler(dp, coins, amount - coin)\n\n        // 子问题无解 跳过\n        if subproblem < 0 {\n            continue\n        }\n    \n        if subproblem < res {\n            res = 1 + subproblem\n        }\n    }\n    if res != 100000 {\n        dp[amount] = res\n    } else {\n        dp[amount] = -1\n    }\n    \n    return dp[amount]\n}\n```\n\n#### dp table，dp[i] = value  凑i需要最少value个硬币\n```golang\nfunc coinChange(coins []int, amount int) int {\n    if amount == 0 {\n        return 0\n    }\n    if amount < 0 {\n        return -1\n    }\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    for i := 1; i <= amount; i ++ {\n        // 初始化为很大\n        dp[i] = 10001\n        for _, coin := range coins {\n            if i - coin < 0 {\n                // 给的数组不一定是递增的，后面的还要测\n                continue\n            }\n            dp[i] = min(dp[i], dp[i - coin] + 1)\n        }\n    }\n\n    if dp[amount] == 10001 {\n        return -1\n    }\n\n    return dp[amount]\n}\n\nfunc min(a, b int) int {\n    if a < b {\n        return a\n    }\n\n    return b\n}\n```\n\n## 最长递增子序列\n给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。\n\n示例 1：\n输入：nums = [10,9,2,5,3,7,101,18]\n输出：4\n解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。\n\n示例 2：\n输入：nums = [0,1,0,3,2,3]\n输出：4\n\n示例 3：\n输入：nums = [7,7,7,7,7,7,7]\n输出：1\n\n### 解答\n\n#### dp table，dp[i]为表示以nums[i]为结尾的数组的最长递增子序列的长度\n```golang\nfunc lengthOfLIS(nums []int) int {\n    // dp[i] 表示以nums[i]为结尾的数组的最长递增子序列的长度\n    // 那么 dp[i] = 遍历小于i的dp[i-1]，当nums[i] > nums[i-1]  就加1\n    dp := make([]int, len(nums))\n    // 初始化数组的最大子序列长度\n    ret := -1\n    for i := 0; i < len(nums); i ++ {\n        // 初始化dp 每个位置 最长子序列至少是1\n        dp[i] = 1\n        // 计算dp[i]\n        for j := 0; j < i; j ++ {\n            if nums[i] > nums[j] {\n                dp[i] = max(dp[i], dp[j] + 1)\n            }\n        }\n        ret = max(ret, dp[i])\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a > b {\n        return a\n    }\n    return b\n}\n```\n\n## 最大子数组\n\n给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n子数组 是数组中的一个连续部分。\n\n示例 1：\n输入：nums = [-2,1,-3,4,-1,2,1,-5,4]\n输出：6\n解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。\n\n示例 2：\n输入：nums = [1]\n输出：1\n\n示例 3：\n输入：nums = [5,4,-1,7,8]\n输出：23\n\n### 解答\n\n#### dp table, dp[i]为以nums[i]结尾的最大子数组和\n```golang\nfunc maxSubArray(nums []int) int {\n    if len(nums) <= 0 {\n        return -1\n    }\n    // 定义dp数组，dp[i]为以nums[i]结尾的最大子数组和\n    dp := make([]int, len(nums))\n    dp[0] = nums[0]\n    ret := dp[0]\n    \n    // 状态转移\n    for i := 1; i < len(nums); i ++ {\n        dp[i] = max(nums[i], dp[i-1] + nums[i])\n        ret = max(ret, dp[i])  \n    }\n\n    return ret\n}\n\nfunc max(a, b int) int {\n    if a > b {\n        return a\n    }\n    return b\n}\n```\n\n## 最长公共子序列\n\n给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0 。\n一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。\n例如，\"ace\" 是 \"abcde\" 的子序列，但 \"aec\" 不是 \"abcde\" 的子序列。\n两个字符串的 公共子序列 是这两个字符串所共同拥有的子序列。\n\n示例 1：\n输入：text1 = \"abcde\", text2 = \"ace\" \n输出：3  \n解释：最长公共子序列是 \"ace\" ，它的长度为 3 。\n\n示例 2：\n输入：text1 = \"abc\", text2 = \"abc\"\n输出：3\n解释：最长公共子序列是 \"abc\" ，它的长度为 3 。\n\n示例 3：\n输入：text1 = \"abc\", text2 = \"def\"\n输出：0\n解释：两个字符串没有公共子序列，返回 0 。\n\n### 解答\n\n#### dp table，dp[i][j]为str1[0:i]和str2[0:j]最长公共子序列的长度\n```golang\nfunc longestCommonSubsequence(text1 string, text2 string) int {\n    if len(text1) == 0 || len(text2) == 0 {\n        return 0\n    }\n    // dp[i][j] 为text1[0:i] 和 text2[0:j]的最长公共自序列\n    // 默认初始化零\n    dp := make([][]int, (len(text1)+1))\n    for i := range dp {\n        dp[i] = make([]int, (len(text2)+1))\n    }\n\n    ret := -1\n    // 状态转移， 用dp[i+1][j+1]来替换dp[i][j]\n    for i := 0; i < len(text1); i ++ {\n        for j := 0; j < len(text2); j ++ {\n            if text1[i] == text2[j] {\n                // 相同 则等于text1[0:i] 和 text2[0:j]的公共子序列长度+1\n                dp[i+1][j+1] = dp[i][j] + 1\n            }else {\n                // 不相同则等于text1[0:i-1] 和 text2[0:j]中的公共子序列长度\n                // 与 text1[0:i] 和 text2[0:j-1]公共子序列长度较大的\n                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])\n            }\n            ret = max(ret, dp[i+1][j+1])\n       }\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a > b {\n        return a\n    }\n    return b\n}\n```\n\n## 编辑距离\n\n\n\n\n## 以插入最小次数构造回文串\n\n","slug":"algorithm-dp","published":1,"updated":"2023-02-05T03:28:26.612Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre920002agvtfhggbhzy","content":"<p>动态规划的核心问题是穷举，因为要求最值，肯定要把所有可行的答案都穷举出来，然后再其中找最值。</p>\n<p>首先，动态规划的问题存在<strong>重叠子问题</strong>，如果暴力穷举，效率会极其低下，所以需要“备忘录”或“DP table”来优化穷举过程。<br>其次，动态规划的问题一定会具备<strong>最优子结构</strong>，这样才能通过子问题的最值得到原问题的最值<br>最后，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解并不是一件容易的事情，只有列出正确的<strong>状态转移方程</strong>，才能正确的穷举。</p>\n<p>核心套路：状态、选择、dp数组的定义</p>\n<pre><code># 初始化base case\ndp[0][0][...] = base case\n\n# 进行状态转移\nfor 状态1 in 状态1的所有取值：\n  for 状态2 in 状态2的所有取值：\n      for ...\n        dp[状态1][状态2][...] = 求最值(选择1， 选择2, ...)</code></pre><h1 id=\"经典题目\"><a href=\"#经典题目\" class=\"headerlink\" title=\"经典题目\"></a>经典题目</h1><h2 id=\"斐波那契数列\"><a href=\"#斐波那契数列\" class=\"headerlink\" title=\"斐波那契数列\"></a>斐波那契数列</h2><p>写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：<br>F(0) = 0,   F(1) = 1<br>F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.</p>\n<p>示例 1：<br>输入：n = 2<br>输出：1</p>\n<p>示例 2：<br>输入：n = 5<br>输出：5</p>\n<h3 id=\"解答\"><a href=\"#解答\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"递归：定义dp-i-为f-i\"><a href=\"#递归：定义dp-i-为f-i\" class=\"headerlink\" title=\"递归：定义dp[i]为f(i)\"></a>递归：定义dp[i]为f(i)</h4><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">func fib(n int) int {\n    dp := make([]int, n+1)\n    dp[0] = 0\n    dp[1] = 1\n\n    return hepler(dp, n)\n}\n\nfunc hepler(dp []int, n int)int {\n    if n ==  0 {\n        return 0\n    }\n    if dp[n] != 0 {\n        return dp[n]\n    }\n    // 递归计算\n    dp[n] = hepler(dp, n-1) + hepler(dp, n-2)\n    return dp[n]\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"dp-table：定义dp-i-为f-i\"><a href=\"#dp-table：定义dp-i-为f-i\" class=\"headerlink\" title=\"dp table：定义dp[i]为f(i)\"></a>dp table：定义dp[i]为f(i)</h4><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">func fib(n int) int {\n    if n == 0 {\n        return 0\n    }\n    if n == 1{\n        return 1\n    }\n\n    dp := make([]int, n+1)\n    // 初始化base case\n    dp[0] = 0\n    dp[1] = 1\n\n    // 状态转移\n    for i := 2; i <= n; i++{\n        dp[i] = dp[i-1] + dp[i-2]\n    }\n\n    return dp[n]\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"凑零钱\"><a href=\"#凑零钱\" class=\"headerlink\" title=\"凑零钱\"></a>凑零钱</h2><p>给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。<br>计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。<br>你可以认为每种硬币的数量是无限的。</p>\n<p>示例 1：<br>输入：coins = [1, 2, 5], amount = 11<br>输出：3<br>解释：11 = 5 + 5 + 1</p>\n<p>示例 2：<br>输入：coins = [2], amount = 3<br>输出：-1</p>\n<p>示例 3：<br>输入：coins = [1], amount = 0<br>输出：0</p>\n<h3 id=\"解答-1\"><a href=\"#解答-1\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"递归，dp-i-value-凑i需要最少value个硬币\"><a href=\"#递归，dp-i-value-凑i需要最少value个硬币\" class=\"headerlink\" title=\"递归，dp[i] = value  凑i需要最少value个硬币\"></a>递归，dp[i] = value  凑i需要最少value个硬币</h4><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">func coinChange(coins []int, amount int) int {\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    return hepler(dp, coins, amount)\n}\n\nfunc hepler(dp, coins []int, amount int) int{\n    // 是否已经计算过dp[amount]\n    if amount == 0 {\n        return 0\n    }\n    if amount < 0 {\n        return -1\n    }\n    if dp[amount] != 0{\n        return dp[amount]\n    }\n\n    // 递归计算 dp[n] = min(dp(n-coin) + 1)\n    res := 100000\n    for _, coin := range coins {\n        subproblem := hepler(dp, coins, amount - coin)\n\n        // 子问题无解 跳过\n        if subproblem < 0 {\n            continue\n        }\n\n        if subproblem < res {\n            res = 1 + subproblem\n        }\n    }\n    if res != 100000 {\n        dp[amount] = res\n    } else {\n        dp[amount] = -1\n    }\n\n    return dp[amount]\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"dp-table，dp-i-value-凑i需要最少value个硬币\"><a href=\"#dp-table，dp-i-value-凑i需要最少value个硬币\" class=\"headerlink\" title=\"dp table，dp[i] = value  凑i需要最少value个硬币\"></a>dp table，dp[i] = value  凑i需要最少value个硬币</h4><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">func coinChange(coins []int, amount int) int {\n    if amount == 0 {\n        return 0\n    }\n    if amount < 0 {\n        return -1\n    }\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    for i := 1; i <= amount; i ++ {\n        // 初始化为很大\n        dp[i] = 10001\n        for _, coin := range coins {\n            if i - coin < 0 {\n                // 给的数组不一定是递增的，后面的还要测\n                continue\n            }\n            dp[i] = min(dp[i], dp[i - coin] + 1)\n        }\n    }\n\n    if dp[amount] == 10001 {\n        return -1\n    }\n\n    return dp[amount]\n}\n\nfunc min(a, b int) int {\n    if a < b {\n        return a\n    }\n\n    return b\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"最长递增子序列\"><a href=\"#最长递增子序列\" class=\"headerlink\" title=\"最长递增子序列\"></a>最长递增子序列</h2><p>给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。<br>子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。</p>\n<p>示例 1：<br>输入：nums = [10,9,2,5,3,7,101,18]<br>输出：4<br>解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。</p>\n<p>示例 2：<br>输入：nums = [0,1,0,3,2,3]<br>输出：4</p>\n<p>示例 3：<br>输入：nums = [7,7,7,7,7,7,7]<br>输出：1</p>\n<h3 id=\"解答-2\"><a href=\"#解答-2\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"dp-table，dp-i-为表示以nums-i-为结尾的数组的最长递增子序列的长度\"><a href=\"#dp-table，dp-i-为表示以nums-i-为结尾的数组的最长递增子序列的长度\" class=\"headerlink\" title=\"dp table，dp[i]为表示以nums[i]为结尾的数组的最长递增子序列的长度\"></a>dp table，dp[i]为表示以nums[i]为结尾的数组的最长递增子序列的长度</h4><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">func lengthOfLIS(nums []int) int {\n    // dp[i] 表示以nums[i]为结尾的数组的最长递增子序列的长度\n    // 那么 dp[i] = 遍历小于i的dp[i-1]，当nums[i] > nums[i-1]  就加1\n    dp := make([]int, len(nums))\n    // 初始化数组的最大子序列长度\n    ret := -1\n    for i := 0; i < len(nums); i ++ {\n        // 初始化dp 每个位置 最长子序列至少是1\n        dp[i] = 1\n        // 计算dp[i]\n        for j := 0; j < i; j ++ {\n            if nums[i] > nums[j] {\n                dp[i] = max(dp[i], dp[j] + 1)\n            }\n        }\n        ret = max(ret, dp[i])\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a > b {\n        return a\n    }\n    return b\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"最大子数组\"><a href=\"#最大子数组\" class=\"headerlink\" title=\"最大子数组\"></a>最大子数组</h2><p>给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。<br>子数组 是数组中的一个连续部分。</p>\n<p>示例 1：<br>输入：nums = [-2,1,-3,4,-1,2,1,-5,4]<br>输出：6<br>解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。</p>\n<p>示例 2：<br>输入：nums = [1]<br>输出：1</p>\n<p>示例 3：<br>输入：nums = [5,4,-1,7,8]<br>输出：23</p>\n<h3 id=\"解答-3\"><a href=\"#解答-3\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"dp-table-dp-i-为以nums-i-结尾的最大子数组和\"><a href=\"#dp-table-dp-i-为以nums-i-结尾的最大子数组和\" class=\"headerlink\" title=\"dp table, dp[i]为以nums[i]结尾的最大子数组和\"></a>dp table, dp[i]为以nums[i]结尾的最大子数组和</h4><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">func maxSubArray(nums []int) int {\n    if len(nums) <= 0 {\n        return -1\n    }\n    // 定义dp数组，dp[i]为以nums[i]结尾的最大子数组和\n    dp := make([]int, len(nums))\n    dp[0] = nums[0]\n    ret := dp[0]\n\n    // 状态转移\n    for i := 1; i < len(nums); i ++ {\n        dp[i] = max(nums[i], dp[i-1] + nums[i])\n        ret = max(ret, dp[i])  \n    }\n\n    return ret\n}\n\nfunc max(a, b int) int {\n    if a > b {\n        return a\n    }\n    return b\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"最长公共子序列\"><a href=\"#最长公共子序列\" class=\"headerlink\" title=\"最长公共子序列\"></a>最长公共子序列</h2><p>给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0 。<br>一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。<br>例如，”ace” 是 “abcde” 的子序列，但 “aec” 不是 “abcde” 的子序列。<br>两个字符串的 公共子序列 是这两个字符串所共同拥有的子序列。</p>\n<p>示例 1：<br>输入：text1 = “abcde”, text2 = “ace”<br>输出：3<br>解释：最长公共子序列是 “ace” ，它的长度为 3 。</p>\n<p>示例 2：<br>输入：text1 = “abc”, text2 = “abc”<br>输出：3<br>解释：最长公共子序列是 “abc” ，它的长度为 3 。</p>\n<p>示例 3：<br>输入：text1 = “abc”, text2 = “def”<br>输出：0<br>解释：两个字符串没有公共子序列，返回 0 。</p>\n<h3 id=\"解答-4\"><a href=\"#解答-4\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"dp-table，dp-i-j-为str1-0-i-和str2-0-j-最长公共子序列的长度\"><a href=\"#dp-table，dp-i-j-为str1-0-i-和str2-0-j-最长公共子序列的长度\" class=\"headerlink\" title=\"dp table，dp[i][j]为str1[0:i]和str2[0:j]最长公共子序列的长度\"></a>dp table，dp[i][j]为str1[0:i]和str2[0:j]最长公共子序列的长度</h4><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">func longestCommonSubsequence(text1 string, text2 string) int {\n    if len(text1) == 0 || len(text2) == 0 {\n        return 0\n    }\n    // dp[i][j] 为text1[0:i] 和 text2[0:j]的最长公共自序列\n    // 默认初始化零\n    dp := make([][]int, (len(text1)+1))\n    for i := range dp {\n        dp[i] = make([]int, (len(text2)+1))\n    }\n\n    ret := -1\n    // 状态转移， 用dp[i+1][j+1]来替换dp[i][j]\n    for i := 0; i < len(text1); i ++ {\n        for j := 0; j < len(text2); j ++ {\n            if text1[i] == text2[j] {\n                // 相同 则等于text1[0:i] 和 text2[0:j]的公共子序列长度+1\n                dp[i+1][j+1] = dp[i][j] + 1\n            }else {\n                // 不相同则等于text1[0:i-1] 和 text2[0:j]中的公共子序列长度\n                // 与 text1[0:i] 和 text2[0:j-1]公共子序列长度较大的\n                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])\n            }\n            ret = max(ret, dp[i+1][j+1])\n       }\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a > b {\n        return a\n    }\n    return b\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"编辑距离\"><a href=\"#编辑距离\" class=\"headerlink\" title=\"编辑距离\"></a>编辑距离</h2><h2 id=\"以插入最小次数构造回文串\"><a href=\"#以插入最小次数构造回文串\" class=\"headerlink\" title=\"以插入最小次数构造回文串\"></a>以插入最小次数构造回文串</h2><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<p>动态规划的核心问题是穷举，因为要求最值，肯定要把所有可行的答案都穷举出来，然后再其中找最值。</p>\n<p>首先，动态规划的问题存在<strong>重叠子问题</strong>，如果暴力穷举，效率会极其低下，所以需要“备忘录”或“DP table”来优化穷举过程。<br>其次，动态规划的问题一定会具备<strong>最优子结构</strong>，这样才能通过子问题的最值得到原问题的最值<br>最后，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解并不是一件容易的事情，只有列出正确的<strong>状态转移方程</strong>，才能正确的穷举。</p>\n<p>核心套路：状态、选择、dp数组的定义</p>\n<pre><code># 初始化base case\ndp[0][0][...] = base case\n\n# 进行状态转移\nfor 状态1 in 状态1的所有取值：\n  for 状态2 in 状态2的所有取值：\n      for ...\n        dp[状态1][状态2][...] = 求最值(选择1， 选择2, ...)</code></pre><h1 id=\"经典题目\"><a href=\"#经典题目\" class=\"headerlink\" title=\"经典题目\"></a>经典题目</h1><h2 id=\"斐波那契数列\"><a href=\"#斐波那契数列\" class=\"headerlink\" title=\"斐波那契数列\"></a>斐波那契数列</h2><p>写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：<br>F(0) = 0,   F(1) = 1<br>F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.</p>\n<p>示例 1：<br>输入：n = 2<br>输出：1</p>\n<p>示例 2：<br>输入：n = 5<br>输出：5</p>\n<h3 id=\"解答\"><a href=\"#解答\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"递归：定义dp-i-为f-i\"><a href=\"#递归：定义dp-i-为f-i\" class=\"headerlink\" title=\"递归：定义dp[i]为f(i)\"></a>递归：定义dp[i]为f(i)</h4><pre><code class=\"golang\">func fib(n int) int {\n    dp := make([]int, n+1)\n    dp[0] = 0\n    dp[1] = 1\n\n    return hepler(dp, n)\n}\n\nfunc hepler(dp []int, n int)int {\n    if n ==  0 {\n        return 0\n    }\n    if dp[n] != 0 {\n        return dp[n]\n    }\n    // 递归计算\n    dp[n] = hepler(dp, n-1) + hepler(dp, n-2)\n    return dp[n]\n}</code></pre>\n<h4 id=\"dp-table：定义dp-i-为f-i\"><a href=\"#dp-table：定义dp-i-为f-i\" class=\"headerlink\" title=\"dp table：定义dp[i]为f(i)\"></a>dp table：定义dp[i]为f(i)</h4><pre><code class=\"golang\">func fib(n int) int {\n    if n == 0 {\n        return 0\n    }\n    if n == 1{\n        return 1\n    }\n\n    dp := make([]int, n+1)\n    // 初始化base case\n    dp[0] = 0\n    dp[1] = 1\n\n    // 状态转移\n    for i := 2; i &lt;= n; i++{\n        dp[i] = dp[i-1] + dp[i-2]\n    }\n\n    return dp[n]\n}</code></pre>\n<h2 id=\"凑零钱\"><a href=\"#凑零钱\" class=\"headerlink\" title=\"凑零钱\"></a>凑零钱</h2><p>给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。<br>计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。<br>你可以认为每种硬币的数量是无限的。</p>\n<p>示例 1：<br>输入：coins = [1, 2, 5], amount = 11<br>输出：3<br>解释：11 = 5 + 5 + 1</p>\n<p>示例 2：<br>输入：coins = [2], amount = 3<br>输出：-1</p>\n<p>示例 3：<br>输入：coins = [1], amount = 0<br>输出：0</p>\n<h3 id=\"解答-1\"><a href=\"#解答-1\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"递归，dp-i-value-凑i需要最少value个硬币\"><a href=\"#递归，dp-i-value-凑i需要最少value个硬币\" class=\"headerlink\" title=\"递归，dp[i] = value  凑i需要最少value个硬币\"></a>递归，dp[i] = value  凑i需要最少value个硬币</h4><pre><code class=\"golang\">func coinChange(coins []int, amount int) int {\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    return hepler(dp, coins, amount)\n}\n\nfunc hepler(dp, coins []int, amount int) int{\n    // 是否已经计算过dp[amount]\n    if amount == 0 {\n        return 0\n    }\n    if amount &lt; 0 {\n        return -1\n    }\n    if dp[amount] != 0{\n        return dp[amount]\n    }\n\n    // 递归计算 dp[n] = min(dp(n-coin) + 1)\n    res := 100000\n    for _, coin := range coins {\n        subproblem := hepler(dp, coins, amount - coin)\n\n        // 子问题无解 跳过\n        if subproblem &lt; 0 {\n            continue\n        }\n\n        if subproblem &lt; res {\n            res = 1 + subproblem\n        }\n    }\n    if res != 100000 {\n        dp[amount] = res\n    } else {\n        dp[amount] = -1\n    }\n\n    return dp[amount]\n}</code></pre>\n<h4 id=\"dp-table，dp-i-value-凑i需要最少value个硬币\"><a href=\"#dp-table，dp-i-value-凑i需要最少value个硬币\" class=\"headerlink\" title=\"dp table，dp[i] = value  凑i需要最少value个硬币\"></a>dp table，dp[i] = value  凑i需要最少value个硬币</h4><pre><code class=\"golang\">func coinChange(coins []int, amount int) int {\n    if amount == 0 {\n        return 0\n    }\n    if amount &lt; 0 {\n        return -1\n    }\n    // 初始化dp数组  dp[i] = value  凑i需要最少value个硬币\n    dp := make([]int, amount + 1)\n    dp[0] = 0\n\n    for i := 1; i &lt;= amount; i ++ {\n        // 初始化为很大\n        dp[i] = 10001\n        for _, coin := range coins {\n            if i - coin &lt; 0 {\n                // 给的数组不一定是递增的，后面的还要测\n                continue\n            }\n            dp[i] = min(dp[i], dp[i - coin] + 1)\n        }\n    }\n\n    if dp[amount] == 10001 {\n        return -1\n    }\n\n    return dp[amount]\n}\n\nfunc min(a, b int) int {\n    if a &lt; b {\n        return a\n    }\n\n    return b\n}</code></pre>\n<h2 id=\"最长递增子序列\"><a href=\"#最长递增子序列\" class=\"headerlink\" title=\"最长递增子序列\"></a>最长递增子序列</h2><p>给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。<br>子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。</p>\n<p>示例 1：<br>输入：nums = [10,9,2,5,3,7,101,18]<br>输出：4<br>解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。</p>\n<p>示例 2：<br>输入：nums = [0,1,0,3,2,3]<br>输出：4</p>\n<p>示例 3：<br>输入：nums = [7,7,7,7,7,7,7]<br>输出：1</p>\n<h3 id=\"解答-2\"><a href=\"#解答-2\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"dp-table，dp-i-为表示以nums-i-为结尾的数组的最长递增子序列的长度\"><a href=\"#dp-table，dp-i-为表示以nums-i-为结尾的数组的最长递增子序列的长度\" class=\"headerlink\" title=\"dp table，dp[i]为表示以nums[i]为结尾的数组的最长递增子序列的长度\"></a>dp table，dp[i]为表示以nums[i]为结尾的数组的最长递增子序列的长度</h4><pre><code class=\"golang\">func lengthOfLIS(nums []int) int {\n    // dp[i] 表示以nums[i]为结尾的数组的最长递增子序列的长度\n    // 那么 dp[i] = 遍历小于i的dp[i-1]，当nums[i] &gt; nums[i-1]  就加1\n    dp := make([]int, len(nums))\n    // 初始化数组的最大子序列长度\n    ret := -1\n    for i := 0; i &lt; len(nums); i ++ {\n        // 初始化dp 每个位置 最长子序列至少是1\n        dp[i] = 1\n        // 计算dp[i]\n        for j := 0; j &lt; i; j ++ {\n            if nums[i] &gt; nums[j] {\n                dp[i] = max(dp[i], dp[j] + 1)\n            }\n        }\n        ret = max(ret, dp[i])\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a &gt; b {\n        return a\n    }\n    return b\n}</code></pre>\n<h2 id=\"最大子数组\"><a href=\"#最大子数组\" class=\"headerlink\" title=\"最大子数组\"></a>最大子数组</h2><p>给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。<br>子数组 是数组中的一个连续部分。</p>\n<p>示例 1：<br>输入：nums = [-2,1,-3,4,-1,2,1,-5,4]<br>输出：6<br>解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。</p>\n<p>示例 2：<br>输入：nums = [1]<br>输出：1</p>\n<p>示例 3：<br>输入：nums = [5,4,-1,7,8]<br>输出：23</p>\n<h3 id=\"解答-3\"><a href=\"#解答-3\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"dp-table-dp-i-为以nums-i-结尾的最大子数组和\"><a href=\"#dp-table-dp-i-为以nums-i-结尾的最大子数组和\" class=\"headerlink\" title=\"dp table, dp[i]为以nums[i]结尾的最大子数组和\"></a>dp table, dp[i]为以nums[i]结尾的最大子数组和</h4><pre><code class=\"golang\">func maxSubArray(nums []int) int {\n    if len(nums) &lt;= 0 {\n        return -1\n    }\n    // 定义dp数组，dp[i]为以nums[i]结尾的最大子数组和\n    dp := make([]int, len(nums))\n    dp[0] = nums[0]\n    ret := dp[0]\n\n    // 状态转移\n    for i := 1; i &lt; len(nums); i ++ {\n        dp[i] = max(nums[i], dp[i-1] + nums[i])\n        ret = max(ret, dp[i])  \n    }\n\n    return ret\n}\n\nfunc max(a, b int) int {\n    if a &gt; b {\n        return a\n    }\n    return b\n}</code></pre>\n<h2 id=\"最长公共子序列\"><a href=\"#最长公共子序列\" class=\"headerlink\" title=\"最长公共子序列\"></a>最长公共子序列</h2><p>给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0 。<br>一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。<br>例如，”ace” 是 “abcde” 的子序列，但 “aec” 不是 “abcde” 的子序列。<br>两个字符串的 公共子序列 是这两个字符串所共同拥有的子序列。</p>\n<p>示例 1：<br>输入：text1 = “abcde”, text2 = “ace”<br>输出：3<br>解释：最长公共子序列是 “ace” ，它的长度为 3 。</p>\n<p>示例 2：<br>输入：text1 = “abc”, text2 = “abc”<br>输出：3<br>解释：最长公共子序列是 “abc” ，它的长度为 3 。</p>\n<p>示例 3：<br>输入：text1 = “abc”, text2 = “def”<br>输出：0<br>解释：两个字符串没有公共子序列，返回 0 。</p>\n<h3 id=\"解答-4\"><a href=\"#解答-4\" class=\"headerlink\" title=\"解答\"></a>解答</h3><h4 id=\"dp-table，dp-i-j-为str1-0-i-和str2-0-j-最长公共子序列的长度\"><a href=\"#dp-table，dp-i-j-为str1-0-i-和str2-0-j-最长公共子序列的长度\" class=\"headerlink\" title=\"dp table，dp[i][j]为str1[0:i]和str2[0:j]最长公共子序列的长度\"></a>dp table，dp[i][j]为str1[0:i]和str2[0:j]最长公共子序列的长度</h4><pre><code class=\"golang\">func longestCommonSubsequence(text1 string, text2 string) int {\n    if len(text1) == 0 || len(text2) == 0 {\n        return 0\n    }\n    // dp[i][j] 为text1[0:i] 和 text2[0:j]的最长公共自序列\n    // 默认初始化零\n    dp := make([][]int, (len(text1)+1))\n    for i := range dp {\n        dp[i] = make([]int, (len(text2)+1))\n    }\n\n    ret := -1\n    // 状态转移， 用dp[i+1][j+1]来替换dp[i][j]\n    for i := 0; i &lt; len(text1); i ++ {\n        for j := 0; j &lt; len(text2); j ++ {\n            if text1[i] == text2[j] {\n                // 相同 则等于text1[0:i] 和 text2[0:j]的公共子序列长度+1\n                dp[i+1][j+1] = dp[i][j] + 1\n            }else {\n                // 不相同则等于text1[0:i-1] 和 text2[0:j]中的公共子序列长度\n                // 与 text1[0:i] 和 text2[0:j-1]公共子序列长度较大的\n                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])\n            }\n            ret = max(ret, dp[i+1][j+1])\n       }\n    }\n    return ret\n}\n\nfunc max(a, b int) int{\n    if a &gt; b {\n        return a\n    }\n    return b\n}</code></pre>\n<h2 id=\"编辑距离\"><a href=\"#编辑距离\" class=\"headerlink\" title=\"编辑距离\"></a>编辑距离</h2><h2 id=\"以插入最小次数构造回文串\"><a href=\"#以插入最小次数构造回文串\" class=\"headerlink\" title=\"以插入最小次数构造回文串\"></a>以插入最小次数构造回文串</h2>"},{"title":"链表相关","img":"/medias/files/linked-list.png","summary":"链表算法的技巧","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2023-04-09T03:39:47.000Z","password":null,"_content":"\n# 经典题目\n\n| 题目                                                                               |\n|:-------------------------------------------------------------------------------- |\n| [合并两个有序列表](https://leetcode.cn/problems/merge-two-sorted-lists/)                 |\n| [分割链表](https://leetcode.cn/problems/partition-list/)                             |\n| [删除链表的倒数第 N 个结点](https://leetcode.cn/problems/remove-nth-node-from-end-of-list/) |\n| [链表的中间结点](https://leetcode.cn/problems/middle-of-the-linked-list/)               |\n|                                                                                  |\n\n### 合并两个有序链表\n\n```golang\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode {\n    // 虚拟头节点\n    head := &ListNode{}\n    p := head\n    for ;list1 != nil && list2 != nil; {\n        // 比较值的大小，并赋值到新的链表\n        if list1.Val < list2.Val {\n            p.Next = list1\n            list1 = list1.Next\n            // 不用断开list1 和 list1.Next,因为后续p.Next 指向谁就是修改谁的作用域\n        } else {\n            p.Next = list2\n            list2 = list2.Next\n        }\n\n        // p 不断前进\n        p = p.Next\n    }\n\n    // list1 还没遍历完\n    if list1 != nil {\n        p.Next = list1\n    }\n    // list2 还没遍历完\n    if list2 != nil {\n        p.Next = list2\n    }\n\n    return head.Next\n}\n```\n\n### 分割链表\n\n```golang\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc partition(head *ListNode, x int) *ListNode {\n    // 分割成两个链表，一个链表小于x 一个链表大于x\n    head1 := &ListNode{}\n    p1 := head1\n    head2 := &ListNode{}\n    p2 := head2\n\n    for ;head != nil; {\n        if head.Val < x {\n            p1.Next = head\n            p1 = p1.Next\n        } else {\n            p2.Next = head\n            p2 = p2.Next\n        }\n\n        // 断开head head.Next两个节点的连接\n        // 因为p1 p2是新构造出来的节点，所以需要断开head和head.Next\n        tmp := head.Next\n        head.Next = nil\n        head = tmp\n    }\n\n    // 两个链表接起来\n    p1.Next = head2.Next\n    return head1.Next\n}\n```\n\n### 删除链表的倒数第 N 个结点\n\n```golang\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc removeNthFromEnd(head *ListNode, n int) *ListNode {\n    // 找到倒数第n + 1个节点\n    // 防止删掉头节点时越界操作，要虚拟出来一个节点\n    newHead := &ListNode{}\n    newHead.Next = head\n    p1 := newHead\n    p2 := newHead\n    for ; p1 != nil && n >= 0; {\n        p1 = p1.Next\n        n--\n    }\n\n    for ; p1 != nil; {\n        p1 = p1.Next\n        p2 = p2.Next\n    }\n\n    // 删p2.Next\n    tmp := p2.Next\n    p2.Next = p2.Next.Next\n    tmp.Next = nil\n\n    return newHead.Next\n}\n```\n\n### 链表的中间结点\n\n```go\n\n```","source":"_posts/algorithm-linked-list.md","raw":"---\ntitle: 链表相关\nimg: /medias/files/linked-list.png\nsummary: 链表算法的技巧\ntags:\n  - 博客\n  - 算法\n  - 链表\ncategories:\n  - 随笔\n  - 算法\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2023-04-09 11:39:47\npassword:\n---\n\n# 经典题目\n\n| 题目                                                                               |\n|:-------------------------------------------------------------------------------- |\n| [合并两个有序列表](https://leetcode.cn/problems/merge-two-sorted-lists/)                 |\n| [分割链表](https://leetcode.cn/problems/partition-list/)                             |\n| [删除链表的倒数第 N 个结点](https://leetcode.cn/problems/remove-nth-node-from-end-of-list/) |\n| [链表的中间结点](https://leetcode.cn/problems/middle-of-the-linked-list/)               |\n|                                                                                  |\n\n### 合并两个有序链表\n\n```golang\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode {\n    // 虚拟头节点\n    head := &ListNode{}\n    p := head\n    for ;list1 != nil && list2 != nil; {\n        // 比较值的大小，并赋值到新的链表\n        if list1.Val < list2.Val {\n            p.Next = list1\n            list1 = list1.Next\n            // 不用断开list1 和 list1.Next,因为后续p.Next 指向谁就是修改谁的作用域\n        } else {\n            p.Next = list2\n            list2 = list2.Next\n        }\n\n        // p 不断前进\n        p = p.Next\n    }\n\n    // list1 还没遍历完\n    if list1 != nil {\n        p.Next = list1\n    }\n    // list2 还没遍历完\n    if list2 != nil {\n        p.Next = list2\n    }\n\n    return head.Next\n}\n```\n\n### 分割链表\n\n```golang\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc partition(head *ListNode, x int) *ListNode {\n    // 分割成两个链表，一个链表小于x 一个链表大于x\n    head1 := &ListNode{}\n    p1 := head1\n    head2 := &ListNode{}\n    p2 := head2\n\n    for ;head != nil; {\n        if head.Val < x {\n            p1.Next = head\n            p1 = p1.Next\n        } else {\n            p2.Next = head\n            p2 = p2.Next\n        }\n\n        // 断开head head.Next两个节点的连接\n        // 因为p1 p2是新构造出来的节点，所以需要断开head和head.Next\n        tmp := head.Next\n        head.Next = nil\n        head = tmp\n    }\n\n    // 两个链表接起来\n    p1.Next = head2.Next\n    return head1.Next\n}\n```\n\n### 删除链表的倒数第 N 个结点\n\n```golang\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc removeNthFromEnd(head *ListNode, n int) *ListNode {\n    // 找到倒数第n + 1个节点\n    // 防止删掉头节点时越界操作，要虚拟出来一个节点\n    newHead := &ListNode{}\n    newHead.Next = head\n    p1 := newHead\n    p2 := newHead\n    for ; p1 != nil && n >= 0; {\n        p1 = p1.Next\n        n--\n    }\n\n    for ; p1 != nil; {\n        p1 = p1.Next\n        p2 = p2.Next\n    }\n\n    // 删p2.Next\n    tmp := p2.Next\n    p2.Next = p2.Next.Next\n    tmp.Next = nil\n\n    return newHead.Next\n}\n```\n\n### 链表的中间结点\n\n```go\n\n```","slug":"algorithm-linked-list","published":1,"updated":"2023-04-09T05:27:25.589Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9h0004agvtk8jmc69n","content":"<h1 id=\"经典题目\"><a href=\"#经典题目\" class=\"headerlink\" title=\"经典题目\"></a>经典题目</h1><table>\n<thead>\n<tr>\n<th align=\"left\">题目</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/merge-two-sorted-lists/\" target=\"_blank\" rel=\"noopener\">合并两个有序列表</a></td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/partition-list/\" target=\"_blank\" rel=\"noopener\">分割链表</a></td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/remove-nth-node-from-end-of-list/\" target=\"_blank\" rel=\"noopener\">删除链表的倒数第 N 个结点</a></td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/middle-of-the-linked-list/\" target=\"_blank\" rel=\"noopener\">链表的中间结点</a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"合并两个有序链表\"><a href=\"#合并两个有序链表\" class=\"headerlink\" title=\"合并两个有序链表\"></a>合并两个有序链表</h3><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode {\n    // 虚拟头节点\n    head := &ListNode{}\n    p := head\n    for ;list1 != nil && list2 != nil; {\n        // 比较值的大小，并赋值到新的链表\n        if list1.Val < list2.Val {\n            p.Next = list1\n            list1 = list1.Next\n            // 不用断开list1 和 list1.Next,因为后续p.Next 指向谁就是修改谁的作用域\n        } else {\n            p.Next = list2\n            list2 = list2.Next\n        }\n\n        // p 不断前进\n        p = p.Next\n    }\n\n    // list1 还没遍历完\n    if list1 != nil {\n        p.Next = list1\n    }\n    // list2 还没遍历完\n    if list2 != nil {\n        p.Next = list2\n    }\n\n    return head.Next\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"分割链表\"><a href=\"#分割链表\" class=\"headerlink\" title=\"分割链表\"></a>分割链表</h3><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc partition(head *ListNode, x int) *ListNode {\n    // 分割成两个链表，一个链表小于x 一个链表大于x\n    head1 := &ListNode{}\n    p1 := head1\n    head2 := &ListNode{}\n    p2 := head2\n\n    for ;head != nil; {\n        if head.Val < x {\n            p1.Next = head\n            p1 = p1.Next\n        } else {\n            p2.Next = head\n            p2 = p2.Next\n        }\n\n        // 断开head head.Next两个节点的连接\n        // 因为p1 p2是新构造出来的节点，所以需要断开head和head.Next\n        tmp := head.Next\n        head.Next = nil\n        head = tmp\n    }\n\n    // 两个链表接起来\n    p1.Next = head2.Next\n    return head1.Next\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"删除链表的倒数第-N-个结点\"><a href=\"#删除链表的倒数第-N-个结点\" class=\"headerlink\" title=\"删除链表的倒数第 N 个结点\"></a>删除链表的倒数第 N 个结点</h3><pre class=\"line-numbers language-golang\"><code class=\"language-golang\">/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc removeNthFromEnd(head *ListNode, n int) *ListNode {\n    // 找到倒数第n + 1个节点\n    // 防止删掉头节点时越界操作，要虚拟出来一个节点\n    newHead := &ListNode{}\n    newHead.Next = head\n    p1 := newHead\n    p2 := newHead\n    for ; p1 != nil && n >= 0; {\n        p1 = p1.Next\n        n--\n    }\n\n    for ; p1 != nil; {\n        p1 = p1.Next\n        p2 = p2.Next\n    }\n\n    // 删p2.Next\n    tmp := p2.Next\n    p2.Next = p2.Next.Next\n    tmp.Next = nil\n\n    return newHead.Next\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"链表的中间结点\"><a href=\"#链表的中间结点\" class=\"headerlink\" title=\"链表的中间结点\"></a>链表的中间结点</h3><pre class=\"line-numbers language-go\"><code class=\"language-go\"><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<h1 id=\"经典题目\"><a href=\"#经典题目\" class=\"headerlink\" title=\"经典题目\"></a>经典题目</h1><table>\n<thead>\n<tr>\n<th align=\"left\">题目</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/merge-two-sorted-lists/\" target=\"_blank\" rel=\"noopener\">合并两个有序列表</a></td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/partition-list/\" target=\"_blank\" rel=\"noopener\">分割链表</a></td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/remove-nth-node-from-end-of-list/\" target=\"_blank\" rel=\"noopener\">删除链表的倒数第 N 个结点</a></td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://leetcode.cn/problems/middle-of-the-linked-list/\" target=\"_blank\" rel=\"noopener\">链表的中间结点</a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"合并两个有序链表\"><a href=\"#合并两个有序链表\" class=\"headerlink\" title=\"合并两个有序链表\"></a>合并两个有序链表</h3><pre><code class=\"golang\">/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode {\n    // 虚拟头节点\n    head := &amp;ListNode{}\n    p := head\n    for ;list1 != nil &amp;&amp; list2 != nil; {\n        // 比较值的大小，并赋值到新的链表\n        if list1.Val &lt; list2.Val {\n            p.Next = list1\n            list1 = list1.Next\n            // 不用断开list1 和 list1.Next,因为后续p.Next 指向谁就是修改谁的作用域\n        } else {\n            p.Next = list2\n            list2 = list2.Next\n        }\n\n        // p 不断前进\n        p = p.Next\n    }\n\n    // list1 还没遍历完\n    if list1 != nil {\n        p.Next = list1\n    }\n    // list2 还没遍历完\n    if list2 != nil {\n        p.Next = list2\n    }\n\n    return head.Next\n}</code></pre>\n<h3 id=\"分割链表\"><a href=\"#分割链表\" class=\"headerlink\" title=\"分割链表\"></a>分割链表</h3><pre><code class=\"golang\">/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc partition(head *ListNode, x int) *ListNode {\n    // 分割成两个链表，一个链表小于x 一个链表大于x\n    head1 := &amp;ListNode{}\n    p1 := head1\n    head2 := &amp;ListNode{}\n    p2 := head2\n\n    for ;head != nil; {\n        if head.Val &lt; x {\n            p1.Next = head\n            p1 = p1.Next\n        } else {\n            p2.Next = head\n            p2 = p2.Next\n        }\n\n        // 断开head head.Next两个节点的连接\n        // 因为p1 p2是新构造出来的节点，所以需要断开head和head.Next\n        tmp := head.Next\n        head.Next = nil\n        head = tmp\n    }\n\n    // 两个链表接起来\n    p1.Next = head2.Next\n    return head1.Next\n}</code></pre>\n<h3 id=\"删除链表的倒数第-N-个结点\"><a href=\"#删除链表的倒数第-N-个结点\" class=\"headerlink\" title=\"删除链表的倒数第 N 个结点\"></a>删除链表的倒数第 N 个结点</h3><pre><code class=\"golang\">/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc removeNthFromEnd(head *ListNode, n int) *ListNode {\n    // 找到倒数第n + 1个节点\n    // 防止删掉头节点时越界操作，要虚拟出来一个节点\n    newHead := &amp;ListNode{}\n    newHead.Next = head\n    p1 := newHead\n    p2 := newHead\n    for ; p1 != nil &amp;&amp; n &gt;= 0; {\n        p1 = p1.Next\n        n--\n    }\n\n    for ; p1 != nil; {\n        p1 = p1.Next\n        p2 = p2.Next\n    }\n\n    // 删p2.Next\n    tmp := p2.Next\n    p2.Next = p2.Next.Next\n    tmp.Next = nil\n\n    return newHead.Next\n}</code></pre>\n<h3 id=\"链表的中间结点\"><a href=\"#链表的中间结点\" class=\"headerlink\" title=\"链表的中间结点\"></a>链表的中间结点</h3><pre><code class=\"go\"></code></pre>\n"},{"title":"go语言基础","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-06-05T10:22:24.000Z","img":"/medias/files/golang.jpeg","summary":"golang基础语法使用","password":null,"_content":"\n## Go语言基础语法介绍\n\n- Google开源\n\n- 编译型语言\n\n特点：\n\n- 语法简洁\n\n- 开发效率高\n\n- 执行性能好\n\n参考:www.liwenzhou.com  https://go.dev/tour/welcome/1\n\n## Go开发环境搭建\n\nGo开发包镜像地址：https://golang.google.cn/dl/\n\n安装好后，cmd下运行`go version`显示版本号\n\n## go语法\n\n### 包、变量、函数\n\n```\n推荐import package方式\n\nimport (\n    \"fmt\"\n\n    \"math\"\n)\n```\n\n**函数**\n\nfunc 函数名(参数名 类型,...) 返回值... {\n\n}\n\n- 多个参数同一类型时，支持简写`(x, y int)`\n\n- 支持多个返回值时 声明为`func swap(x, y string) (string, string)`   返回为 `return x, y`\n\n- 支持return named return values   声明为`func test(sum int)(x, y int)`   返回为 `return`\n\n**变量**\n\n- var 变量名... 类型   // 声明\n\n- `var x, y int = 1, 2` // 声明加初始化\n\n- `x := 1`            // 短变量声明，类型推导出x是什么类型\n\n**基本类型**\n\n```\nbool\n\nstring\n\nint  int8  int16  int32  int64\n\nuint uint8 uint16 uint32 uint64 uintptr\n\nbyte // alias for uint8\n\nrune // alias for int32\n\n     // represents a Unicode code point\n\nfloat32 float64\n\ncomplex64 complex128\n\nzero values：\n\n0 for numeric types,\n\nfalse for the boolean type, and\n\n\"\" (the empty string) for strings.\n\nnil for other type\n```\n\n**类型转换**\n\n`T(v)`\n\n**常量**\n\n`const 变量 = 值`\n\n- 不能使用短变量声明法\n\n### 流程控制\n\n**for**\n\n```\nfor init statment; condition statement; post statement {\n\n}\n```\n\n- 初始和结束执行的语句可以省略(保留分号)\n\n- 语句只有condition，效果为像使用while一样(没有分号)\n\n- 语句连condition都没有(用于死循环)\n\n**if**\n\n```\nif condition {\n\n}\n```\n\n- 没有小括号，但是{}是必须的\n\n- 变形 `if init statement; condition stament {}`(init statement声明的短变量作用域在if else块内)\n\n**switch**\n\n```\nswitch init statement;condition{\n\n    case 值1：\n\n    case 值2\n\n}\n```\n\n- go自动在每个case后break\n\n- switch case的条件不必是const的，也不一定是integer\n\n- switch语句也可以带短变量声明语句，也可以省略condition(等于switch true)\n\n**defer**\n\n```\nfunc test() {\n\n    fmt.Println(\"123\")\n\n}\n\nfunc main() {\n\n    defer fmt.Println(\"world\")\n\n    fmt.Println(\"hello\")\n\n    test()\n\n}\n```\n\n- defer语句会立即求值，但是推迟到函数返回之前执行。\n\n- 多个defer语句会压栈，直到函数返回时，多个defer会按出栈顺序调用\n\n### 复合数据类型\n\n**pointer**\n\n`i= 42`\n\n`p := &i`\n\n- 默认初始化为nil，没有指数算术\n\n**struct**\n\n```\ntype Vertex struct {\n\n    X int\n\n    Y int\n\n}\n\nfunc main() {\n\n    v := Vertex{1, 2}\n\n    p := &v\n\n    p.X = 666\n\n    fmt.Println(v)\n\n}\n```\n\n- 可以使用v.X 也可以使用指针p.X访问成员\n\n**array**\n\n```\nvar a [2]string\n\na[0] = \"Hello\"\n\na[1] = \"World\"\n\nfmt.Println(a)\n```\n\n- array是值，数组长度固定\n\n**slice**\n\n```\nprimes := [6]int{2, 3, 5, 7, 11, 13}\n\nvar s []int = primes[:4]  //切片\n\nfmt.Println(s)\n```\n\n- 切片是引用，切片底层指向数组，长度可扩容\n\n- 切片`a[low:high];`省略low为0，省略high为切片的len\n\n- make 构造，`make([]int, len, cap)`\n\n- 切片元素为切片\n\n- append 可以添加一个元素、多个元素、一个切片。当切片容量不足，则新创建一个大数组，切片指向新数组\n\n**range**\n\n- range 数组；slice；返回 inedx, value\n\n- range map；返回 key, value\n\n- 匿名变量 `_` ，接收不使用的值\n\n**map**\n\n- 删除元素  `delete(map1, key)`\n\n- 测试key值是否存在 `value， ok = map1[key]`\n\n**function**\n\n`func 函数名(参数) 返回值 {}`\n\n- 函数可以作为参数，也可以作为返回值\n\n- 函数闭包：闭包是一个函数值，它从其主体外部引用变量。该函数可以访问并分配给引用的变量。函数是绑定到变量的\n\n### 方法和接口\n\n**method**\n\n`func (receiver) 函数名(参数) 返回值 {}`\n\n- 作用于特定的receiver的函数\n\n- 声明method和reveiver必须在同一个package\n\n- 特定的receiver可以不是struct，可以是基本数据类型。\n  \n  指针receiver 和 值receiver；指针receiver可以修改值，(传参无需关心传的是指针还是值)(函数则不行，函数必须要确定传参类型匹配)\n\n**interface**\n\n```\ntype T struct {\n\n    S string\n\n}\n\ntype I interface {\n\n    Abs() float64\n\n}\n\nfunc (t T) Abs() { // 类型通过实现其method来实现接口\n\n    fmt.Println(t.S)\n\n}\n\nvar i I = T{\"hello\"}\n\ni.M()\n```\n\n- 接口值可以视为(value, type)，在接口值上调用方法会在其基础类型上执行相同名称的方法。\n\n- `var i I`；一个空的接口值，其value和type都是nil，调用会产生运行时错误\n\n- `var i interface{}`；一个空接口，可以保存任何类型的值\n\n`s, ok := i.(string)`； 判断接口是否含有类型string\n\n- fmt就是其他都实现了String接口\n\n- go中的error是其他实现了Error接口\n\n```\ntype Stringer interface {\n\n    String() string\n\n}\n\n\n\ntype error interface {\n\n    Error() string\n\n}\n```\n\n### 并发\n\n**goroutines**\n\n- 协程，Go运行时管理的轻量级线程，goroutines运行在相同的地址空间，所以对共享内存的访问必须同步，可以借助sync包\n\n**channels**\n\n```\nch <- v    // 将v值发送到通道ch\n\nv := <-ch  // 从通道ch接收，并给v赋值\n\n数据按照箭头方向流动\n\n\n// 使用前必须创建\n\nch := make(chan int)\n```\n\n- channel有类型，可以发送和接收 ，运算符<-\n\n- 默认情况下，无缓冲的channel，发送和接收是阻塞的，这允许在没有显式锁或条件变量的情况下进行同步\n\n- 有缓冲的channel  `make(chan int, 100)`, 可以异步，当缓冲区满时再写入才会阻塞，缓冲区空时读取才会阻塞\n\n-  通道可以close，可以通过ok测试 `v, ok := <- ch`，只有发送者可以关闭通道，在关闭的通道里发送会panic，对于for range通道运算，需要主动close来告知接收者通道没有值了\n\n**select**\n\n- select 语句让gotroutine等待多个通信操作， select阻塞直到它的一个case可以运行，如果都准备好了，它随机运行一个。\n\n- select 可以有default语句，当没有case准备好时，就执行default语句\n","source":"_posts/hello-go.md","raw":"---\ntitle: go语言基础\ntags:\n  - Go\ncategories:\n  - 学习笔记\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-06-05 18:22:24\nimg: /medias/files/golang.jpeg\nsummary: golang基础语法使用\npassword: \n---\n\n## Go语言基础语法介绍\n\n- Google开源\n\n- 编译型语言\n\n特点：\n\n- 语法简洁\n\n- 开发效率高\n\n- 执行性能好\n\n参考:www.liwenzhou.com  https://go.dev/tour/welcome/1\n\n## Go开发环境搭建\n\nGo开发包镜像地址：https://golang.google.cn/dl/\n\n安装好后，cmd下运行`go version`显示版本号\n\n## go语法\n\n### 包、变量、函数\n\n```\n推荐import package方式\n\nimport (\n    \"fmt\"\n\n    \"math\"\n)\n```\n\n**函数**\n\nfunc 函数名(参数名 类型,...) 返回值... {\n\n}\n\n- 多个参数同一类型时，支持简写`(x, y int)`\n\n- 支持多个返回值时 声明为`func swap(x, y string) (string, string)`   返回为 `return x, y`\n\n- 支持return named return values   声明为`func test(sum int)(x, y int)`   返回为 `return`\n\n**变量**\n\n- var 变量名... 类型   // 声明\n\n- `var x, y int = 1, 2` // 声明加初始化\n\n- `x := 1`            // 短变量声明，类型推导出x是什么类型\n\n**基本类型**\n\n```\nbool\n\nstring\n\nint  int8  int16  int32  int64\n\nuint uint8 uint16 uint32 uint64 uintptr\n\nbyte // alias for uint8\n\nrune // alias for int32\n\n     // represents a Unicode code point\n\nfloat32 float64\n\ncomplex64 complex128\n\nzero values：\n\n0 for numeric types,\n\nfalse for the boolean type, and\n\n\"\" (the empty string) for strings.\n\nnil for other type\n```\n\n**类型转换**\n\n`T(v)`\n\n**常量**\n\n`const 变量 = 值`\n\n- 不能使用短变量声明法\n\n### 流程控制\n\n**for**\n\n```\nfor init statment; condition statement; post statement {\n\n}\n```\n\n- 初始和结束执行的语句可以省略(保留分号)\n\n- 语句只有condition，效果为像使用while一样(没有分号)\n\n- 语句连condition都没有(用于死循环)\n\n**if**\n\n```\nif condition {\n\n}\n```\n\n- 没有小括号，但是{}是必须的\n\n- 变形 `if init statement; condition stament {}`(init statement声明的短变量作用域在if else块内)\n\n**switch**\n\n```\nswitch init statement;condition{\n\n    case 值1：\n\n    case 值2\n\n}\n```\n\n- go自动在每个case后break\n\n- switch case的条件不必是const的，也不一定是integer\n\n- switch语句也可以带短变量声明语句，也可以省略condition(等于switch true)\n\n**defer**\n\n```\nfunc test() {\n\n    fmt.Println(\"123\")\n\n}\n\nfunc main() {\n\n    defer fmt.Println(\"world\")\n\n    fmt.Println(\"hello\")\n\n    test()\n\n}\n```\n\n- defer语句会立即求值，但是推迟到函数返回之前执行。\n\n- 多个defer语句会压栈，直到函数返回时，多个defer会按出栈顺序调用\n\n### 复合数据类型\n\n**pointer**\n\n`i= 42`\n\n`p := &i`\n\n- 默认初始化为nil，没有指数算术\n\n**struct**\n\n```\ntype Vertex struct {\n\n    X int\n\n    Y int\n\n}\n\nfunc main() {\n\n    v := Vertex{1, 2}\n\n    p := &v\n\n    p.X = 666\n\n    fmt.Println(v)\n\n}\n```\n\n- 可以使用v.X 也可以使用指针p.X访问成员\n\n**array**\n\n```\nvar a [2]string\n\na[0] = \"Hello\"\n\na[1] = \"World\"\n\nfmt.Println(a)\n```\n\n- array是值，数组长度固定\n\n**slice**\n\n```\nprimes := [6]int{2, 3, 5, 7, 11, 13}\n\nvar s []int = primes[:4]  //切片\n\nfmt.Println(s)\n```\n\n- 切片是引用，切片底层指向数组，长度可扩容\n\n- 切片`a[low:high];`省略low为0，省略high为切片的len\n\n- make 构造，`make([]int, len, cap)`\n\n- 切片元素为切片\n\n- append 可以添加一个元素、多个元素、一个切片。当切片容量不足，则新创建一个大数组，切片指向新数组\n\n**range**\n\n- range 数组；slice；返回 inedx, value\n\n- range map；返回 key, value\n\n- 匿名变量 `_` ，接收不使用的值\n\n**map**\n\n- 删除元素  `delete(map1, key)`\n\n- 测试key值是否存在 `value， ok = map1[key]`\n\n**function**\n\n`func 函数名(参数) 返回值 {}`\n\n- 函数可以作为参数，也可以作为返回值\n\n- 函数闭包：闭包是一个函数值，它从其主体外部引用变量。该函数可以访问并分配给引用的变量。函数是绑定到变量的\n\n### 方法和接口\n\n**method**\n\n`func (receiver) 函数名(参数) 返回值 {}`\n\n- 作用于特定的receiver的函数\n\n- 声明method和reveiver必须在同一个package\n\n- 特定的receiver可以不是struct，可以是基本数据类型。\n  \n  指针receiver 和 值receiver；指针receiver可以修改值，(传参无需关心传的是指针还是值)(函数则不行，函数必须要确定传参类型匹配)\n\n**interface**\n\n```\ntype T struct {\n\n    S string\n\n}\n\ntype I interface {\n\n    Abs() float64\n\n}\n\nfunc (t T) Abs() { // 类型通过实现其method来实现接口\n\n    fmt.Println(t.S)\n\n}\n\nvar i I = T{\"hello\"}\n\ni.M()\n```\n\n- 接口值可以视为(value, type)，在接口值上调用方法会在其基础类型上执行相同名称的方法。\n\n- `var i I`；一个空的接口值，其value和type都是nil，调用会产生运行时错误\n\n- `var i interface{}`；一个空接口，可以保存任何类型的值\n\n`s, ok := i.(string)`； 判断接口是否含有类型string\n\n- fmt就是其他都实现了String接口\n\n- go中的error是其他实现了Error接口\n\n```\ntype Stringer interface {\n\n    String() string\n\n}\n\n\n\ntype error interface {\n\n    Error() string\n\n}\n```\n\n### 并发\n\n**goroutines**\n\n- 协程，Go运行时管理的轻量级线程，goroutines运行在相同的地址空间，所以对共享内存的访问必须同步，可以借助sync包\n\n**channels**\n\n```\nch <- v    // 将v值发送到通道ch\n\nv := <-ch  // 从通道ch接收，并给v赋值\n\n数据按照箭头方向流动\n\n\n// 使用前必须创建\n\nch := make(chan int)\n```\n\n- channel有类型，可以发送和接收 ，运算符<-\n\n- 默认情况下，无缓冲的channel，发送和接收是阻塞的，这允许在没有显式锁或条件变量的情况下进行同步\n\n- 有缓冲的channel  `make(chan int, 100)`, 可以异步，当缓冲区满时再写入才会阻塞，缓冲区空时读取才会阻塞\n\n-  通道可以close，可以通过ok测试 `v, ok := <- ch`，只有发送者可以关闭通道，在关闭的通道里发送会panic，对于for range通道运算，需要主动close来告知接收者通道没有值了\n\n**select**\n\n- select 语句让gotroutine等待多个通信操作， select阻塞直到它的一个case可以运行，如果都准备好了，它随机运行一个。\n\n- select 可以有default语句，当没有case准备好时，就执行default语句\n","slug":"hello-go","published":1,"updated":"2022-07-05T14:23:09.893Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9h0008agvtiuu84svp","content":"<h2 id=\"Go语言基础语法介绍\"><a href=\"#Go语言基础语法介绍\" class=\"headerlink\" title=\"Go语言基础语法介绍\"></a>Go语言基础语法介绍</h2><ul>\n<li><p>Google开源</p>\n</li>\n<li><p>编译型语言</p>\n</li>\n</ul>\n<p>特点：</p>\n<ul>\n<li><p>语法简洁</p>\n</li>\n<li><p>开发效率高</p>\n</li>\n<li><p>执行性能好</p>\n</li>\n</ul>\n<p>参考:<a href=\"http://www.liwenzhou.com\" target=\"_blank\" rel=\"noopener\">www.liwenzhou.com</a>  <a href=\"https://go.dev/tour/welcome/1\" target=\"_blank\" rel=\"noopener\">https://go.dev/tour/welcome/1</a></p>\n<h2 id=\"Go开发环境搭建\"><a href=\"#Go开发环境搭建\" class=\"headerlink\" title=\"Go开发环境搭建\"></a>Go开发环境搭建</h2><p>Go开发包镜像地址：<a href=\"https://golang.google.cn/dl/\" target=\"_blank\" rel=\"noopener\">https://golang.google.cn/dl/</a></p>\n<p>安装好后，cmd下运行<code>go version</code>显示版本号</p>\n<h2 id=\"go语法\"><a href=\"#go语法\" class=\"headerlink\" title=\"go语法\"></a>go语法</h2><h3 id=\"包、变量、函数\"><a href=\"#包、变量、函数\" class=\"headerlink\" title=\"包、变量、函数\"></a>包、变量、函数</h3><pre><code>推荐import package方式\n\nimport (\n    &quot;fmt&quot;\n\n    &quot;math&quot;\n)</code></pre><p><strong>函数</strong></p>\n<p>func 函数名(参数名 类型,…) 返回值… {</p>\n<p>}</p>\n<ul>\n<li><p>多个参数同一类型时，支持简写<code>(x, y int)</code></p>\n</li>\n<li><p>支持多个返回值时 声明为<code>func swap(x, y string) (string, string)</code>   返回为 <code>return x, y</code></p>\n</li>\n<li><p>支持return named return values   声明为<code>func test(sum int)(x, y int)</code>   返回为 <code>return</code></p>\n</li>\n</ul>\n<p><strong>变量</strong></p>\n<ul>\n<li><p>var 变量名… 类型   // 声明</p>\n</li>\n<li><p><code>var x, y int = 1, 2</code> // 声明加初始化</p>\n</li>\n<li><p><code>x := 1</code>            // 短变量声明，类型推导出x是什么类型</p>\n</li>\n</ul>\n<p><strong>基本类型</strong></p>\n<pre><code>bool\n\nstring\n\nint  int8  int16  int32  int64\n\nuint uint8 uint16 uint32 uint64 uintptr\n\nbyte // alias for uint8\n\nrune // alias for int32\n\n     // represents a Unicode code point\n\nfloat32 float64\n\ncomplex64 complex128\n\nzero values：\n\n0 for numeric types,\n\nfalse for the boolean type, and\n\n&quot;&quot; (the empty string) for strings.\n\nnil for other type</code></pre><p><strong>类型转换</strong></p>\n<p><code>T(v)</code></p>\n<p><strong>常量</strong></p>\n<p><code>const 变量 = 值</code></p>\n<ul>\n<li>不能使用短变量声明法</li>\n</ul>\n<h3 id=\"流程控制\"><a href=\"#流程控制\" class=\"headerlink\" title=\"流程控制\"></a>流程控制</h3><p><strong>for</strong></p>\n<pre><code>for init statment; condition statement; post statement {\n\n}</code></pre><ul>\n<li><p>初始和结束执行的语句可以省略(保留分号)</p>\n</li>\n<li><p>语句只有condition，效果为像使用while一样(没有分号)</p>\n</li>\n<li><p>语句连condition都没有(用于死循环)</p>\n</li>\n</ul>\n<p><strong>if</strong></p>\n<pre><code>if condition {\n\n}</code></pre><ul>\n<li><p>没有小括号，但是{}是必须的</p>\n</li>\n<li><p>变形 <code>if init statement; condition stament {}</code>(init statement声明的短变量作用域在if else块内)</p>\n</li>\n</ul>\n<p><strong>switch</strong></p>\n<pre><code>switch init statement;condition{\n\n    case 值1：\n\n    case 值2\n\n}</code></pre><ul>\n<li><p>go自动在每个case后break</p>\n</li>\n<li><p>switch case的条件不必是const的，也不一定是integer</p>\n</li>\n<li><p>switch语句也可以带短变量声明语句，也可以省略condition(等于switch true)</p>\n</li>\n</ul>\n<p><strong>defer</strong></p>\n<pre><code>func test() {\n\n    fmt.Println(&quot;123&quot;)\n\n}\n\nfunc main() {\n\n    defer fmt.Println(&quot;world&quot;)\n\n    fmt.Println(&quot;hello&quot;)\n\n    test()\n\n}</code></pre><ul>\n<li><p>defer语句会立即求值，但是推迟到函数返回之前执行。</p>\n</li>\n<li><p>多个defer语句会压栈，直到函数返回时，多个defer会按出栈顺序调用</p>\n</li>\n</ul>\n<h3 id=\"复合数据类型\"><a href=\"#复合数据类型\" class=\"headerlink\" title=\"复合数据类型\"></a>复合数据类型</h3><p><strong>pointer</strong></p>\n<p><code>i= 42</code></p>\n<p><code>p := &amp;i</code></p>\n<ul>\n<li>默认初始化为nil，没有指数算术</li>\n</ul>\n<p><strong>struct</strong></p>\n<pre><code>type Vertex struct {\n\n    X int\n\n    Y int\n\n}\n\nfunc main() {\n\n    v := Vertex{1, 2}\n\n    p := &amp;v\n\n    p.X = 666\n\n    fmt.Println(v)\n\n}</code></pre><ul>\n<li>可以使用v.X 也可以使用指针p.X访问成员</li>\n</ul>\n<p><strong>array</strong></p>\n<pre><code>var a [2]string\n\na[0] = &quot;Hello&quot;\n\na[1] = &quot;World&quot;\n\nfmt.Println(a)</code></pre><ul>\n<li>array是值，数组长度固定</li>\n</ul>\n<p><strong>slice</strong></p>\n<pre><code>primes := [6]int{2, 3, 5, 7, 11, 13}\n\nvar s []int = primes[:4]  //切片\n\nfmt.Println(s)</code></pre><ul>\n<li><p>切片是引用，切片底层指向数组，长度可扩容</p>\n</li>\n<li><p>切片<code>a[low:high];</code>省略low为0，省略high为切片的len</p>\n</li>\n<li><p>make 构造，<code>make([]int, len, cap)</code></p>\n</li>\n<li><p>切片元素为切片</p>\n</li>\n<li><p>append 可以添加一个元素、多个元素、一个切片。当切片容量不足，则新创建一个大数组，切片指向新数组</p>\n</li>\n</ul>\n<p><strong>range</strong></p>\n<ul>\n<li><p>range 数组；slice；返回 inedx, value</p>\n</li>\n<li><p>range map；返回 key, value</p>\n</li>\n<li><p>匿名变量 <code>_</code> ，接收不使用的值</p>\n</li>\n</ul>\n<p><strong>map</strong></p>\n<ul>\n<li><p>删除元素  <code>delete(map1, key)</code></p>\n</li>\n<li><p>测试key值是否存在 <code>value， ok = map1[key]</code></p>\n</li>\n</ul>\n<p><strong>function</strong></p>\n<p><code>func 函数名(参数) 返回值 {}</code></p>\n<ul>\n<li><p>函数可以作为参数，也可以作为返回值</p>\n</li>\n<li><p>函数闭包：闭包是一个函数值，它从其主体外部引用变量。该函数可以访问并分配给引用的变量。函数是绑定到变量的</p>\n</li>\n</ul>\n<h3 id=\"方法和接口\"><a href=\"#方法和接口\" class=\"headerlink\" title=\"方法和接口\"></a>方法和接口</h3><p><strong>method</strong></p>\n<p><code>func (receiver) 函数名(参数) 返回值 {}</code></p>\n<ul>\n<li><p>作用于特定的receiver的函数</p>\n</li>\n<li><p>声明method和reveiver必须在同一个package</p>\n</li>\n<li><p>特定的receiver可以不是struct，可以是基本数据类型。</p>\n<p>指针receiver 和 值receiver；指针receiver可以修改值，(传参无需关心传的是指针还是值)(函数则不行，函数必须要确定传参类型匹配)</p>\n</li>\n</ul>\n<p><strong>interface</strong></p>\n<pre><code>type T struct {\n\n    S string\n\n}\n\ntype I interface {\n\n    Abs() float64\n\n}\n\nfunc (t T) Abs() { // 类型通过实现其method来实现接口\n\n    fmt.Println(t.S)\n\n}\n\nvar i I = T{&quot;hello&quot;}\n\ni.M()</code></pre><ul>\n<li><p>接口值可以视为(value, type)，在接口值上调用方法会在其基础类型上执行相同名称的方法。</p>\n</li>\n<li><p><code>var i I</code>；一个空的接口值，其value和type都是nil，调用会产生运行时错误</p>\n</li>\n<li><p><code>var i interface{}</code>；一个空接口，可以保存任何类型的值</p>\n</li>\n</ul>\n<p><code>s, ok := i.(string)</code>； 判断接口是否含有类型string</p>\n<ul>\n<li><p>fmt就是其他都实现了String接口</p>\n</li>\n<li><p>go中的error是其他实现了Error接口</p>\n</li>\n</ul>\n<pre><code>type Stringer interface {\n\n    String() string\n\n}\n\n\n\ntype error interface {\n\n    Error() string\n\n}</code></pre><h3 id=\"并发\"><a href=\"#并发\" class=\"headerlink\" title=\"并发\"></a>并发</h3><p><strong>goroutines</strong></p>\n<ul>\n<li>协程，Go运行时管理的轻量级线程，goroutines运行在相同的地址空间，所以对共享内存的访问必须同步，可以借助sync包</li>\n</ul>\n<p><strong>channels</strong></p>\n<pre><code>ch &lt;- v    // 将v值发送到通道ch\n\nv := &lt;-ch  // 从通道ch接收，并给v赋值\n\n数据按照箭头方向流动\n\n\n// 使用前必须创建\n\nch := make(chan int)</code></pre><ul>\n<li><p>channel有类型，可以发送和接收 ，运算符&lt;-</p>\n</li>\n<li><p>默认情况下，无缓冲的channel，发送和接收是阻塞的，这允许在没有显式锁或条件变量的情况下进行同步</p>\n</li>\n<li><p>有缓冲的channel  <code>make(chan int, 100)</code>, 可以异步，当缓冲区满时再写入才会阻塞，缓冲区空时读取才会阻塞</p>\n</li>\n<li><p>通道可以close，可以通过ok测试 <code>v, ok := &lt;- ch</code>，只有发送者可以关闭通道，在关闭的通道里发送会panic，对于for range通道运算，需要主动close来告知接收者通道没有值了</p>\n</li>\n</ul>\n<p><strong>select</strong></p>\n<ul>\n<li><p>select 语句让gotroutine等待多个通信操作， select阻塞直到它的一个case可以运行，如果都准备好了，它随机运行一个。</p>\n</li>\n<li><p>select 可以有default语句，当没有case准备好时，就执行default语句</p>\n</li>\n</ul>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<h2 id=\"Go语言基础语法介绍\"><a href=\"#Go语言基础语法介绍\" class=\"headerlink\" title=\"Go语言基础语法介绍\"></a>Go语言基础语法介绍</h2><ul>\n<li><p>Google开源</p>\n</li>\n<li><p>编译型语言</p>\n</li>\n</ul>\n<p>特点：</p>\n<ul>\n<li><p>语法简洁</p>\n</li>\n<li><p>开发效率高</p>\n</li>\n<li><p>执行性能好</p>\n</li>\n</ul>\n<p>参考:<a href=\"http://www.liwenzhou.com\" target=\"_blank\" rel=\"noopener\">www.liwenzhou.com</a>  <a href=\"https://go.dev/tour/welcome/1\" target=\"_blank\" rel=\"noopener\">https://go.dev/tour/welcome/1</a></p>\n<h2 id=\"Go开发环境搭建\"><a href=\"#Go开发环境搭建\" class=\"headerlink\" title=\"Go开发环境搭建\"></a>Go开发环境搭建</h2><p>Go开发包镜像地址：<a href=\"https://golang.google.cn/dl/\" target=\"_blank\" rel=\"noopener\">https://golang.google.cn/dl/</a></p>\n<p>安装好后，cmd下运行<code>go version</code>显示版本号</p>\n<h2 id=\"go语法\"><a href=\"#go语法\" class=\"headerlink\" title=\"go语法\"></a>go语法</h2><h3 id=\"包、变量、函数\"><a href=\"#包、变量、函数\" class=\"headerlink\" title=\"包、变量、函数\"></a>包、变量、函数</h3><pre><code>推荐import package方式\n\nimport (\n    &quot;fmt&quot;\n\n    &quot;math&quot;\n)</code></pre><p><strong>函数</strong></p>\n<p>func 函数名(参数名 类型,…) 返回值… {</p>\n<p>}</p>\n<ul>\n<li><p>多个参数同一类型时，支持简写<code>(x, y int)</code></p>\n</li>\n<li><p>支持多个返回值时 声明为<code>func swap(x, y string) (string, string)</code>   返回为 <code>return x, y</code></p>\n</li>\n<li><p>支持return named return values   声明为<code>func test(sum int)(x, y int)</code>   返回为 <code>return</code></p>\n</li>\n</ul>\n<p><strong>变量</strong></p>\n<ul>\n<li><p>var 变量名… 类型   // 声明</p>\n</li>\n<li><p><code>var x, y int = 1, 2</code> // 声明加初始化</p>\n</li>\n<li><p><code>x := 1</code>            // 短变量声明，类型推导出x是什么类型</p>\n</li>\n</ul>\n<p><strong>基本类型</strong></p>\n<pre><code>bool\n\nstring\n\nint  int8  int16  int32  int64\n\nuint uint8 uint16 uint32 uint64 uintptr\n\nbyte // alias for uint8\n\nrune // alias for int32\n\n     // represents a Unicode code point\n\nfloat32 float64\n\ncomplex64 complex128\n\nzero values：\n\n0 for numeric types,\n\nfalse for the boolean type, and\n\n&quot;&quot; (the empty string) for strings.\n\nnil for other type</code></pre><p><strong>类型转换</strong></p>\n<p><code>T(v)</code></p>\n<p><strong>常量</strong></p>\n<p><code>const 变量 = 值</code></p>\n<ul>\n<li>不能使用短变量声明法</li>\n</ul>\n<h3 id=\"流程控制\"><a href=\"#流程控制\" class=\"headerlink\" title=\"流程控制\"></a>流程控制</h3><p><strong>for</strong></p>\n<pre><code>for init statment; condition statement; post statement {\n\n}</code></pre><ul>\n<li><p>初始和结束执行的语句可以省略(保留分号)</p>\n</li>\n<li><p>语句只有condition，效果为像使用while一样(没有分号)</p>\n</li>\n<li><p>语句连condition都没有(用于死循环)</p>\n</li>\n</ul>\n<p><strong>if</strong></p>\n<pre><code>if condition {\n\n}</code></pre><ul>\n<li><p>没有小括号，但是{}是必须的</p>\n</li>\n<li><p>变形 <code>if init statement; condition stament {}</code>(init statement声明的短变量作用域在if else块内)</p>\n</li>\n</ul>\n<p><strong>switch</strong></p>\n<pre><code>switch init statement;condition{\n\n    case 值1：\n\n    case 值2\n\n}</code></pre><ul>\n<li><p>go自动在每个case后break</p>\n</li>\n<li><p>switch case的条件不必是const的，也不一定是integer</p>\n</li>\n<li><p>switch语句也可以带短变量声明语句，也可以省略condition(等于switch true)</p>\n</li>\n</ul>\n<p><strong>defer</strong></p>\n<pre><code>func test() {\n\n    fmt.Println(&quot;123&quot;)\n\n}\n\nfunc main() {\n\n    defer fmt.Println(&quot;world&quot;)\n\n    fmt.Println(&quot;hello&quot;)\n\n    test()\n\n}</code></pre><ul>\n<li><p>defer语句会立即求值，但是推迟到函数返回之前执行。</p>\n</li>\n<li><p>多个defer语句会压栈，直到函数返回时，多个defer会按出栈顺序调用</p>\n</li>\n</ul>\n<h3 id=\"复合数据类型\"><a href=\"#复合数据类型\" class=\"headerlink\" title=\"复合数据类型\"></a>复合数据类型</h3><p><strong>pointer</strong></p>\n<p><code>i= 42</code></p>\n<p><code>p := &amp;i</code></p>\n<ul>\n<li>默认初始化为nil，没有指数算术</li>\n</ul>\n<p><strong>struct</strong></p>\n<pre><code>type Vertex struct {\n\n    X int\n\n    Y int\n\n}\n\nfunc main() {\n\n    v := Vertex{1, 2}\n\n    p := &amp;v\n\n    p.X = 666\n\n    fmt.Println(v)\n\n}</code></pre><ul>\n<li>可以使用v.X 也可以使用指针p.X访问成员</li>\n</ul>\n<p><strong>array</strong></p>\n<pre><code>var a [2]string\n\na[0] = &quot;Hello&quot;\n\na[1] = &quot;World&quot;\n\nfmt.Println(a)</code></pre><ul>\n<li>array是值，数组长度固定</li>\n</ul>\n<p><strong>slice</strong></p>\n<pre><code>primes := [6]int{2, 3, 5, 7, 11, 13}\n\nvar s []int = primes[:4]  //切片\n\nfmt.Println(s)</code></pre><ul>\n<li><p>切片是引用，切片底层指向数组，长度可扩容</p>\n</li>\n<li><p>切片<code>a[low:high];</code>省略low为0，省略high为切片的len</p>\n</li>\n<li><p>make 构造，<code>make([]int, len, cap)</code></p>\n</li>\n<li><p>切片元素为切片</p>\n</li>\n<li><p>append 可以添加一个元素、多个元素、一个切片。当切片容量不足，则新创建一个大数组，切片指向新数组</p>\n</li>\n</ul>\n<p><strong>range</strong></p>\n<ul>\n<li><p>range 数组；slice；返回 inedx, value</p>\n</li>\n<li><p>range map；返回 key, value</p>\n</li>\n<li><p>匿名变量 <code>_</code> ，接收不使用的值</p>\n</li>\n</ul>\n<p><strong>map</strong></p>\n<ul>\n<li><p>删除元素  <code>delete(map1, key)</code></p>\n</li>\n<li><p>测试key值是否存在 <code>value， ok = map1[key]</code></p>\n</li>\n</ul>\n<p><strong>function</strong></p>\n<p><code>func 函数名(参数) 返回值 {}</code></p>\n<ul>\n<li><p>函数可以作为参数，也可以作为返回值</p>\n</li>\n<li><p>函数闭包：闭包是一个函数值，它从其主体外部引用变量。该函数可以访问并分配给引用的变量。函数是绑定到变量的</p>\n</li>\n</ul>\n<h3 id=\"方法和接口\"><a href=\"#方法和接口\" class=\"headerlink\" title=\"方法和接口\"></a>方法和接口</h3><p><strong>method</strong></p>\n<p><code>func (receiver) 函数名(参数) 返回值 {}</code></p>\n<ul>\n<li><p>作用于特定的receiver的函数</p>\n</li>\n<li><p>声明method和reveiver必须在同一个package</p>\n</li>\n<li><p>特定的receiver可以不是struct，可以是基本数据类型。</p>\n<p>指针receiver 和 值receiver；指针receiver可以修改值，(传参无需关心传的是指针还是值)(函数则不行，函数必须要确定传参类型匹配)</p>\n</li>\n</ul>\n<p><strong>interface</strong></p>\n<pre><code>type T struct {\n\n    S string\n\n}\n\ntype I interface {\n\n    Abs() float64\n\n}\n\nfunc (t T) Abs() { // 类型通过实现其method来实现接口\n\n    fmt.Println(t.S)\n\n}\n\nvar i I = T{&quot;hello&quot;}\n\ni.M()</code></pre><ul>\n<li><p>接口值可以视为(value, type)，在接口值上调用方法会在其基础类型上执行相同名称的方法。</p>\n</li>\n<li><p><code>var i I</code>；一个空的接口值，其value和type都是nil，调用会产生运行时错误</p>\n</li>\n<li><p><code>var i interface{}</code>；一个空接口，可以保存任何类型的值</p>\n</li>\n</ul>\n<p><code>s, ok := i.(string)</code>； 判断接口是否含有类型string</p>\n<ul>\n<li><p>fmt就是其他都实现了String接口</p>\n</li>\n<li><p>go中的error是其他实现了Error接口</p>\n</li>\n</ul>\n<pre><code>type Stringer interface {\n\n    String() string\n\n}\n\n\n\ntype error interface {\n\n    Error() string\n\n}</code></pre><h3 id=\"并发\"><a href=\"#并发\" class=\"headerlink\" title=\"并发\"></a>并发</h3><p><strong>goroutines</strong></p>\n<ul>\n<li>协程，Go运行时管理的轻量级线程，goroutines运行在相同的地址空间，所以对共享内存的访问必须同步，可以借助sync包</li>\n</ul>\n<p><strong>channels</strong></p>\n<pre><code>ch &lt;- v    // 将v值发送到通道ch\n\nv := &lt;-ch  // 从通道ch接收，并给v赋值\n\n数据按照箭头方向流动\n\n\n// 使用前必须创建\n\nch := make(chan int)</code></pre><ul>\n<li><p>channel有类型，可以发送和接收 ，运算符&lt;-</p>\n</li>\n<li><p>默认情况下，无缓冲的channel，发送和接收是阻塞的，这允许在没有显式锁或条件变量的情况下进行同步</p>\n</li>\n<li><p>有缓冲的channel  <code>make(chan int, 100)</code>, 可以异步，当缓冲区满时再写入才会阻塞，缓冲区空时读取才会阻塞</p>\n</li>\n<li><p>通道可以close，可以通过ok测试 <code>v, ok := &lt;- ch</code>，只有发送者可以关闭通道，在关闭的通道里发送会panic，对于for range通道运算，需要主动close来告知接收者通道没有值了</p>\n</li>\n</ul>\n<p><strong>select</strong></p>\n<ul>\n<li><p>select 语句让gotroutine等待多个通信操作， select阻塞直到它的一个case可以运行，如果都准备好了，它随机运行一个。</p>\n</li>\n<li><p>select 可以有default语句，当没有case准备好时，就执行default语句</p>\n</li>\n</ul>\n"},{"title":"Hello, Hexo","top":true,"cover":false,"toc":true,"img":"/medias/files/hexo.png","mathjax":true,"date":"2020-01-14T07:27:31.000Z","password":null,"summary":"Hexo是一个快速, 简洁且高效的博客框架. 让上百个页面在几秒内瞬间完成渲染. Hexo支持Github Flavored Markdown的所有功能, 甚至可以整合Octopress的大多数插件. 并自己也拥有强大的插件系统.","_content":"\n> Hexo是本次新挖掘出来的搭建网站的快速工具，容易上手，且样式好看。\n\n### 起源\n\n一直想要一个永久的域名，但是在学生时代经费紧张，就只能先这么凑合了。偶然有一次看到了Hexo + Github搭建个人网站的例子，Hexo是一款强大的产品，可以快速的生成页面。我也有尝试另外一款是wordpress，但是我本地测试后还有很多不易用的感受，而且我也不是专业的前端程序员，而Hexo可以根据网上的教程快速的搭建成自己舒服的样子，所以就被我pick。今天正式启用此站点，Hello Hexo！\n\n## 2020.6.26\n\n一次偶然的机会看到百度云可以1元得到一个域名和一个虚拟主机资源，所以产生了`www.yteng3456.xyz`，后来我也在这个域名上部署了php搭建的个人页面以及在复习专业课时总结的一些文章，但是后面时间到了域名失效了，如果要用还得重新备案；虚拟主机的资源也失效了，为了折腾，就把写的文章搬到了Hexo+Github去，就当是体验了一把个人网站上云。\n\n## 2021.06.30\n\nhexo 文章插图技巧\n1.站点的_config.yml 的post_asset_folder: false改为true\n2.在新建文章的时候`hexo new hello`就会在文章下生成同名文件夹，在文件夹中放图片，在文章中引用即可。\n\n```\n![](1.png)\n```\n\nhexo源码等保留到了github，换了电脑或者笔记本重装系统后需要重新部署环境\n\n- 安装git，配置git账号信息，ssh key\n- 安装nodejs\n- 安装hexo `npm install -g hexo-cli `\n- 安装git部署插件 `npm install hexo-deployer-git --save`\n- 安装图片路径转换插件 `npm install https://github.com/CodeFalling/hexo-asset-image --save`\n\n`hexo d`失败，报错：`typeError [ERR_INVALID_ARG_TYPE]: The \"mode\" argument must be integer. Received an instance of Object`\n原因：nodejs版本过高，和hexo版本不匹配\n解决办法：切换nodejs为低版本\n\n## 2021.08.15\n\nhexo文章编写技巧\n\n`<!--more-->`该标签前面可以写文章摘要\n\n`<center><center/>` 该标签可以把摘要居中\n\n`<br/>`该标签可以插入一个换行\n\n可以不用`![]`来插入图片，可以使用`<img src='' width='20' height='20>`来插入图片\n\n## 2022.05.22\n\n参考别人的主题进行了一次改版，参考网站：`https://godweiyang.com/`\nMatery主题美化参考：`https://blog.csdn.net/kuashijidexibao/article/details/112971657`\n为什么要改版？\n因为之前的风格看的有些厌倦，不能让我很好的坚持写博客，不如换一个风格。\n\n| 配置选项          | 默认值                     | 描述                                                                                                   |\n| ------------- | ----------------------- | ---------------------------------------------------------------------------------------------------- |\n| title         | markdown文件标题            | 文章标题，强烈建议填写此选项                                                                                       |\n| date          | 文件创建时的日期时间              |                                                                                                      |\n| author        | 根 _config.yml 中的 author |                                                                                                      |\n| img           | featureImages 中的某个值     | 文章特征图，推荐使用图床                                                                                         |\n| top           | true                    | 推荐文章(文章是否置顶)，如果top为true，则会作为首页推荐文章                                                                   |\n| cover         | false                   | 表示该文章是否需要加入到首页轮播封面                                                                                   |\n| coverImg      | 无                       | 表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片                                                              |\n| password      | 无                       | 文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置                                                                        |\n| toc           | true                    | 是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项                                         |\n| mathjax       | false                   | 是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行                                           |\n| summary       | 无                       | 文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要                                          |\n| categories    | 无                       | 文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类                                                                     |\n| tags          | 无                       | 文章标签，一篇文章可以多个标签                                                                                      |\n| reprintPolicy | cc_by                   | 文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个 |\n","source":"_posts/hexo_new.md","raw":"---\ntitle: Hello, Hexo\ntop: true\ncover: false\ntoc: true\nimg: /medias/files/hexo.png\nmathjax: true\ndate: 2020-01-14 15:27:31\npassword:\nsummary: Hexo是一个快速, 简洁且高效的博客框架. 让上百个页面在几秒内瞬间完成渲染. Hexo支持Github Flavored Markdown的所有功能, 甚至可以整合Octopress的大多数插件. 并自己也拥有强大的插件系统.\ntags:\n- Hexo\ncategories:\n- 随笔\n---\n\n> Hexo是本次新挖掘出来的搭建网站的快速工具，容易上手，且样式好看。\n\n### 起源\n\n一直想要一个永久的域名，但是在学生时代经费紧张，就只能先这么凑合了。偶然有一次看到了Hexo + Github搭建个人网站的例子，Hexo是一款强大的产品，可以快速的生成页面。我也有尝试另外一款是wordpress，但是我本地测试后还有很多不易用的感受，而且我也不是专业的前端程序员，而Hexo可以根据网上的教程快速的搭建成自己舒服的样子，所以就被我pick。今天正式启用此站点，Hello Hexo！\n\n## 2020.6.26\n\n一次偶然的机会看到百度云可以1元得到一个域名和一个虚拟主机资源，所以产生了`www.yteng3456.xyz`，后来我也在这个域名上部署了php搭建的个人页面以及在复习专业课时总结的一些文章，但是后面时间到了域名失效了，如果要用还得重新备案；虚拟主机的资源也失效了，为了折腾，就把写的文章搬到了Hexo+Github去，就当是体验了一把个人网站上云。\n\n## 2021.06.30\n\nhexo 文章插图技巧\n1.站点的_config.yml 的post_asset_folder: false改为true\n2.在新建文章的时候`hexo new hello`就会在文章下生成同名文件夹，在文件夹中放图片，在文章中引用即可。\n\n```\n![](1.png)\n```\n\nhexo源码等保留到了github，换了电脑或者笔记本重装系统后需要重新部署环境\n\n- 安装git，配置git账号信息，ssh key\n- 安装nodejs\n- 安装hexo `npm install -g hexo-cli `\n- 安装git部署插件 `npm install hexo-deployer-git --save`\n- 安装图片路径转换插件 `npm install https://github.com/CodeFalling/hexo-asset-image --save`\n\n`hexo d`失败，报错：`typeError [ERR_INVALID_ARG_TYPE]: The \"mode\" argument must be integer. Received an instance of Object`\n原因：nodejs版本过高，和hexo版本不匹配\n解决办法：切换nodejs为低版本\n\n## 2021.08.15\n\nhexo文章编写技巧\n\n`<!--more-->`该标签前面可以写文章摘要\n\n`<center><center/>` 该标签可以把摘要居中\n\n`<br/>`该标签可以插入一个换行\n\n可以不用`![]`来插入图片，可以使用`<img src='' width='20' height='20>`来插入图片\n\n## 2022.05.22\n\n参考别人的主题进行了一次改版，参考网站：`https://godweiyang.com/`\nMatery主题美化参考：`https://blog.csdn.net/kuashijidexibao/article/details/112971657`\n为什么要改版？\n因为之前的风格看的有些厌倦，不能让我很好的坚持写博客，不如换一个风格。\n\n| 配置选项          | 默认值                     | 描述                                                                                                   |\n| ------------- | ----------------------- | ---------------------------------------------------------------------------------------------------- |\n| title         | markdown文件标题            | 文章标题，强烈建议填写此选项                                                                                       |\n| date          | 文件创建时的日期时间              |                                                                                                      |\n| author        | 根 _config.yml 中的 author |                                                                                                      |\n| img           | featureImages 中的某个值     | 文章特征图，推荐使用图床                                                                                         |\n| top           | true                    | 推荐文章(文章是否置顶)，如果top为true，则会作为首页推荐文章                                                                   |\n| cover         | false                   | 表示该文章是否需要加入到首页轮播封面                                                                                   |\n| coverImg      | 无                       | 表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片                                                              |\n| password      | 无                       | 文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置                                                                        |\n| toc           | true                    | 是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项                                         |\n| mathjax       | false                   | 是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行                                           |\n| summary       | 无                       | 文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要                                          |\n| categories    | 无                       | 文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类                                                                     |\n| tags          | 无                       | 文章标签，一篇文章可以多个标签                                                                                      |\n| reprintPolicy | cc_by                   | 文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个 |\n","slug":"hexo_new","published":1,"updated":"2022-07-04T14:25:15.525Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9h000aagvtaxknxyi2","content":"<blockquote>\n<p>Hexo是本次新挖掘出来的搭建网站的快速工具，容易上手，且样式好看。</p>\n</blockquote>\n<h3 id=\"起源\"><a href=\"#起源\" class=\"headerlink\" title=\"起源\"></a>起源</h3><p>一直想要一个永久的域名，但是在学生时代经费紧张，就只能先这么凑合了。偶然有一次看到了Hexo + Github搭建个人网站的例子，Hexo是一款强大的产品，可以快速的生成页面。我也有尝试另外一款是wordpress，但是我本地测试后还有很多不易用的感受，而且我也不是专业的前端程序员，而Hexo可以根据网上的教程快速的搭建成自己舒服的样子，所以就被我pick。今天正式启用此站点，Hello Hexo！</p>\n<h2 id=\"2020-6-26\"><a href=\"#2020-6-26\" class=\"headerlink\" title=\"2020.6.26\"></a>2020.6.26</h2><p>一次偶然的机会看到百度云可以1元得到一个域名和一个虚拟主机资源，所以产生了<code>www.yteng3456.xyz</code>，后来我也在这个域名上部署了php搭建的个人页面以及在复习专业课时总结的一些文章，但是后面时间到了域名失效了，如果要用还得重新备案；虚拟主机的资源也失效了，为了折腾，就把写的文章搬到了Hexo+Github去，就当是体验了一把个人网站上云。</p>\n<h2 id=\"2021-06-30\"><a href=\"#2021-06-30\" class=\"headerlink\" title=\"2021.06.30\"></a>2021.06.30</h2><p>hexo 文章插图技巧<br>1.站点的_config.yml 的post_asset_folder: false改为true<br>2.在新建文章的时候<code>hexo new hello</code>就会在文章下生成同名文件夹，在文件夹中放图片，在文章中引用即可。</p>\n<pre><code>![](1.png)</code></pre><p>hexo源码等保留到了github，换了电脑或者笔记本重装系统后需要重新部署环境</p>\n<ul>\n<li>安装git，配置git账号信息，ssh key</li>\n<li>安装nodejs</li>\n<li>安装hexo <code>npm install -g hexo-cli</code></li>\n<li>安装git部署插件 <code>npm install hexo-deployer-git --save</code></li>\n<li>安装图片路径转换插件 <code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code></li>\n</ul>\n<p><code>hexo d</code>失败，报错：<code>typeError [ERR_INVALID_ARG_TYPE]: The &quot;mode&quot; argument must be integer. Received an instance of Object</code><br>原因：nodejs版本过高，和hexo版本不匹配<br>解决办法：切换nodejs为低版本</p>\n<h2 id=\"2021-08-15\"><a href=\"#2021-08-15\" class=\"headerlink\" title=\"2021.08.15\"></a>2021.08.15</h2><p>hexo文章编写技巧</p>\n<p><code>&lt;!--more--&gt;</code>该标签前面可以写文章摘要</p>\n<p><code>&lt;center&gt;&lt;center/&gt;</code> 该标签可以把摘要居中</p>\n<p><code>&lt;br/&gt;</code>该标签可以插入一个换行</p>\n<p>可以不用<code>![]</code>来插入图片，可以使用<code>&lt;img src=&#39;&#39; width=&#39;20&#39; height=&#39;20&gt;</code>来插入图片</p>\n<h2 id=\"2022-05-22\"><a href=\"#2022-05-22\" class=\"headerlink\" title=\"2022.05.22\"></a>2022.05.22</h2><p>参考别人的主题进行了一次改版，参考网站：<code>https://godweiyang.com/</code><br>Matery主题美化参考：<code>https://blog.csdn.net/kuashijidexibao/article/details/112971657</code><br>为什么要改版？<br>因为之前的风格看的有些厌倦，不能让我很好的坚持写博客，不如换一个风格。</p>\n<table>\n<thead>\n<tr>\n<th>配置选项</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>title</td>\n<td>markdown文件标题</td>\n<td>文章标题，强烈建议填写此选项</td>\n</tr>\n<tr>\n<td>date</td>\n<td>文件创建时的日期时间</td>\n<td></td>\n</tr>\n<tr>\n<td>author</td>\n<td>根 _config.yml 中的 author</td>\n<td></td>\n</tr>\n<tr>\n<td>img</td>\n<td>featureImages 中的某个值</td>\n<td>文章特征图，推荐使用图床</td>\n</tr>\n<tr>\n<td>top</td>\n<td>true</td>\n<td>推荐文章(文章是否置顶)，如果top为true，则会作为首页推荐文章</td>\n</tr>\n<tr>\n<td>cover</td>\n<td>false</td>\n<td>表示该文章是否需要加入到首页轮播封面</td>\n</tr>\n<tr>\n<td>coverImg</td>\n<td>无</td>\n<td>表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td>\n</tr>\n<tr>\n<td>password</td>\n<td>无</td>\n<td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置</td>\n</tr>\n<tr>\n<td>toc</td>\n<td>true</td>\n<td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项</td>\n</tr>\n<tr>\n<td>mathjax</td>\n<td>false</td>\n<td>是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行</td>\n</tr>\n<tr>\n<td>summary</td>\n<td>无</td>\n<td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td>\n</tr>\n<tr>\n<td>categories</td>\n<td>无</td>\n<td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td>\n</tr>\n<tr>\n<td>tags</td>\n<td>无</td>\n<td>文章标签，一篇文章可以多个标签</td>\n</tr>\n<tr>\n<td>reprintPolicy</td>\n<td>cc_by</td>\n<td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td>\n</tr>\n</tbody></table>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<blockquote>\n<p>Hexo是本次新挖掘出来的搭建网站的快速工具，容易上手，且样式好看。</p>\n</blockquote>\n<h3 id=\"起源\"><a href=\"#起源\" class=\"headerlink\" title=\"起源\"></a>起源</h3><p>一直想要一个永久的域名，但是在学生时代经费紧张，就只能先这么凑合了。偶然有一次看到了Hexo + Github搭建个人网站的例子，Hexo是一款强大的产品，可以快速的生成页面。我也有尝试另外一款是wordpress，但是我本地测试后还有很多不易用的感受，而且我也不是专业的前端程序员，而Hexo可以根据网上的教程快速的搭建成自己舒服的样子，所以就被我pick。今天正式启用此站点，Hello Hexo！</p>\n<h2 id=\"2020-6-26\"><a href=\"#2020-6-26\" class=\"headerlink\" title=\"2020.6.26\"></a>2020.6.26</h2><p>一次偶然的机会看到百度云可以1元得到一个域名和一个虚拟主机资源，所以产生了<code>www.yteng3456.xyz</code>，后来我也在这个域名上部署了php搭建的个人页面以及在复习专业课时总结的一些文章，但是后面时间到了域名失效了，如果要用还得重新备案；虚拟主机的资源也失效了，为了折腾，就把写的文章搬到了Hexo+Github去，就当是体验了一把个人网站上云。</p>\n<h2 id=\"2021-06-30\"><a href=\"#2021-06-30\" class=\"headerlink\" title=\"2021.06.30\"></a>2021.06.30</h2><p>hexo 文章插图技巧<br>1.站点的_config.yml 的post_asset_folder: false改为true<br>2.在新建文章的时候<code>hexo new hello</code>就会在文章下生成同名文件夹，在文件夹中放图片，在文章中引用即可。</p>\n<pre><code>![](1.png)</code></pre><p>hexo源码等保留到了github，换了电脑或者笔记本重装系统后需要重新部署环境</p>\n<ul>\n<li>安装git，配置git账号信息，ssh key</li>\n<li>安装nodejs</li>\n<li>安装hexo <code>npm install -g hexo-cli</code></li>\n<li>安装git部署插件 <code>npm install hexo-deployer-git --save</code></li>\n<li>安装图片路径转换插件 <code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code></li>\n</ul>\n<p><code>hexo d</code>失败，报错：<code>typeError [ERR_INVALID_ARG_TYPE]: The &quot;mode&quot; argument must be integer. Received an instance of Object</code><br>原因：nodejs版本过高，和hexo版本不匹配<br>解决办法：切换nodejs为低版本</p>\n<h2 id=\"2021-08-15\"><a href=\"#2021-08-15\" class=\"headerlink\" title=\"2021.08.15\"></a>2021.08.15</h2><p>hexo文章编写技巧</p>\n<p><code>&lt;!--more--&gt;</code>该标签前面可以写文章摘要</p>\n<p><code>&lt;center&gt;&lt;center/&gt;</code> 该标签可以把摘要居中</p>\n<p><code>&lt;br/&gt;</code>该标签可以插入一个换行</p>\n<p>可以不用<code>![]</code>来插入图片，可以使用<code>&lt;img src=&#39;&#39; width=&#39;20&#39; height=&#39;20&gt;</code>来插入图片</p>\n<h2 id=\"2022-05-22\"><a href=\"#2022-05-22\" class=\"headerlink\" title=\"2022.05.22\"></a>2022.05.22</h2><p>参考别人的主题进行了一次改版，参考网站：<code>https://godweiyang.com/</code><br>Matery主题美化参考：<code>https://blog.csdn.net/kuashijidexibao/article/details/112971657</code><br>为什么要改版？<br>因为之前的风格看的有些厌倦，不能让我很好的坚持写博客，不如换一个风格。</p>\n<table>\n<thead>\n<tr>\n<th>配置选项</th>\n<th>默认值</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>title</td>\n<td>markdown文件标题</td>\n<td>文章标题，强烈建议填写此选项</td>\n</tr>\n<tr>\n<td>date</td>\n<td>文件创建时的日期时间</td>\n<td></td>\n</tr>\n<tr>\n<td>author</td>\n<td>根 _config.yml 中的 author</td>\n<td></td>\n</tr>\n<tr>\n<td>img</td>\n<td>featureImages 中的某个值</td>\n<td>文章特征图，推荐使用图床</td>\n</tr>\n<tr>\n<td>top</td>\n<td>true</td>\n<td>推荐文章(文章是否置顶)，如果top为true，则会作为首页推荐文章</td>\n</tr>\n<tr>\n<td>cover</td>\n<td>false</td>\n<td>表示该文章是否需要加入到首页轮播封面</td>\n</tr>\n<tr>\n<td>coverImg</td>\n<td>无</td>\n<td>表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td>\n</tr>\n<tr>\n<td>password</td>\n<td>无</td>\n<td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置</td>\n</tr>\n<tr>\n<td>toc</td>\n<td>true</td>\n<td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项</td>\n</tr>\n<tr>\n<td>mathjax</td>\n<td>false</td>\n<td>是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行</td>\n</tr>\n<tr>\n<td>summary</td>\n<td>无</td>\n<td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td>\n</tr>\n<tr>\n<td>categories</td>\n<td>无</td>\n<td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td>\n</tr>\n<tr>\n<td>tags</td>\n<td>无</td>\n<td>文章标签，一篇文章可以多个标签</td>\n</tr>\n<tr>\n<td>reprintPolicy</td>\n<td>cc_by</td>\n<td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td>\n</tr>\n</tbody></table>\n"},{"title":"kafka - 生产者消费者","img":"/medias/files/kafka.png","summary":"一个有名的多分区多副本且基于ZooKeeper协调的分布式消息系统，高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性被使用。","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-10-16T06:08:24.000Z","password":null,"_content":"\nkafka角色：\n- 消息系统：Kafka和传统的消息系统都具备系统解耦性、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。Kafka还提供大多数消息系统难以实现的消息顺序性保障和回溯消费功能\n- 存储系统：Kafka把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于Kafka的消息持久化功能和多副本机制，我们可以吧Kafka作为长期对的数据存储系统来使用。\n- 流式处理平台：Kafka不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库\n\n# 初识Kafka\n\n\n\n## 基本概念\n\n- Producer：生产者，也就是发送消息的一方，生产者负责创建消息，然后将其投递到Kafka中\n- Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理\n- Broker：服务代理结点：对于Kafka而言，Broker可以简单的看做一个独立的Kafka服务结点或Kafka服务实例。\n- 主题：Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题，而消费者负责订阅主题并进行消费\n- 分区：一个分区只属于单个主题，同一主题下不同分区包含的消息是不同的，分区在存储层面可以看做一个可追加的日志文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量。如果一个主题只对应一个文件，那么这个文件所在的机器IO将会成功这个主题的性能瓶颈，而通过增加分区的数量可以实现水平扩展。\n- Offset偏移量：offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，Kafka保证分区有序而不是主题有序\n- 副本因子：副本个数；通过增加副本数量可以提升容灾能力，leader副本负责处理读写请求，follower副本负责与leader副本消息同步。当leader副本出现故障时，从follower副本中重新选举leader副本对外提供服务。kafka通过多副本机制实现了故障的自动转移。\n- AR：分区内所有副本(assigned replicas)\n- ISR:所有与leader副本保持一定程度同步的副本(in-sync replicas)\n- OSR:与leader副本同步滞后过多的副本 (out-of-sync replicas)\n- HW:高水位：标识一个特定的offset，消费者只能拉取到这个offset之前的消息 (high watermark)\n- LEO: 标识当前日志文件中下一条待写入消息的offset (Log End Offset)\n\n新产生的消息会先写入leader副本，然后follower副本会发送拉取请求来拉取落后的消息来进行消息同步。\n当同步完成后，消费者才可以消费这条消息(为了防止leader副本宕机造成消息丢失)\nkafka的复制机制既不是完全的同步复制，也不是单纯的落后复制。同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认为已成功提交，这种方式极大的影响了性能。而在异步复制方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就认为已经成功提交。(在这种情况下，如果follower副本都还没有复制完而落后与leader副本，突然leader副本宕机，则会造成数据丢失)。\n\n![](kafka-producer-consumer/img-20221016191323.png)\n\n\n## 生产与消费\n\n\n```\n./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-demo --replication-factor 3 --partitions 4\n\n\n./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-demo \n\n./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic-demo\n\n./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic-demo\n```\n\n`zookeeper.connect`  zk集群服务地址\n`listeners` broker监听客户端连接的地址列表\n`broker.id` broker的唯一标识\n`log.dir` kafka日志文件存放的目录，默认/tmp/kafka-logs\n`log.dirs` 优先级高\n`message.max.bytes` broker所能接收消息的最大值\n\n# 生产者\n\n## 生产者客户端开发\n步骤：\n1. 配置生产者客户端参数及创建相应的生产者实例\n2. 构建待发送的消息\n3. 发送消息\n4. 关闭生产者实例\n\n```java\npublic static Properties initConfig() {\n\tProperties props = new Properties();\n\tprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n}\n\npublic static void main(String[] args) {\n\tProperties props = initConfig();\n\tKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\tProducerRecord<String, String> record = new ProducerRecord<>(topic, \"Hello, Kafka\");\n\t\n\ttry {\n\t\tproducer.send(record);\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n}\n```\n\n\n\n消息对象ProducerRecord 并不是单纯意义上的消息，包含了多个属性\n\n```java\npublic class ProducerRecord<K, V> {\n\tprivate final String topic;\n\tprivate final Integer paitition;\n\tprivate final Headers headers;\n\tprivate final K key;\n\tprivate final V value;\n\tprivate final Long timestamp;\n}\n```\n\n`bootstrap.servers` 指定生产者客户端连接kafka所需的broker地址清单\n`key.serializer` 序列化成字节数组\n`value.serializer`\n\n- KafkaProducer是线程安全的，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化来供其他线程调用\n\n- 构建ProducerRecord 对象，topic属性和value属性是必填，其他选填\n\n\n\n### 发送消息\n\n发送消息的三种模式\n发后即忘：send方法不指定Callback，性能最高，可靠性最差\n\n同步：send方法利用返回的Future对象，阻塞等待Kafka响应\n\n异步：send方法，指定Callback回调函数\n\n\n\n可重试异常和不可重试异常\n\n对于可重试异常，如果配置了retries参数，那么只要在规定的重试次数内自行恢复，就不会抛出异常\n\n对于不可重试的异常，则直接抛出异常，不进行重试\n\n\n\n对于同一个分区而言，如果消息record1先与record2发送，那么KafkaProducer就可以保证对应的callback1先与callback2调用\n\n\n\n### 序列化器\n\n生产者需要使用序列化器将对象转换成字节数组，才能通过网络发送给Kafka，在对端消费者使用反序列化器把Kafka转换成相应的对象\n\n\n\n序列化器实现了org.apache.kafka.common.serialization.Serializer接口\n\n一般要实现\n\n```java\npublic void configure(Map<String, ?>configs,boolean isKey)\npublic byte[]serialize(String topic, T data)\npublic void close()\n```\n\n\n\n可以使用Avro、JSON、Thrift、Protobuf、Protostuff等通用工具来实现\n\n\n\n### 分区器\n\n\n\n```java\npublic int partition(String topic, Object key,byte[] keyBytes, Object Value, byte[] valueBytes,Cluster cluster);\npublic void close();\n```\n\n\n\n- 如果ProducerRecord中指定了partition字段，则不需要分区器，partition字段就是要发往的分区号\n\n- 如果没有指定分区器，就需要分区器根据key字段来计算partition值。Kafka的默认分区器实现了 xx.Partitioner接口，接口中有partition方法和close方法\n  默认分区器会判断key不为null，则对key进行哈希，最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息会以轮询的方式发往主题内的某一个可用分区\n\n  \n  自定义分区器也只需实现上述接口即可\n\n\n\n### 生产者拦截器\n\n消息发送前做一些过滤，修改等等\n\n需要自定义实现ProducerInterceptor接口\n\n\n\nKafkaProducer会在消息被应答之前或消息发送失败时调用拦截器的onAcknowledgement方法，优于用户设定的Callback之前执行。\n\n```java\npublic ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);\npublic void onAcknowledgement(RecordMetadata metadata, Exception exception);\npublic void close();\n```\n\n\n\n可以指定一个拦截链，KafkaProducer按照interceptor.classes参数配置的拦截器的顺序来一一执行（各个拦截器按逗号隔开）\n\n\n## 原理分析\n\n### 整体架构\n\n\n\n![生产者客户端整体架构](kafka-producer-consumer/producer-structure.jpg)\n\n\n\n生产者客户端有两个线程，主线程和Sender线程。主线程生产消息经过拦截器、序列化器、分区器缓存到消息累加器中，Sender线程从RecordAccumulator中获取消息并发往Kafka中\n\n\n\n`buffer.memory`： 指定RecordAccumulator缓存的大小\n\n`max.block.ms`：指定生产者发送太快，缓冲区满了，阻塞的最大时间\n\nRecordAccumulator缓存的大小由buffer.memory配置；如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时候producer的send方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的设置。\n\n\nRecordAccumulator为每个分区维护一个双端队列，队列内容为ProducerBatch，ProducerBatch为一个至多个ProducerRecord；可以使得生产者创建的消息组成一个批次，更为紧凑。\n\n\n\n消息在网络上传输是以字节传输的，发送之前要创建内存区域。kafka生产者中，通过java.io.ByteBuffer实现消息内存创建和释放。RecordAccumulator内部还有一个BufferPool，实现ByteBuffer的复用。BufferPool只针对特定大小的ByteBuffer进行管理，这个大小由`batch.size`指定。\n\n`batch.size` 指定ByteBuffer的大小\n\n\n\nProducerBatch的大小和batch.size相关。当一条ProducerRecord消息到了RecordAccumulator，会先寻找与分区对应的双端队列(如果没有则新建)，再从尾部获取一个ProducerBatch，查看该ProducerBatch中是否还可以写入这个ProducerRecord，可以写入则写入，不可以写入则新建ProducerBatch。\n\n新建ProducerBatch时，判断这条ProducerRecord消息大小是否超过batch.size没超过，则就以batch.size的大小新建ProducerBatch，这段内存还可以由ByterBuffer复用；如果超过了则以评估的大小新建ProducerBatch，这段内存不会被复用。\n\n\n\nSender从RecordAccumulator获取缓存的消息后，进一步将原本的`<分区，Deque<ProducerBatch>>` 转换为 `<Node, List<ProducerBatch>>`Node表示kafka集群的结点。生产者向具体的broker结点发消息。\n\nSender还会进一步封装为`<Node, Request>`才发往各个Node，请求在从Sender发往kafka之前会保存到InFlightRequests中，保存形式为`Map<NodeId, Deque<Request>>`主要作用是缓存了已经发出去，但是还没有收到响应的请求。\n\n这里限制了每个连接最多缓存的请求数，由`max.in.flight.requests.per.connecttion`指定，默认为5\n\n\n\n### 元数据的更新\n\nNode中未确认的请求越多，则认为负载越大。\n\n选择leastLoadedNode发送请求可以使它能尽快发出，避免网络拥塞等异常的影响。\nleastLoadedNode，即所有Node中负载最小的。\n\nleastLoadedNode还可以用于**元数据请求**、**消费者组播协议的交互**\n\n\n如果发送一个很简单的消息\n\n```\nProducerRecord<string, string> record = new ProducerRecord<>(topic, \"hello\");\n```\n\n这里只有主题和消息\nKafkaProducer需要将消息追加到指定主题的某个分区的对应leader副本之前。需要知道分区数目，计算出目标分区，需要知道目标分区的leader副本所在broker结点的地址、端口信息。这些需要的信息都属于**元数据信息**。\n\n\nbootstrap.servers参数只需要配置部分broker结点的地址，客户端可以发现其他broker结点的地址，这一过程属于元数据更新。\n\n客户端没有元数据信息时，会先选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作由Sender线程发起，在创建完MetadataRequest后同样会存入inFlightRequests。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里数据同步通过synchronized 和 final关键字保障。\n\n\n\n### 重要的生产者参数\n\n`acks`：指定分区中必须要有多少副本收到这条消息，之后生产者才会认为这条消息是成功写入的。\n\n默认acks = 1\n\nacks = 0 生产者发送消息之后不需要等待任何服务端响应\n\n`max.request.size` 客户端能发送消息的最大值\n\nretries 和 retry.backoff.ms\n\n`retries`是生产者重试的次数\n\n`retry.backoff.ms` 两次重试之间的间隔，默认100ms\n\n`compression.type` 默认值为none，指定消息压缩\n\n`connections.max.idle.ms` 指定在多久之后关闭闲置的连接\n\n`linger.ms` 指定生产者发送ProducerBatch之前等待更多ProducerRecord加入的时间\n\n`receive.buffer.bytes` 设置Socket接收消息缓冲区大小  默认32kb\n\n`send.buffer.bytes` Socket发送消息缓冲区大小\n\n`request.timeout.ms` 配置Producer等待请求响应的最长时间，默认30000ms\n\n\n\n# 消费者\n\n\n\n## 消费者与消费者组\n\n每个消费者都有一个对应的消费者组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。\n\n每个消费组消费全部分区的消息。\n\n消费者与消费组这种模型又可以让整体的消费能力具备横向伸缩性，我们可以增加消费者的个数来提高整体的消费能力。对于分区数固定的情况，一直增加消费者，到消费者个数超过分区数，就会有消费者分配不到分区。\n\n\n消息投递模式：\n点对点模式：基于队列，消息生产者发送消息到队列，消费者从消息队列中接收消息。\n\n发布订阅模式：定义了如何想一个内容节点发布和订阅消息，这个内容节点叫做主题，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布订阅模式在消息的一对多广播时采用。\n\nkafka同时支持两种消息投递模式。\n\n- 如果所有的消费者隶属于一个消费者组，那么所有的消息都会被均衡的投递给每一个消费者，即每条消息只会被一个消费者处理，这相当于点对点。\n- 如果所有的消费者隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息都会被所有的消费者处理，相当于发布订阅模式应用。\n\n\n\n消费组是一个逻辑概念，每个消费者在消费前需要指定所属消费组的名称，由`group.id`指定。消费者是实际的应用实例，可以是一个线程，也可以是一个进程，同一个消费组的消费者既可以部署在同一机器上，也可以部署在不同机器上。\n\n\n\n## 客户端开发\n\n1. 配置消费者客户端参数以及创建相应的消费者实例\n2. 订阅主题\n3. 拉取消息并消费\n4. 提交消费位移\n5. 关闭消费者实例\n\n```java\npublic class KafkaConsumerAnalysis {\n\tpublic static final String brokerList = \"\";\n\t...\n\t\n\tpublic static Properties initConfig() {\n\t\tProperties props = new Properties();\n\t\tprops.put(\"bootstrap.servers\", brokerList);\n\t}\n\t\n\tpublic static void main() {\n\t\tProperties props = initConfig();\n\t\tKafkaConsumer<String, String> consumer = new KafkaConsmer<>(props);\n\t\tconsumer.subscribe(Arrays.asList(topic));\n\t\t\n\t\ttry {\n\t\t\twhile(isRunning.get()) {\n\t\t\t\tConsumerRecrds<String, String> records = consumer.poll(Duration.ofMillis(1000));\n\t\t\t\t\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"\");\n\t\t\t} finally {\n\t\t\t\tconsumer.close();\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n\n\n### 必要的参数配置\n\n`bootstrap.servers` 集群broker地址\n\n`group.id` 消费者组名称\n\n`key.deserializer`  反序列化\n\n`value.deserializer`\n\n参数众多，直接使用org.apache.kafka.clients.consumer.ConsumerConfig\n\n每个参数在ConsumerConfig类中都有对应的名称\n\n如ConsumerConfig.GROUP_ID_CONFIG\n\n\n\n### 订阅主题与分区\n\n一个消费者可以订阅一个或多个主题，subscribe的几个重载方法\n\n```java\npublic void subscribe(Collection<String> topics, ConsumerRebalanceListener listener);\npublic void subscribe(Collection<String> topics);\npublic void subscribe(Pattern pattern, ConsumerRebalanceListener listener);\npublic void subscribe(Pattern pattern);\n```\n\n\n\n1.集合方式，`subscribe(Collection<String> topics)`订阅了什么就消费什么主题的消息。\n\n2.正则表达式，如果采用正则表达式的方式，在之后如果有人创建了新的主题，且主题名字与正则表达式匹配，那么这个消费者就可以消费到新添加的主题中的消息。\n例 `cosumer.subscribe(Pattern.compile(\"topic.*\"))`\n参数类型`ConsumerRebalanceListener`，设置的是再均衡监听器\n\n3.消费者还能直接订阅某些主题的特定分区\n\n```java\npublic void assign(Collection<TopicPartition> partitions);\n```\n例：`public List<PartitionInfo> partitionsFor(String topic)`\n\n\nTopicPartition类表示分区\n\n```java\npublic final class TopicPartition implements Serializable {\n\tprivate final int partition; //分区\n\tprivate final String topic; //主题\n\t...\n}\n```\n\n\n\n如果事先不知道主题中有多少分区，则使用partitionsFor()方法查询指定主题的元数据信息\n\n```java\npublic List<PartitionInfo> partitionsFor(String topic)\n\npublic class PartitionInfo {\n\tprivate final String topic;\n\tprivate final int paitition;\n\tprivate final Node leader;\n\tprivate final Node[] replicas;  //AR\n\tprivate final Node[] inSyncReplicas; //ISR\n\tprivate final Node offlineReplicas;  //OSR\n}\n```\n\n\n\n取消订阅\n\n```java\nconsumer.unsubscribe()\n```\n\n如果没有订阅任何主题或分区，那么继续执行消费程序会报异常IllegalStateException\n\n\n\n订阅状态:\n集合订阅  `AUTO_TOPICS`\n正则表达式订阅 `AUTO_PATTERN`\n指定分区订阅 `USER_ASSIGNED`\n\n通过subscribe()方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下，可以根据分区分配策略来自动分配各个消费者与分区的关系。\n\n### 反序列化\n\n反序列化器也实现了Deserializer接口，这个接口有以下三个方法：\n\n```java\npublic void configure(Map<String, ?> configs, boolean isKey)\npublic T deserialize(String topic, byte[] data)\npublic void close()\n```\n\n### 消息消费\n\n消费模式：推模式和拉模式\n推模式：服务端主动将消息推送给消费者\n拉模式：消费者主动向服务端发起请求来拉取消息\n\npoll方法定义:\n\n```java\npublic ConsumerRecords<K, V> poll(final Duration timeout) \n```\n\ntimeout参数用来控制poll方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞。\n\nConsumerRecord定义\n\n```java\npublic class ConsumerRecord<K, V> {\n  private final String topic;\n  private final int partition; \n  private final long offset; // 消息所属分区的偏移量\n  private final timestamp; \n  private final TimestampType timestampType;\n  private final int serializedKeySize;\n  private final int serializedValueSize;\n  private final Headers headers; // 消息的头部内容\n  private final K key;\n  private final V value;\n  private volatile Long checksum; // CRC32的校验值\n  // ...\n}\n```\n\n它提供了iterator方法来循环遍历消息集内部的消息\n\n`public Iterator<ConsumerRecord<K, V>> iterator()`\n\n它提供了获取消息集中指定分区消息的方法\n`public List<ConsumerRecord<K, V>> records(TopicPartition partition)`\n\n它还提供了按照主题维度来进行消费的方法\n`public Iterable<ConsumerRecord<K, V>> records(String topic)`\n\n\n### 位移提交\n\n对于kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。\n笔者对于消息在分区中的位置，这个offset称为‘偏移量’\n对于消费者消费到的位移，这个offset称为‘消费位移’\n\n\n在每次调用poll方法时，它返回的是还没有被消费过的消息集，要做到这一点就要记录上一次消费时的消费位移。\n消费位移要持久化保存，这个消费位移存储在kafka内部主题 `_consumer_offsets`中。消费者在消费完消息后需要执行消费位移的提交。\n\n当前消费到的位移x，即lastConsumedOffset；已经提交过的消费位移，即commited offset\n需要提交的位移 x + 1，表示下条需要拉去的消息的位置，即position\nposition = commited offset = lastConsumedOffset + 1\n\n```java\npublic long position(TopicPartition partition)\npublic OffsetAndMetadata committed(TopicPartition partition)\n```\n\n位移提交的时机需要把握，否则很容易引入消费混乱现象\n例：x 上一次提交的消费位移，[x, x+8]本次poll到的消息\n重复消费：\n如果是消费完所有拉取到的消息之后才执行提交，那么当消费到中间x+5消费者发生异常重启，则会重复从x开始拉取消费\n\n 消息丢失：\n如果拉取到消息之后就进行了位移提交x+8，那么当消费到中间x+5消费者发生异常重启，则直接从x+8开始消费，发生了消息丢失\n\n在kafka中默认的消费位移提交为自动提交，由参数`enable.auto.commit`配置；这个默认提交是定期提交，由参数`auto.commit.interval.ms`配置，自动位移提交的动作是在poll方法的逻辑里完成的。\n\n自动提交消费位移也可能造成消费混乱现象：\n重复消费：假设刚刚提交完消费位移，然后拉取一批消息进行消费，在下一次自动提交消费位移之前，消费者重启了，那么又得从上一次位移提交的地方重新开始消费。\n\n消息丢失；假设拉取线程A不断拉取存入本地缓存，消费线程B从缓存中读取，当已经提交的消费位移大于消费线程B消费到的消息，且发生重启时，就会发生消息丢失。\n\n手动提交方式：\n同步提交：\n`public void commitSync`\n`public void commitSync(final Map<TopicOartition, OffsetAndMetadata> offsets)`\n\n异步提交：\n`public void commitAsync`\n`public void commitAsync(OffsetCommitCallback callback)`\n`public void commitAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback)`\n\ncommitSync方法会根据poll方法拉取的最新位移来进行提交，只有没有发生不可恢复的错误，它就会阻塞消费者线程直至位移提交完成。\n\n带参数的commitSync方法提供了offsets参数，用来提交指定分区的位移。\n\n异步提交的方式在执行的时候消费者线程不会被阻塞，可能在提交消费位移的结果还未返回之前就开始了新一次的拉去操作。它提供的异步方法中支持指定回调函数，它会在位移提交完成后回调OffsetCommitCallback中的onComplete()方法。\n\n异步提交的时候同样会发生失败，如果消费位移提交了x失败， 下一次提交了x+y成功了，而这里前一步的提交x重试成功，那么消费位移又变成了x，这里消费者重启就会发生重复消费。\n要避免这个问题可以在位移提交失败需要重试的时候检查提交位移和前一个位移的大小，当发现小于前一个提交的位移大小，则说明有更大的位移已经提交了，可以不用本次重试。\n\n### 控制或关闭消费\n\npause和resume来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。\n\n```java\npublic void pause(Collection<TopicPartition> partitions)\npublic void resume(Collection<TopicPartition> partitions)\n```\n还可以检查被暂停的分区集合\n`public Set<TopicPartition> paused()`\n\nkafka consumer提供了close方法来实现关闭\n```java\npublic void close()\npublic void close(Duration timeout)\npublic void close(long timeout, TimeUnit timeUnit)\n```\n第一种方法没有timeout参数，并不意味着会无限制的等待，它内部设定了最长等待时间30s\n\n### 指定位移消费\n\n当一个新的消费组建立的时候，它根本没有可以查找的消费位移。或者消费组内的一个消费者订阅了一个新的主题，它也没有可以查找的消费位移。当_consumer_offsets主题中有关这个消费组的位移信息过期而被删除后，它没有可以查找的消费位移。\n\n`auto.offset.reset`参数配置当消费者查不到所记录的消费位移时，就会根据该配置来决定从何处开始消费\n可配置的值：\n`latest` ：从分区末尾开始消费消息\n`earliest` ：从起始处开始消费消息\n`none` ： 不从末尾也不从开始处开始消费，报NoOffsetForPartitionException异常\n\nseek方法提供了从特定位移处开始拉去消息的功能\n```java\npublic void seek(TopicPartition partition, long offset)\n```\nseek方法只能重置消费者分配到的分区的消费位置，而分区的分配是在poll方法的调用过程中实现的，也就是说，在执行seek方法之前需要先执行一次poll方法。\n\n```java\nKafkaConsumer <String String> consumer= new KafkaConsumer<> (props); \ncosumer.subscribe(Arrays asList(topic));\nconsumer.poll(Duratio ofMillis(10000) ; \nSet<TopicPartition> assignment = consumer.assignment(); \nfor (Top cPartition tp : assignment) { \nconsumer.seek(tp , 10); \nwhile (true) { \nConsumerRecords<String , String> records = consumer.poll(DurationofMllis(1000)); \n//consume the record .\n}\n```\n如果我们将代码清单 中第①行 poll （）方法的参数设置为 ，即这 行替换为\n`consumer poll(Duration.ofMillis(0)) ;`\n\n此之后， 会发现 seek（） 方法并未有任何作用。因为当 poll （）方法中 参数为0时，此方法立刻返回，那么 poll （） 方法内部进行分区分配的逻辑就会来不及实施。\n\n\n如果对未分配到的分区执行 seek（） 方法 那么会报出IllegalStateException 的异常。类似在调用 subscrib （） 方法之后直接调用 seek（） 方法\n\n```java\nconsumer.subscribe(Arrays.asList(topic)) ; \nconsumer.seek(new TopicPartition(topic, 0), 10 );\n```\n会报出如下的异常\njava.lang.I llegalStateException: No current assignment for partition topic- demo - 0\n\n\nseek的几个方法定义\n```java\npublic Map<Top cPartition Long> endOffsets( Collection<TopicPartition> partitions) \npublic Map<TopicPartition , Long> endOffsets( Collection<Top cPartit on> part tions\nDuration timeout)\n\npublic Map<TopicPartition , Long> beginningOff sets (Collection<TopicPartition> partitions) \npublic Map<TopicPart tion Long> beginningOffsets(Collection<TopicPartition> partitions, \nDuration timeout)\n\npublic void seekToBeginning(Collection<TopicPartition> partitions) \npublic void seekToEnd Collection<TopicPartition> partitions)\n\npublic Map<TopicPartition , OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> timestampsToSearch) \npublic Map<TopicPartition OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> t imestampsToSearch,Duration timeout )\n```\n\n### 再均衡\n\n再均衡是指分区的所属权从一个消费者转移到另一消费者的行为。在再均衡发生期间，消费组内的消费者是无法读取消息的。 就是说，在再均衡发生期间的这一小段时内，消费组会变得不可用 。\n\n比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作 之后这个分区又被分配给了消费组 的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。\n\n再均衡监听器\n\n```java\nvoid onPartitionsRevoked(Collection<TopicPartition> partitions)\nvoid onPartitionsAssigned(Collection<TopicPartition> partitions)\n```\n\n```java\nMap<TopicPartition, OffsetAndMetadata> currentOffsets =new HashMap<>() ; \nconsumer.subscribe(Arrays.asList(topic) , new ConsumerRebalanceListener () { \n@Override \npublic void onPartitionsRevoked(Collection<TopicPartition> part tions) { \nconsumer.commitSync(currentOffsets) ; \ncurrentOffsets.clear(); \n@Override\npublic void onPartitionsAssigned(Collection<TopicPartition partitions) { \n//do nothing . \n}) .,\n```\n\n### 消费者拦截器\n\n消费者拦截器需要自定义实现 org.apache.kafka.clients.consumer.Consumerlnterceptor 接口。\n```java\npublic ConsumerRecords<K, V> onConsume(ConsumerRecords<K , V> records);\npublic void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets);\npublic void close();\n```\n\n\nKafkaconsumer 会在 poll （）方法返回之前调用拦截器的 Consume（） 方法来对消息进行相应\n的定制 操作，KafkaConsumer 会在提交完消费位移之后调用拦截器的 onCommit（） 方法\n\n在消费者中也有拦截链的概念，和生产者的拦截链一样， 也是按照工interceptor classes参数配置的拦截器的顺序来一一执行的（配置的时候，各个拦截器之间使用逗号隔开）。同样也要提防“副作用”的发生 如果在拦截链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。\n\n### 多线程实现\n\nKatkaProducer 是线程安全的，然而 KafkaConsumer 却是非线程安全 KafkaConsumer定义了 acquire （） 方法，用来检测当前是否只有 个线程在操作，若有其他线程正在操作则会抛出 ConcurrentModifcationException 异常\n\n```java\nprivate final AtomicLong currentThread = new Atom cLong(NO CURRENT THREAD ); //Kaf aConsumer 中的成员变量\n\nprivate void acquire() { \nlong threadid = Thread.currentThread().getid();\nif (threadid != currentThread.get() && !currentThread.compareAndSet(NO_CURRENT THREAD, threadid) ) \nthrow new ConcurrentModificationException \n(\"KafkaConsumer is not safe for multi- threaded access \") ; \nrefcount.incrementAndGet();\n}\n```\n\nacquire（）方法和 release （）方法成对出现，表示相应的加锁和解锁操作。\n\n```java\nprivate void release() \nif (refcount.decrementAndGet () == 0) {\n\tcurrentThread.set(NO CURRENT THREAD);\n}\n```\n\n多线程的目的就是为了提高整体的消费能力。多线程的实现方式有多种，第一种也是最常见的方式 线程封闭，即为每个线程实例化一个 KafkaConsumer 对象。\n\n![](kafka-producer-consumer/img-20221030190716.png)\n\n一个消费线程可消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数，当消费线程的个数大于分区数时 就有部分消费线程一直处于空闲的状态。\n\n多个消费线程同时消费同一个分区 ，这个通过 assign（）、 seek （）等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力 。不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，\n\n```java\npublic static void main(String[] args) { \n\tProperties props = itConfig (); \n\tint consumerThreadNum = 4 ; \n\tfor(int i=O;i<consumerThreadNum;i++) { \n\tnew KafkaConsumerThread(props,topic).start();\n\t}\n}\n\npublic static class KafkaConsumerThread extends Thread{\n\tprivate KafkaConsumer<String , String> kafkaConsumer;\n\tpublic KafkaConsumerThread(Properties props, String topic) { \n\tthis.kafkaConsumer =new KafkaConsumer<>(props); \n\tthis.kafkaConsumer.subscribe(Arrays asList(topic));\n}\n\n\t@Override \n\tpublic void run() {\n\ttry { \n\t\twhile (true) { \n\t\tConsumerRecords<String, String> records = \n\t\tkafkaConsumer.poll (Duration.ofMill (1 00)) ; \n\t\tfor (ConsumerRecord<String, Stri g> record : records) { \n\t\t// 处理消息模块 ① \n\t\t}\n\t}\n\t} catch (Exception e) { \n\t\te.printStackTrace(); \n\t} finally { \n\t\tkafkaConsumer.close();\n\t}\n\t}\n```\n\n上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别， 优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的TCP 连接 如果分区数和 consumerThreadNum 的值都很大，那么会造成不 的系统开销。\n\n这里的处理速度取决于处理消息模块，。一般 言， poll（）拉取消息的速度是相当快的 ，而整体消费的瓶颈是在处理消息这一块， 通过－定的方式来改进这一部分，那么就能带动整体消费性能提升。\n\n![](kafka-producer-consumer/img-20221030193459.png)\n\n```java\n\t@Override \n\tpublic void run() {\n\ttry { \n\t\twhile (true) { \n\t\tConsumerRecords<String, String> records = \n\t\tkafkaConsumer.poll(Duration.ofMill (1 00)) ; \n\t\tif (!records.isEmpty () ) { \n\t\t\texecutorService.submit(new RecordsHandler(records));  // 调用各个hander处理消息\n\t\t}\n\t}\n\t} catch (Exception e) { \n\t\te.printStackTrace(); \n\t} finally { \n\t\tkafkaConsumer.close();\n\t}\n\t}\n\n\tpublic static class RecordsHandler extends Thread{ \n\tpublic final ConsumerRecords<String, String> records;\n\n\tpublic RecordsHandl er (ConsumerRecords<String, String> records) ( \n\t\tthis.records =records;\n\t}\n\n\t@Override \n\tpublic void run() {\n\t\t// 处理records\n\t}\n\t}\n\n```\n\nRecordHandler 类是用来处理消息的，而 KafraConsumerThread 类对应的是一个消费线程，里面通过线程池的方式来调用 RecordHandler 处理一批批的消息。\n\n引入一个共享\n变量 offsets 来参与提交\n\n![](kafka-producer-consumer/img-20221030200350.png)\n\n每一个处理消息的 RecordHandler 类在处理完消息之后都将对应的消费位移保存到共享变量offsets 中， KafraConsumerThread 在每一次 poll （）方法之后都读取 offsets 中的内容并对其进行位移提交。\n\n```java\nfor (TopicPartition tp : records .partitions()) { \n\tList<ConsumerRecord<String , String> tpRecords = records . records(tp); \n\t// 处 tpRec ords\n\tlong lastConsumedOffset = tpRecords . get (tpRecords. size() - 1) . offset() ; \n\tsynchronized (offsets) { \n\t\tif offsets.co ta 工口 sKey (tp)) { \n\t\t\toffsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + l)) ; \n\t\t} else { \n\t\t\tlong position = offsets . get(tp) .offset() ; \n\t\t\tif (position < lastConsumedOffset + 1) { \n\t\t\toffsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + l))\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n```java\nsynchronized (offsets) { \nif (!offsets. isEmpty () ) { \n\tkafkaConsumer.commitSync(offsets); \n\toffsets.clear();\n\t}\n}\n```\n\n假设一个处理线程 RecordHand erl 正在处理 offset 99消息，而另一个处理线程 RecordHand er2 己经处理完了 offset 100 99 的消息并进行了位移提交，此时如果 RecordHandler 发生异常，则之后的消费只能从 200 开始而无法再次消费 99的消息，从而造成了消息丢失的现象。这里虽然针对位移覆盖做了一定的处理，但还没有解决异常情况下的位移覆盖问题。\n\n通过消费者拉取分批次的消息，然后提交给多线程进行处理，而这里的滑动窗口式的实现方式是将拉取到的消息暂存起来， 多个消费线程可以拉取暂存的消息，这个用于暂存消息的缓存大小即为滑动窗口的大小， 总体上而言没有太多的变化 不同的是对于消费位移的把控。\n\n![](kafka-producer-consumer/img-20221030201350.png)\n\nstartOffset标注的是当前滑动 口的起始位置 endOffset 注的是末尾位置。每当 startOffset 指向的方格中的消息被消 费完成，就可以提交这部分的位移，与此同时，窗 口向 前滑动一格， 除原来startOffset 所指方格中对应的消息 并且拉取新的消息进入窗口。\n\n滑动窗口的大小固定，所对应的用来暂 消息的缓存大小也就固定了，这部分内存开销可控。方格大小和滑动窗口的大小同决定了消费线程的并发数。\n\n如果 个方格内的消 息无法被标记为消费完成，那么就会造成 startOffset 悬停。为了使窗口能够继续向前滑动 那么就需要设定 个闹值，当 startOffset 悬停一定的时间后就对这部分消息进行本地重试消费，如果重试失败就转入重试队列，如果还不奏效就转入死信队列。\n\n### 重要的消费者参数\n\n`fetch.min.bytes`：Consumer 在一次拉取请求（调用 poll （） 方法）中能从 Kafka 中拉取的最小\n数据量，默认值为 1B。\n\n`fetch .max.bytes`：配置 Consumer 在一次拉取请求中从 Kafka中拉取的最大数据 ，默认值为 52428800 ，也就是 50MB\n\n`fetch.max.wait.ms`：于指定 Kafka 的等待时间，默认值为 500ms\n\n`max.partition.fetch.bytes`：配置从每个分区里返回给 Consumer的最大数据 ，默认值为 1048576 (B)\n\n`max.poll.records`：配置 Consumer 次拉取请求中拉取的最大消息数，默认值为 500 （条）\n\n`connections.max.idle.ms`：指定在多久之后关闭限制的连接，默认值是 540000 (ms ），即 分钟。\n\n`exclude.internal.topics`：Kafka 中有两个内部的主题：_consumer_offsets 和 _transaction_state。 exclude.internal.topics用来指定 Kafka 中的内部主题是否可以向消费者公开，默认值为 true 。\n\n`receive.buffer.bytes`：这个参数用来设置 Socket 接收消息缓冲区的大小，默认值为 65536 (B)\n\n`send.buffer.bytes`：设置 Socket 发送消息缓冲区的大小，默认13 1072 (B)\n\n`request.timeout.ms`：来配置 Consumer 等待请求响应的最长时间，默认值为 30000ms\n\n`metadata.max.age.ms`：用来配置元数据的过期时间，默认值为 300000 ms\n\n`reconnect.backoff.ms`：配置尝试重新连接指定主机之前的等待时间，默认值为50ms\n\n`retry.backo ms`：配置尝试重新发送失败的请求到指定的主题分区之前的等待（退避〉时间，\n\n`isolation.level`：配置消费者的事务隔离级别。有效值为“read uncommitted ，，和\n“ read committed ＂\n\n![](kafka-producer-consumer/img-20221030202942.png)\n\n![](kafka-producer-consumer/img-20221030202957.png)\n\n\n\n\n\n\n\n\n\n","source":"_posts/kafka-producer-consumer.md","raw":"---\ntitle: kafka - 生产者消费者\nimg: /medias/files/kafka.png\nsummary: 一个有名的多分区多副本且基于ZooKeeper协调的分布式消息系统，高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性被使用。\ntags:\n  - 博客\n  - Kafka\ncategories:\n  - 随笔\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-10-16 14:08:24\npassword:\n---\n\nkafka角色：\n- 消息系统：Kafka和传统的消息系统都具备系统解耦性、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。Kafka还提供大多数消息系统难以实现的消息顺序性保障和回溯消费功能\n- 存储系统：Kafka把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于Kafka的消息持久化功能和多副本机制，我们可以吧Kafka作为长期对的数据存储系统来使用。\n- 流式处理平台：Kafka不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库\n\n# 初识Kafka\n\n\n\n## 基本概念\n\n- Producer：生产者，也就是发送消息的一方，生产者负责创建消息，然后将其投递到Kafka中\n- Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理\n- Broker：服务代理结点：对于Kafka而言，Broker可以简单的看做一个独立的Kafka服务结点或Kafka服务实例。\n- 主题：Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题，而消费者负责订阅主题并进行消费\n- 分区：一个分区只属于单个主题，同一主题下不同分区包含的消息是不同的，分区在存储层面可以看做一个可追加的日志文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量。如果一个主题只对应一个文件，那么这个文件所在的机器IO将会成功这个主题的性能瓶颈，而通过增加分区的数量可以实现水平扩展。\n- Offset偏移量：offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，Kafka保证分区有序而不是主题有序\n- 副本因子：副本个数；通过增加副本数量可以提升容灾能力，leader副本负责处理读写请求，follower副本负责与leader副本消息同步。当leader副本出现故障时，从follower副本中重新选举leader副本对外提供服务。kafka通过多副本机制实现了故障的自动转移。\n- AR：分区内所有副本(assigned replicas)\n- ISR:所有与leader副本保持一定程度同步的副本(in-sync replicas)\n- OSR:与leader副本同步滞后过多的副本 (out-of-sync replicas)\n- HW:高水位：标识一个特定的offset，消费者只能拉取到这个offset之前的消息 (high watermark)\n- LEO: 标识当前日志文件中下一条待写入消息的offset (Log End Offset)\n\n新产生的消息会先写入leader副本，然后follower副本会发送拉取请求来拉取落后的消息来进行消息同步。\n当同步完成后，消费者才可以消费这条消息(为了防止leader副本宕机造成消息丢失)\nkafka的复制机制既不是完全的同步复制，也不是单纯的落后复制。同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认为已成功提交，这种方式极大的影响了性能。而在异步复制方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就认为已经成功提交。(在这种情况下，如果follower副本都还没有复制完而落后与leader副本，突然leader副本宕机，则会造成数据丢失)。\n\n![](kafka-producer-consumer/img-20221016191323.png)\n\n\n## 生产与消费\n\n\n```\n./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-demo --replication-factor 3 --partitions 4\n\n\n./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-demo \n\n./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic-demo\n\n./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic-demo\n```\n\n`zookeeper.connect`  zk集群服务地址\n`listeners` broker监听客户端连接的地址列表\n`broker.id` broker的唯一标识\n`log.dir` kafka日志文件存放的目录，默认/tmp/kafka-logs\n`log.dirs` 优先级高\n`message.max.bytes` broker所能接收消息的最大值\n\n# 生产者\n\n## 生产者客户端开发\n步骤：\n1. 配置生产者客户端参数及创建相应的生产者实例\n2. 构建待发送的消息\n3. 发送消息\n4. 关闭生产者实例\n\n```java\npublic static Properties initConfig() {\n\tProperties props = new Properties();\n\tprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n}\n\npublic static void main(String[] args) {\n\tProperties props = initConfig();\n\tKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\tProducerRecord<String, String> record = new ProducerRecord<>(topic, \"Hello, Kafka\");\n\t\n\ttry {\n\t\tproducer.send(record);\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n}\n```\n\n\n\n消息对象ProducerRecord 并不是单纯意义上的消息，包含了多个属性\n\n```java\npublic class ProducerRecord<K, V> {\n\tprivate final String topic;\n\tprivate final Integer paitition;\n\tprivate final Headers headers;\n\tprivate final K key;\n\tprivate final V value;\n\tprivate final Long timestamp;\n}\n```\n\n`bootstrap.servers` 指定生产者客户端连接kafka所需的broker地址清单\n`key.serializer` 序列化成字节数组\n`value.serializer`\n\n- KafkaProducer是线程安全的，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化来供其他线程调用\n\n- 构建ProducerRecord 对象，topic属性和value属性是必填，其他选填\n\n\n\n### 发送消息\n\n发送消息的三种模式\n发后即忘：send方法不指定Callback，性能最高，可靠性最差\n\n同步：send方法利用返回的Future对象，阻塞等待Kafka响应\n\n异步：send方法，指定Callback回调函数\n\n\n\n可重试异常和不可重试异常\n\n对于可重试异常，如果配置了retries参数，那么只要在规定的重试次数内自行恢复，就不会抛出异常\n\n对于不可重试的异常，则直接抛出异常，不进行重试\n\n\n\n对于同一个分区而言，如果消息record1先与record2发送，那么KafkaProducer就可以保证对应的callback1先与callback2调用\n\n\n\n### 序列化器\n\n生产者需要使用序列化器将对象转换成字节数组，才能通过网络发送给Kafka，在对端消费者使用反序列化器把Kafka转换成相应的对象\n\n\n\n序列化器实现了org.apache.kafka.common.serialization.Serializer接口\n\n一般要实现\n\n```java\npublic void configure(Map<String, ?>configs,boolean isKey)\npublic byte[]serialize(String topic, T data)\npublic void close()\n```\n\n\n\n可以使用Avro、JSON、Thrift、Protobuf、Protostuff等通用工具来实现\n\n\n\n### 分区器\n\n\n\n```java\npublic int partition(String topic, Object key,byte[] keyBytes, Object Value, byte[] valueBytes,Cluster cluster);\npublic void close();\n```\n\n\n\n- 如果ProducerRecord中指定了partition字段，则不需要分区器，partition字段就是要发往的分区号\n\n- 如果没有指定分区器，就需要分区器根据key字段来计算partition值。Kafka的默认分区器实现了 xx.Partitioner接口，接口中有partition方法和close方法\n  默认分区器会判断key不为null，则对key进行哈希，最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息会以轮询的方式发往主题内的某一个可用分区\n\n  \n  自定义分区器也只需实现上述接口即可\n\n\n\n### 生产者拦截器\n\n消息发送前做一些过滤，修改等等\n\n需要自定义实现ProducerInterceptor接口\n\n\n\nKafkaProducer会在消息被应答之前或消息发送失败时调用拦截器的onAcknowledgement方法，优于用户设定的Callback之前执行。\n\n```java\npublic ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);\npublic void onAcknowledgement(RecordMetadata metadata, Exception exception);\npublic void close();\n```\n\n\n\n可以指定一个拦截链，KafkaProducer按照interceptor.classes参数配置的拦截器的顺序来一一执行（各个拦截器按逗号隔开）\n\n\n## 原理分析\n\n### 整体架构\n\n\n\n![生产者客户端整体架构](kafka-producer-consumer/producer-structure.jpg)\n\n\n\n生产者客户端有两个线程，主线程和Sender线程。主线程生产消息经过拦截器、序列化器、分区器缓存到消息累加器中，Sender线程从RecordAccumulator中获取消息并发往Kafka中\n\n\n\n`buffer.memory`： 指定RecordAccumulator缓存的大小\n\n`max.block.ms`：指定生产者发送太快，缓冲区满了，阻塞的最大时间\n\nRecordAccumulator缓存的大小由buffer.memory配置；如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时候producer的send方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的设置。\n\n\nRecordAccumulator为每个分区维护一个双端队列，队列内容为ProducerBatch，ProducerBatch为一个至多个ProducerRecord；可以使得生产者创建的消息组成一个批次，更为紧凑。\n\n\n\n消息在网络上传输是以字节传输的，发送之前要创建内存区域。kafka生产者中，通过java.io.ByteBuffer实现消息内存创建和释放。RecordAccumulator内部还有一个BufferPool，实现ByteBuffer的复用。BufferPool只针对特定大小的ByteBuffer进行管理，这个大小由`batch.size`指定。\n\n`batch.size` 指定ByteBuffer的大小\n\n\n\nProducerBatch的大小和batch.size相关。当一条ProducerRecord消息到了RecordAccumulator，会先寻找与分区对应的双端队列(如果没有则新建)，再从尾部获取一个ProducerBatch，查看该ProducerBatch中是否还可以写入这个ProducerRecord，可以写入则写入，不可以写入则新建ProducerBatch。\n\n新建ProducerBatch时，判断这条ProducerRecord消息大小是否超过batch.size没超过，则就以batch.size的大小新建ProducerBatch，这段内存还可以由ByterBuffer复用；如果超过了则以评估的大小新建ProducerBatch，这段内存不会被复用。\n\n\n\nSender从RecordAccumulator获取缓存的消息后，进一步将原本的`<分区，Deque<ProducerBatch>>` 转换为 `<Node, List<ProducerBatch>>`Node表示kafka集群的结点。生产者向具体的broker结点发消息。\n\nSender还会进一步封装为`<Node, Request>`才发往各个Node，请求在从Sender发往kafka之前会保存到InFlightRequests中，保存形式为`Map<NodeId, Deque<Request>>`主要作用是缓存了已经发出去，但是还没有收到响应的请求。\n\n这里限制了每个连接最多缓存的请求数，由`max.in.flight.requests.per.connecttion`指定，默认为5\n\n\n\n### 元数据的更新\n\nNode中未确认的请求越多，则认为负载越大。\n\n选择leastLoadedNode发送请求可以使它能尽快发出，避免网络拥塞等异常的影响。\nleastLoadedNode，即所有Node中负载最小的。\n\nleastLoadedNode还可以用于**元数据请求**、**消费者组播协议的交互**\n\n\n如果发送一个很简单的消息\n\n```\nProducerRecord<string, string> record = new ProducerRecord<>(topic, \"hello\");\n```\n\n这里只有主题和消息\nKafkaProducer需要将消息追加到指定主题的某个分区的对应leader副本之前。需要知道分区数目，计算出目标分区，需要知道目标分区的leader副本所在broker结点的地址、端口信息。这些需要的信息都属于**元数据信息**。\n\n\nbootstrap.servers参数只需要配置部分broker结点的地址，客户端可以发现其他broker结点的地址，这一过程属于元数据更新。\n\n客户端没有元数据信息时，会先选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作由Sender线程发起，在创建完MetadataRequest后同样会存入inFlightRequests。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里数据同步通过synchronized 和 final关键字保障。\n\n\n\n### 重要的生产者参数\n\n`acks`：指定分区中必须要有多少副本收到这条消息，之后生产者才会认为这条消息是成功写入的。\n\n默认acks = 1\n\nacks = 0 生产者发送消息之后不需要等待任何服务端响应\n\n`max.request.size` 客户端能发送消息的最大值\n\nretries 和 retry.backoff.ms\n\n`retries`是生产者重试的次数\n\n`retry.backoff.ms` 两次重试之间的间隔，默认100ms\n\n`compression.type` 默认值为none，指定消息压缩\n\n`connections.max.idle.ms` 指定在多久之后关闭闲置的连接\n\n`linger.ms` 指定生产者发送ProducerBatch之前等待更多ProducerRecord加入的时间\n\n`receive.buffer.bytes` 设置Socket接收消息缓冲区大小  默认32kb\n\n`send.buffer.bytes` Socket发送消息缓冲区大小\n\n`request.timeout.ms` 配置Producer等待请求响应的最长时间，默认30000ms\n\n\n\n# 消费者\n\n\n\n## 消费者与消费者组\n\n每个消费者都有一个对应的消费者组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。\n\n每个消费组消费全部分区的消息。\n\n消费者与消费组这种模型又可以让整体的消费能力具备横向伸缩性，我们可以增加消费者的个数来提高整体的消费能力。对于分区数固定的情况，一直增加消费者，到消费者个数超过分区数，就会有消费者分配不到分区。\n\n\n消息投递模式：\n点对点模式：基于队列，消息生产者发送消息到队列，消费者从消息队列中接收消息。\n\n发布订阅模式：定义了如何想一个内容节点发布和订阅消息，这个内容节点叫做主题，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布订阅模式在消息的一对多广播时采用。\n\nkafka同时支持两种消息投递模式。\n\n- 如果所有的消费者隶属于一个消费者组，那么所有的消息都会被均衡的投递给每一个消费者，即每条消息只会被一个消费者处理，这相当于点对点。\n- 如果所有的消费者隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息都会被所有的消费者处理，相当于发布订阅模式应用。\n\n\n\n消费组是一个逻辑概念，每个消费者在消费前需要指定所属消费组的名称，由`group.id`指定。消费者是实际的应用实例，可以是一个线程，也可以是一个进程，同一个消费组的消费者既可以部署在同一机器上，也可以部署在不同机器上。\n\n\n\n## 客户端开发\n\n1. 配置消费者客户端参数以及创建相应的消费者实例\n2. 订阅主题\n3. 拉取消息并消费\n4. 提交消费位移\n5. 关闭消费者实例\n\n```java\npublic class KafkaConsumerAnalysis {\n\tpublic static final String brokerList = \"\";\n\t...\n\t\n\tpublic static Properties initConfig() {\n\t\tProperties props = new Properties();\n\t\tprops.put(\"bootstrap.servers\", brokerList);\n\t}\n\t\n\tpublic static void main() {\n\t\tProperties props = initConfig();\n\t\tKafkaConsumer<String, String> consumer = new KafkaConsmer<>(props);\n\t\tconsumer.subscribe(Arrays.asList(topic));\n\t\t\n\t\ttry {\n\t\t\twhile(isRunning.get()) {\n\t\t\t\tConsumerRecrds<String, String> records = consumer.poll(Duration.ofMillis(1000));\n\t\t\t\t\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"\");\n\t\t\t} finally {\n\t\t\t\tconsumer.close();\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n\n\n### 必要的参数配置\n\n`bootstrap.servers` 集群broker地址\n\n`group.id` 消费者组名称\n\n`key.deserializer`  反序列化\n\n`value.deserializer`\n\n参数众多，直接使用org.apache.kafka.clients.consumer.ConsumerConfig\n\n每个参数在ConsumerConfig类中都有对应的名称\n\n如ConsumerConfig.GROUP_ID_CONFIG\n\n\n\n### 订阅主题与分区\n\n一个消费者可以订阅一个或多个主题，subscribe的几个重载方法\n\n```java\npublic void subscribe(Collection<String> topics, ConsumerRebalanceListener listener);\npublic void subscribe(Collection<String> topics);\npublic void subscribe(Pattern pattern, ConsumerRebalanceListener listener);\npublic void subscribe(Pattern pattern);\n```\n\n\n\n1.集合方式，`subscribe(Collection<String> topics)`订阅了什么就消费什么主题的消息。\n\n2.正则表达式，如果采用正则表达式的方式，在之后如果有人创建了新的主题，且主题名字与正则表达式匹配，那么这个消费者就可以消费到新添加的主题中的消息。\n例 `cosumer.subscribe(Pattern.compile(\"topic.*\"))`\n参数类型`ConsumerRebalanceListener`，设置的是再均衡监听器\n\n3.消费者还能直接订阅某些主题的特定分区\n\n```java\npublic void assign(Collection<TopicPartition> partitions);\n```\n例：`public List<PartitionInfo> partitionsFor(String topic)`\n\n\nTopicPartition类表示分区\n\n```java\npublic final class TopicPartition implements Serializable {\n\tprivate final int partition; //分区\n\tprivate final String topic; //主题\n\t...\n}\n```\n\n\n\n如果事先不知道主题中有多少分区，则使用partitionsFor()方法查询指定主题的元数据信息\n\n```java\npublic List<PartitionInfo> partitionsFor(String topic)\n\npublic class PartitionInfo {\n\tprivate final String topic;\n\tprivate final int paitition;\n\tprivate final Node leader;\n\tprivate final Node[] replicas;  //AR\n\tprivate final Node[] inSyncReplicas; //ISR\n\tprivate final Node offlineReplicas;  //OSR\n}\n```\n\n\n\n取消订阅\n\n```java\nconsumer.unsubscribe()\n```\n\n如果没有订阅任何主题或分区，那么继续执行消费程序会报异常IllegalStateException\n\n\n\n订阅状态:\n集合订阅  `AUTO_TOPICS`\n正则表达式订阅 `AUTO_PATTERN`\n指定分区订阅 `USER_ASSIGNED`\n\n通过subscribe()方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下，可以根据分区分配策略来自动分配各个消费者与分区的关系。\n\n### 反序列化\n\n反序列化器也实现了Deserializer接口，这个接口有以下三个方法：\n\n```java\npublic void configure(Map<String, ?> configs, boolean isKey)\npublic T deserialize(String topic, byte[] data)\npublic void close()\n```\n\n### 消息消费\n\n消费模式：推模式和拉模式\n推模式：服务端主动将消息推送给消费者\n拉模式：消费者主动向服务端发起请求来拉取消息\n\npoll方法定义:\n\n```java\npublic ConsumerRecords<K, V> poll(final Duration timeout) \n```\n\ntimeout参数用来控制poll方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞。\n\nConsumerRecord定义\n\n```java\npublic class ConsumerRecord<K, V> {\n  private final String topic;\n  private final int partition; \n  private final long offset; // 消息所属分区的偏移量\n  private final timestamp; \n  private final TimestampType timestampType;\n  private final int serializedKeySize;\n  private final int serializedValueSize;\n  private final Headers headers; // 消息的头部内容\n  private final K key;\n  private final V value;\n  private volatile Long checksum; // CRC32的校验值\n  // ...\n}\n```\n\n它提供了iterator方法来循环遍历消息集内部的消息\n\n`public Iterator<ConsumerRecord<K, V>> iterator()`\n\n它提供了获取消息集中指定分区消息的方法\n`public List<ConsumerRecord<K, V>> records(TopicPartition partition)`\n\n它还提供了按照主题维度来进行消费的方法\n`public Iterable<ConsumerRecord<K, V>> records(String topic)`\n\n\n### 位移提交\n\n对于kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。\n笔者对于消息在分区中的位置，这个offset称为‘偏移量’\n对于消费者消费到的位移，这个offset称为‘消费位移’\n\n\n在每次调用poll方法时，它返回的是还没有被消费过的消息集，要做到这一点就要记录上一次消费时的消费位移。\n消费位移要持久化保存，这个消费位移存储在kafka内部主题 `_consumer_offsets`中。消费者在消费完消息后需要执行消费位移的提交。\n\n当前消费到的位移x，即lastConsumedOffset；已经提交过的消费位移，即commited offset\n需要提交的位移 x + 1，表示下条需要拉去的消息的位置，即position\nposition = commited offset = lastConsumedOffset + 1\n\n```java\npublic long position(TopicPartition partition)\npublic OffsetAndMetadata committed(TopicPartition partition)\n```\n\n位移提交的时机需要把握，否则很容易引入消费混乱现象\n例：x 上一次提交的消费位移，[x, x+8]本次poll到的消息\n重复消费：\n如果是消费完所有拉取到的消息之后才执行提交，那么当消费到中间x+5消费者发生异常重启，则会重复从x开始拉取消费\n\n 消息丢失：\n如果拉取到消息之后就进行了位移提交x+8，那么当消费到中间x+5消费者发生异常重启，则直接从x+8开始消费，发生了消息丢失\n\n在kafka中默认的消费位移提交为自动提交，由参数`enable.auto.commit`配置；这个默认提交是定期提交，由参数`auto.commit.interval.ms`配置，自动位移提交的动作是在poll方法的逻辑里完成的。\n\n自动提交消费位移也可能造成消费混乱现象：\n重复消费：假设刚刚提交完消费位移，然后拉取一批消息进行消费，在下一次自动提交消费位移之前，消费者重启了，那么又得从上一次位移提交的地方重新开始消费。\n\n消息丢失；假设拉取线程A不断拉取存入本地缓存，消费线程B从缓存中读取，当已经提交的消费位移大于消费线程B消费到的消息，且发生重启时，就会发生消息丢失。\n\n手动提交方式：\n同步提交：\n`public void commitSync`\n`public void commitSync(final Map<TopicOartition, OffsetAndMetadata> offsets)`\n\n异步提交：\n`public void commitAsync`\n`public void commitAsync(OffsetCommitCallback callback)`\n`public void commitAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback)`\n\ncommitSync方法会根据poll方法拉取的最新位移来进行提交，只有没有发生不可恢复的错误，它就会阻塞消费者线程直至位移提交完成。\n\n带参数的commitSync方法提供了offsets参数，用来提交指定分区的位移。\n\n异步提交的方式在执行的时候消费者线程不会被阻塞，可能在提交消费位移的结果还未返回之前就开始了新一次的拉去操作。它提供的异步方法中支持指定回调函数，它会在位移提交完成后回调OffsetCommitCallback中的onComplete()方法。\n\n异步提交的时候同样会发生失败，如果消费位移提交了x失败， 下一次提交了x+y成功了，而这里前一步的提交x重试成功，那么消费位移又变成了x，这里消费者重启就会发生重复消费。\n要避免这个问题可以在位移提交失败需要重试的时候检查提交位移和前一个位移的大小，当发现小于前一个提交的位移大小，则说明有更大的位移已经提交了，可以不用本次重试。\n\n### 控制或关闭消费\n\npause和resume来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。\n\n```java\npublic void pause(Collection<TopicPartition> partitions)\npublic void resume(Collection<TopicPartition> partitions)\n```\n还可以检查被暂停的分区集合\n`public Set<TopicPartition> paused()`\n\nkafka consumer提供了close方法来实现关闭\n```java\npublic void close()\npublic void close(Duration timeout)\npublic void close(long timeout, TimeUnit timeUnit)\n```\n第一种方法没有timeout参数，并不意味着会无限制的等待，它内部设定了最长等待时间30s\n\n### 指定位移消费\n\n当一个新的消费组建立的时候，它根本没有可以查找的消费位移。或者消费组内的一个消费者订阅了一个新的主题，它也没有可以查找的消费位移。当_consumer_offsets主题中有关这个消费组的位移信息过期而被删除后，它没有可以查找的消费位移。\n\n`auto.offset.reset`参数配置当消费者查不到所记录的消费位移时，就会根据该配置来决定从何处开始消费\n可配置的值：\n`latest` ：从分区末尾开始消费消息\n`earliest` ：从起始处开始消费消息\n`none` ： 不从末尾也不从开始处开始消费，报NoOffsetForPartitionException异常\n\nseek方法提供了从特定位移处开始拉去消息的功能\n```java\npublic void seek(TopicPartition partition, long offset)\n```\nseek方法只能重置消费者分配到的分区的消费位置，而分区的分配是在poll方法的调用过程中实现的，也就是说，在执行seek方法之前需要先执行一次poll方法。\n\n```java\nKafkaConsumer <String String> consumer= new KafkaConsumer<> (props); \ncosumer.subscribe(Arrays asList(topic));\nconsumer.poll(Duratio ofMillis(10000) ; \nSet<TopicPartition> assignment = consumer.assignment(); \nfor (Top cPartition tp : assignment) { \nconsumer.seek(tp , 10); \nwhile (true) { \nConsumerRecords<String , String> records = consumer.poll(DurationofMllis(1000)); \n//consume the record .\n}\n```\n如果我们将代码清单 中第①行 poll （）方法的参数设置为 ，即这 行替换为\n`consumer poll(Duration.ofMillis(0)) ;`\n\n此之后， 会发现 seek（） 方法并未有任何作用。因为当 poll （）方法中 参数为0时，此方法立刻返回，那么 poll （） 方法内部进行分区分配的逻辑就会来不及实施。\n\n\n如果对未分配到的分区执行 seek（） 方法 那么会报出IllegalStateException 的异常。类似在调用 subscrib （） 方法之后直接调用 seek（） 方法\n\n```java\nconsumer.subscribe(Arrays.asList(topic)) ; \nconsumer.seek(new TopicPartition(topic, 0), 10 );\n```\n会报出如下的异常\njava.lang.I llegalStateException: No current assignment for partition topic- demo - 0\n\n\nseek的几个方法定义\n```java\npublic Map<Top cPartition Long> endOffsets( Collection<TopicPartition> partitions) \npublic Map<TopicPartition , Long> endOffsets( Collection<Top cPartit on> part tions\nDuration timeout)\n\npublic Map<TopicPartition , Long> beginningOff sets (Collection<TopicPartition> partitions) \npublic Map<TopicPart tion Long> beginningOffsets(Collection<TopicPartition> partitions, \nDuration timeout)\n\npublic void seekToBeginning(Collection<TopicPartition> partitions) \npublic void seekToEnd Collection<TopicPartition> partitions)\n\npublic Map<TopicPartition , OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> timestampsToSearch) \npublic Map<TopicPartition OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> t imestampsToSearch,Duration timeout )\n```\n\n### 再均衡\n\n再均衡是指分区的所属权从一个消费者转移到另一消费者的行为。在再均衡发生期间，消费组内的消费者是无法读取消息的。 就是说，在再均衡发生期间的这一小段时内，消费组会变得不可用 。\n\n比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作 之后这个分区又被分配给了消费组 的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。\n\n再均衡监听器\n\n```java\nvoid onPartitionsRevoked(Collection<TopicPartition> partitions)\nvoid onPartitionsAssigned(Collection<TopicPartition> partitions)\n```\n\n```java\nMap<TopicPartition, OffsetAndMetadata> currentOffsets =new HashMap<>() ; \nconsumer.subscribe(Arrays.asList(topic) , new ConsumerRebalanceListener () { \n@Override \npublic void onPartitionsRevoked(Collection<TopicPartition> part tions) { \nconsumer.commitSync(currentOffsets) ; \ncurrentOffsets.clear(); \n@Override\npublic void onPartitionsAssigned(Collection<TopicPartition partitions) { \n//do nothing . \n}) .,\n```\n\n### 消费者拦截器\n\n消费者拦截器需要自定义实现 org.apache.kafka.clients.consumer.Consumerlnterceptor 接口。\n```java\npublic ConsumerRecords<K, V> onConsume(ConsumerRecords<K , V> records);\npublic void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets);\npublic void close();\n```\n\n\nKafkaconsumer 会在 poll （）方法返回之前调用拦截器的 Consume（） 方法来对消息进行相应\n的定制 操作，KafkaConsumer 会在提交完消费位移之后调用拦截器的 onCommit（） 方法\n\n在消费者中也有拦截链的概念，和生产者的拦截链一样， 也是按照工interceptor classes参数配置的拦截器的顺序来一一执行的（配置的时候，各个拦截器之间使用逗号隔开）。同样也要提防“副作用”的发生 如果在拦截链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。\n\n### 多线程实现\n\nKatkaProducer 是线程安全的，然而 KafkaConsumer 却是非线程安全 KafkaConsumer定义了 acquire （） 方法，用来检测当前是否只有 个线程在操作，若有其他线程正在操作则会抛出 ConcurrentModifcationException 异常\n\n```java\nprivate final AtomicLong currentThread = new Atom cLong(NO CURRENT THREAD ); //Kaf aConsumer 中的成员变量\n\nprivate void acquire() { \nlong threadid = Thread.currentThread().getid();\nif (threadid != currentThread.get() && !currentThread.compareAndSet(NO_CURRENT THREAD, threadid) ) \nthrow new ConcurrentModificationException \n(\"KafkaConsumer is not safe for multi- threaded access \") ; \nrefcount.incrementAndGet();\n}\n```\n\nacquire（）方法和 release （）方法成对出现，表示相应的加锁和解锁操作。\n\n```java\nprivate void release() \nif (refcount.decrementAndGet () == 0) {\n\tcurrentThread.set(NO CURRENT THREAD);\n}\n```\n\n多线程的目的就是为了提高整体的消费能力。多线程的实现方式有多种，第一种也是最常见的方式 线程封闭，即为每个线程实例化一个 KafkaConsumer 对象。\n\n![](kafka-producer-consumer/img-20221030190716.png)\n\n一个消费线程可消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数，当消费线程的个数大于分区数时 就有部分消费线程一直处于空闲的状态。\n\n多个消费线程同时消费同一个分区 ，这个通过 assign（）、 seek （）等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力 。不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，\n\n```java\npublic static void main(String[] args) { \n\tProperties props = itConfig (); \n\tint consumerThreadNum = 4 ; \n\tfor(int i=O;i<consumerThreadNum;i++) { \n\tnew KafkaConsumerThread(props,topic).start();\n\t}\n}\n\npublic static class KafkaConsumerThread extends Thread{\n\tprivate KafkaConsumer<String , String> kafkaConsumer;\n\tpublic KafkaConsumerThread(Properties props, String topic) { \n\tthis.kafkaConsumer =new KafkaConsumer<>(props); \n\tthis.kafkaConsumer.subscribe(Arrays asList(topic));\n}\n\n\t@Override \n\tpublic void run() {\n\ttry { \n\t\twhile (true) { \n\t\tConsumerRecords<String, String> records = \n\t\tkafkaConsumer.poll (Duration.ofMill (1 00)) ; \n\t\tfor (ConsumerRecord<String, Stri g> record : records) { \n\t\t// 处理消息模块 ① \n\t\t}\n\t}\n\t} catch (Exception e) { \n\t\te.printStackTrace(); \n\t} finally { \n\t\tkafkaConsumer.close();\n\t}\n\t}\n```\n\n上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别， 优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的TCP 连接 如果分区数和 consumerThreadNum 的值都很大，那么会造成不 的系统开销。\n\n这里的处理速度取决于处理消息模块，。一般 言， poll（）拉取消息的速度是相当快的 ，而整体消费的瓶颈是在处理消息这一块， 通过－定的方式来改进这一部分，那么就能带动整体消费性能提升。\n\n![](kafka-producer-consumer/img-20221030193459.png)\n\n```java\n\t@Override \n\tpublic void run() {\n\ttry { \n\t\twhile (true) { \n\t\tConsumerRecords<String, String> records = \n\t\tkafkaConsumer.poll(Duration.ofMill (1 00)) ; \n\t\tif (!records.isEmpty () ) { \n\t\t\texecutorService.submit(new RecordsHandler(records));  // 调用各个hander处理消息\n\t\t}\n\t}\n\t} catch (Exception e) { \n\t\te.printStackTrace(); \n\t} finally { \n\t\tkafkaConsumer.close();\n\t}\n\t}\n\n\tpublic static class RecordsHandler extends Thread{ \n\tpublic final ConsumerRecords<String, String> records;\n\n\tpublic RecordsHandl er (ConsumerRecords<String, String> records) ( \n\t\tthis.records =records;\n\t}\n\n\t@Override \n\tpublic void run() {\n\t\t// 处理records\n\t}\n\t}\n\n```\n\nRecordHandler 类是用来处理消息的，而 KafraConsumerThread 类对应的是一个消费线程，里面通过线程池的方式来调用 RecordHandler 处理一批批的消息。\n\n引入一个共享\n变量 offsets 来参与提交\n\n![](kafka-producer-consumer/img-20221030200350.png)\n\n每一个处理消息的 RecordHandler 类在处理完消息之后都将对应的消费位移保存到共享变量offsets 中， KafraConsumerThread 在每一次 poll （）方法之后都读取 offsets 中的内容并对其进行位移提交。\n\n```java\nfor (TopicPartition tp : records .partitions()) { \n\tList<ConsumerRecord<String , String> tpRecords = records . records(tp); \n\t// 处 tpRec ords\n\tlong lastConsumedOffset = tpRecords . get (tpRecords. size() - 1) . offset() ; \n\tsynchronized (offsets) { \n\t\tif offsets.co ta 工口 sKey (tp)) { \n\t\t\toffsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + l)) ; \n\t\t} else { \n\t\t\tlong position = offsets . get(tp) .offset() ; \n\t\t\tif (position < lastConsumedOffset + 1) { \n\t\t\toffsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + l))\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n```java\nsynchronized (offsets) { \nif (!offsets. isEmpty () ) { \n\tkafkaConsumer.commitSync(offsets); \n\toffsets.clear();\n\t}\n}\n```\n\n假设一个处理线程 RecordHand erl 正在处理 offset 99消息，而另一个处理线程 RecordHand er2 己经处理完了 offset 100 99 的消息并进行了位移提交，此时如果 RecordHandler 发生异常，则之后的消费只能从 200 开始而无法再次消费 99的消息，从而造成了消息丢失的现象。这里虽然针对位移覆盖做了一定的处理，但还没有解决异常情况下的位移覆盖问题。\n\n通过消费者拉取分批次的消息，然后提交给多线程进行处理，而这里的滑动窗口式的实现方式是将拉取到的消息暂存起来， 多个消费线程可以拉取暂存的消息，这个用于暂存消息的缓存大小即为滑动窗口的大小， 总体上而言没有太多的变化 不同的是对于消费位移的把控。\n\n![](kafka-producer-consumer/img-20221030201350.png)\n\nstartOffset标注的是当前滑动 口的起始位置 endOffset 注的是末尾位置。每当 startOffset 指向的方格中的消息被消 费完成，就可以提交这部分的位移，与此同时，窗 口向 前滑动一格， 除原来startOffset 所指方格中对应的消息 并且拉取新的消息进入窗口。\n\n滑动窗口的大小固定，所对应的用来暂 消息的缓存大小也就固定了，这部分内存开销可控。方格大小和滑动窗口的大小同决定了消费线程的并发数。\n\n如果 个方格内的消 息无法被标记为消费完成，那么就会造成 startOffset 悬停。为了使窗口能够继续向前滑动 那么就需要设定 个闹值，当 startOffset 悬停一定的时间后就对这部分消息进行本地重试消费，如果重试失败就转入重试队列，如果还不奏效就转入死信队列。\n\n### 重要的消费者参数\n\n`fetch.min.bytes`：Consumer 在一次拉取请求（调用 poll （） 方法）中能从 Kafka 中拉取的最小\n数据量，默认值为 1B。\n\n`fetch .max.bytes`：配置 Consumer 在一次拉取请求中从 Kafka中拉取的最大数据 ，默认值为 52428800 ，也就是 50MB\n\n`fetch.max.wait.ms`：于指定 Kafka 的等待时间，默认值为 500ms\n\n`max.partition.fetch.bytes`：配置从每个分区里返回给 Consumer的最大数据 ，默认值为 1048576 (B)\n\n`max.poll.records`：配置 Consumer 次拉取请求中拉取的最大消息数，默认值为 500 （条）\n\n`connections.max.idle.ms`：指定在多久之后关闭限制的连接，默认值是 540000 (ms ），即 分钟。\n\n`exclude.internal.topics`：Kafka 中有两个内部的主题：_consumer_offsets 和 _transaction_state。 exclude.internal.topics用来指定 Kafka 中的内部主题是否可以向消费者公开，默认值为 true 。\n\n`receive.buffer.bytes`：这个参数用来设置 Socket 接收消息缓冲区的大小，默认值为 65536 (B)\n\n`send.buffer.bytes`：设置 Socket 发送消息缓冲区的大小，默认13 1072 (B)\n\n`request.timeout.ms`：来配置 Consumer 等待请求响应的最长时间，默认值为 30000ms\n\n`metadata.max.age.ms`：用来配置元数据的过期时间，默认值为 300000 ms\n\n`reconnect.backoff.ms`：配置尝试重新连接指定主机之前的等待时间，默认值为50ms\n\n`retry.backo ms`：配置尝试重新发送失败的请求到指定的主题分区之前的等待（退避〉时间，\n\n`isolation.level`：配置消费者的事务隔离级别。有效值为“read uncommitted ，，和\n“ read committed ＂\n\n![](kafka-producer-consumer/img-20221030202942.png)\n\n![](kafka-producer-consumer/img-20221030202957.png)\n\n\n\n\n\n\n\n\n\n","slug":"kafka-producer-consumer","published":1,"updated":"2022-10-30T13:03:18.388Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9h000cagvtstpma2s5","content":"<p>kafka角色：</p>\n<ul>\n<li>消息系统：Kafka和传统的消息系统都具备系统解耦性、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。Kafka还提供大多数消息系统难以实现的消息顺序性保障和回溯消费功能</li>\n<li>存储系统：Kafka把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于Kafka的消息持久化功能和多副本机制，我们可以吧Kafka作为长期对的数据存储系统来使用。</li>\n<li>流式处理平台：Kafka不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库</li>\n</ul>\n<h1 id=\"初识Kafka\"><a href=\"#初识Kafka\" class=\"headerlink\" title=\"初识Kafka\"></a>初识Kafka</h1><h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><ul>\n<li>Producer：生产者，也就是发送消息的一方，生产者负责创建消息，然后将其投递到Kafka中</li>\n<li>Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理</li>\n<li>Broker：服务代理结点：对于Kafka而言，Broker可以简单的看做一个独立的Kafka服务结点或Kafka服务实例。</li>\n<li>主题：Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题，而消费者负责订阅主题并进行消费</li>\n<li>分区：一个分区只属于单个主题，同一主题下不同分区包含的消息是不同的，分区在存储层面可以看做一个可追加的日志文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量。如果一个主题只对应一个文件，那么这个文件所在的机器IO将会成功这个主题的性能瓶颈，而通过增加分区的数量可以实现水平扩展。</li>\n<li>Offset偏移量：offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，Kafka保证分区有序而不是主题有序</li>\n<li>副本因子：副本个数；通过增加副本数量可以提升容灾能力，leader副本负责处理读写请求，follower副本负责与leader副本消息同步。当leader副本出现故障时，从follower副本中重新选举leader副本对外提供服务。kafka通过多副本机制实现了故障的自动转移。</li>\n<li>AR：分区内所有副本(assigned replicas)</li>\n<li>ISR:所有与leader副本保持一定程度同步的副本(in-sync replicas)</li>\n<li>OSR:与leader副本同步滞后过多的副本 (out-of-sync replicas)</li>\n<li>HW:高水位：标识一个特定的offset，消费者只能拉取到这个offset之前的消息 (high watermark)</li>\n<li>LEO: 标识当前日志文件中下一条待写入消息的offset (Log End Offset)</li>\n</ul>\n<p>新产生的消息会先写入leader副本，然后follower副本会发送拉取请求来拉取落后的消息来进行消息同步。<br>当同步完成后，消费者才可以消费这条消息(为了防止leader副本宕机造成消息丢失)<br>kafka的复制机制既不是完全的同步复制，也不是单纯的落后复制。同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认为已成功提交，这种方式极大的影响了性能。而在异步复制方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就认为已经成功提交。(在这种情况下，如果follower副本都还没有复制完而落后与leader副本，突然leader副本宕机，则会造成数据丢失)。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221016191323.png\" alt></p>\n<h2 id=\"生产与消费\"><a href=\"#生产与消费\" class=\"headerlink\" title=\"生产与消费\"></a>生产与消费</h2><pre><code>./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-demo --replication-factor 3 --partitions 4\n\n\n./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-demo \n\n./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic-demo\n\n./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic-demo</code></pre><p><code>zookeeper.connect</code>  zk集群服务地址<br><code>listeners</code> broker监听客户端连接的地址列表<br><code>broker.id</code> broker的唯一标识<br><code>log.dir</code> kafka日志文件存放的目录，默认/tmp/kafka-logs<br><code>log.dirs</code> 优先级高<br><code>message.max.bytes</code> broker所能接收消息的最大值</p>\n<h1 id=\"生产者\"><a href=\"#生产者\" class=\"headerlink\" title=\"生产者\"></a>生产者</h1><h2 id=\"生产者客户端开发\"><a href=\"#生产者客户端开发\" class=\"headerlink\" title=\"生产者客户端开发\"></a>生产者客户端开发</h2><p>步骤：</p>\n<ol>\n<li>配置生产者客户端参数及创建相应的生产者实例</li>\n<li>构建待发送的消息</li>\n<li>发送消息</li>\n<li>关闭生产者实例</li>\n</ol>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> Properties <span class=\"token function\">initConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ProducerConfig<span class=\"token punctuation\">.</span>BOOTSTRAP_SERVERS_CONFIG<span class=\"token punctuation\">,</span> brokerList<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    Properties props <span class=\"token operator\">=</span> <span class=\"token function\">initConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    KafkaProducer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaProducer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    ProducerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ProducerRecord</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> <span class=\"token string\">\"Hello, Kafka\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n        producer<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        e<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>消息对象ProducerRecord 并不是单纯意义上的消息，包含了多个属性</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">ProducerRecord</span><span class=\"token operator\">&lt;</span>K<span class=\"token punctuation\">,</span> V<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String topic<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Integer paitition<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Headers headers<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> K key<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> V value<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Long timestamp<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>bootstrap.servers</code> 指定生产者客户端连接kafka所需的broker地址清单<br><code>key.serializer</code> 序列化成字节数组<br><code>value.serializer</code></p>\n<ul>\n<li><p>KafkaProducer是线程安全的，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化来供其他线程调用</p>\n</li>\n<li><p>构建ProducerRecord 对象，topic属性和value属性是必填，其他选填</p>\n</li>\n</ul>\n<h3 id=\"发送消息\"><a href=\"#发送消息\" class=\"headerlink\" title=\"发送消息\"></a>发送消息</h3><p>发送消息的三种模式<br>发后即忘：send方法不指定Callback，性能最高，可靠性最差</p>\n<p>同步：send方法利用返回的Future对象，阻塞等待Kafka响应</p>\n<p>异步：send方法，指定Callback回调函数</p>\n<p>可重试异常和不可重试异常</p>\n<p>对于可重试异常，如果配置了retries参数，那么只要在规定的重试次数内自行恢复，就不会抛出异常</p>\n<p>对于不可重试的异常，则直接抛出异常，不进行重试</p>\n<p>对于同一个分区而言，如果消息record1先与record2发送，那么KafkaProducer就可以保证对应的callback1先与callback2调用</p>\n<h3 id=\"序列化器\"><a href=\"#序列化器\" class=\"headerlink\" title=\"序列化器\"></a>序列化器</h3><p>生产者需要使用序列化器将对象转换成字节数组，才能通过网络发送给Kafka，在对端消费者使用反序列化器把Kafka转换成相应的对象</p>\n<p>序列化器实现了org.apache.kafka.common.serialization.Serializer接口</p>\n<p>一般要实现</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">configure</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> <span class=\"token operator\">?</span><span class=\"token operator\">></span>configs<span class=\"token punctuation\">,</span><span class=\"token keyword\">boolean</span> isKey<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token function\">serialize</span><span class=\"token punctuation\">(</span>String topic<span class=\"token punctuation\">,</span> T data<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>可以使用Avro、JSON、Thrift、Protobuf、Protostuff等通用工具来实现</p>\n<h3 id=\"分区器\"><a href=\"#分区器\" class=\"headerlink\" title=\"分区器\"></a>分区器</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">int</span> <span class=\"token function\">partition</span><span class=\"token punctuation\">(</span>String topic<span class=\"token punctuation\">,</span> Object key<span class=\"token punctuation\">,</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> keyBytes<span class=\"token punctuation\">,</span> Object Value<span class=\"token punctuation\">,</span> <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> valueBytes<span class=\"token punctuation\">,</span>Cluster cluster<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<ul>\n<li><p>如果ProducerRecord中指定了partition字段，则不需要分区器，partition字段就是要发往的分区号</p>\n</li>\n<li><p>如果没有指定分区器，就需要分区器根据key字段来计算partition值。Kafka的默认分区器实现了 xx.Partitioner接口，接口中有partition方法和close方法<br>默认分区器会判断key不为null，则对key进行哈希，最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息会以轮询的方式发往主题内的某一个可用分区</p>\n</li>\n</ul>\n<p>  自定义分区器也只需实现上述接口即可</p>\n<h3 id=\"生产者拦截器\"><a href=\"#生产者拦截器\" class=\"headerlink\" title=\"生产者拦截器\"></a>生产者拦截器</h3><p>消息发送前做一些过滤，修改等等</p>\n<p>需要自定义实现ProducerInterceptor接口</p>\n<p>KafkaProducer会在消息被应答之前或消息发送失败时调用拦截器的onAcknowledgement方法，优于用户设定的Callback之前执行。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> ProducerRecord<span class=\"token operator\">&lt;</span>K<span class=\"token punctuation\">,</span> V<span class=\"token operator\">></span> <span class=\"token function\">onSend</span><span class=\"token punctuation\">(</span>ProducerRecord<span class=\"token operator\">&lt;</span>K<span class=\"token punctuation\">,</span> V<span class=\"token operator\">></span> record<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onAcknowledgement</span><span class=\"token punctuation\">(</span>RecordMetadata metadata<span class=\"token punctuation\">,</span> Exception exception<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>可以指定一个拦截链，KafkaProducer按照interceptor.classes参数配置的拦截器的顺序来一一执行（各个拦截器按逗号隔开）</p>\n<h2 id=\"原理分析\"><a href=\"#原理分析\" class=\"headerlink\" title=\"原理分析\"></a>原理分析</h2><h3 id=\"整体架构\"><a href=\"#整体架构\" class=\"headerlink\" title=\"整体架构\"></a>整体架构</h3><p><img src=\"/2022/10/16/kafka-producer-consumer/producer-structure.jpg\" alt=\"生产者客户端整体架构\"></p>\n<p>生产者客户端有两个线程，主线程和Sender线程。主线程生产消息经过拦截器、序列化器、分区器缓存到消息累加器中，Sender线程从RecordAccumulator中获取消息并发往Kafka中</p>\n<p><code>buffer.memory</code>： 指定RecordAccumulator缓存的大小</p>\n<p><code>max.block.ms</code>：指定生产者发送太快，缓冲区满了，阻塞的最大时间</p>\n<p>RecordAccumulator缓存的大小由buffer.memory配置；如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时候producer的send方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的设置。</p>\n<p>RecordAccumulator为每个分区维护一个双端队列，队列内容为ProducerBatch，ProducerBatch为一个至多个ProducerRecord；可以使得生产者创建的消息组成一个批次，更为紧凑。</p>\n<p>消息在网络上传输是以字节传输的，发送之前要创建内存区域。kafka生产者中，通过java.io.ByteBuffer实现消息内存创建和释放。RecordAccumulator内部还有一个BufferPool，实现ByteBuffer的复用。BufferPool只针对特定大小的ByteBuffer进行管理，这个大小由<code>batch.size</code>指定。</p>\n<p><code>batch.size</code> 指定ByteBuffer的大小</p>\n<p>ProducerBatch的大小和batch.size相关。当一条ProducerRecord消息到了RecordAccumulator，会先寻找与分区对应的双端队列(如果没有则新建)，再从尾部获取一个ProducerBatch，查看该ProducerBatch中是否还可以写入这个ProducerRecord，可以写入则写入，不可以写入则新建ProducerBatch。</p>\n<p>新建ProducerBatch时，判断这条ProducerRecord消息大小是否超过batch.size没超过，则就以batch.size的大小新建ProducerBatch，这段内存还可以由ByterBuffer复用；如果超过了则以评估的大小新建ProducerBatch，这段内存不会被复用。</p>\n<p>Sender从RecordAccumulator获取缓存的消息后，进一步将原本的<code>&lt;分区，Deque&lt;ProducerBatch&gt;&gt;</code> 转换为 <code>&lt;Node, List&lt;ProducerBatch&gt;&gt;</code>Node表示kafka集群的结点。生产者向具体的broker结点发消息。</p>\n<p>Sender还会进一步封装为<code>&lt;Node, Request&gt;</code>才发往各个Node，请求在从Sender发往kafka之前会保存到InFlightRequests中，保存形式为<code>Map&lt;NodeId, Deque&lt;Request&gt;&gt;</code>主要作用是缓存了已经发出去，但是还没有收到响应的请求。</p>\n<p>这里限制了每个连接最多缓存的请求数，由<code>max.in.flight.requests.per.connecttion</code>指定，默认为5</p>\n<h3 id=\"元数据的更新\"><a href=\"#元数据的更新\" class=\"headerlink\" title=\"元数据的更新\"></a>元数据的更新</h3><p>Node中未确认的请求越多，则认为负载越大。</p>\n<p>选择leastLoadedNode发送请求可以使它能尽快发出，避免网络拥塞等异常的影响。<br>leastLoadedNode，即所有Node中负载最小的。</p>\n<p>leastLoadedNode还可以用于<strong>元数据请求</strong>、<strong>消费者组播协议的交互</strong></p>\n<p>如果发送一个很简单的消息</p>\n<pre><code>ProducerRecord&lt;string, string&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello&quot;);</code></pre><p>这里只有主题和消息<br>KafkaProducer需要将消息追加到指定主题的某个分区的对应leader副本之前。需要知道分区数目，计算出目标分区，需要知道目标分区的leader副本所在broker结点的地址、端口信息。这些需要的信息都属于<strong>元数据信息</strong>。</p>\n<p>bootstrap.servers参数只需要配置部分broker结点的地址，客户端可以发现其他broker结点的地址，这一过程属于元数据更新。</p>\n<p>客户端没有元数据信息时，会先选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作由Sender线程发起，在创建完MetadataRequest后同样会存入inFlightRequests。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里数据同步通过synchronized 和 final关键字保障。</p>\n<h3 id=\"重要的生产者参数\"><a href=\"#重要的生产者参数\" class=\"headerlink\" title=\"重要的生产者参数\"></a>重要的生产者参数</h3><p><code>acks</code>：指定分区中必须要有多少副本收到这条消息，之后生产者才会认为这条消息是成功写入的。</p>\n<p>默认acks = 1</p>\n<p>acks = 0 生产者发送消息之后不需要等待任何服务端响应</p>\n<p><code>max.request.size</code> 客户端能发送消息的最大值</p>\n<p>retries 和 retry.backoff.ms</p>\n<p><code>retries</code>是生产者重试的次数</p>\n<p><code>retry.backoff.ms</code> 两次重试之间的间隔，默认100ms</p>\n<p><code>compression.type</code> 默认值为none，指定消息压缩</p>\n<p><code>connections.max.idle.ms</code> 指定在多久之后关闭闲置的连接</p>\n<p><code>linger.ms</code> 指定生产者发送ProducerBatch之前等待更多ProducerRecord加入的时间</p>\n<p><code>receive.buffer.bytes</code> 设置Socket接收消息缓冲区大小  默认32kb</p>\n<p><code>send.buffer.bytes</code> Socket发送消息缓冲区大小</p>\n<p><code>request.timeout.ms</code> 配置Producer等待请求响应的最长时间，默认30000ms</p>\n<h1 id=\"消费者\"><a href=\"#消费者\" class=\"headerlink\" title=\"消费者\"></a>消费者</h1><h2 id=\"消费者与消费者组\"><a href=\"#消费者与消费者组\" class=\"headerlink\" title=\"消费者与消费者组\"></a>消费者与消费者组</h2><p>每个消费者都有一个对应的消费者组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。</p>\n<p>每个消费组消费全部分区的消息。</p>\n<p>消费者与消费组这种模型又可以让整体的消费能力具备横向伸缩性，我们可以增加消费者的个数来提高整体的消费能力。对于分区数固定的情况，一直增加消费者，到消费者个数超过分区数，就会有消费者分配不到分区。</p>\n<p>消息投递模式：<br>点对点模式：基于队列，消息生产者发送消息到队列，消费者从消息队列中接收消息。</p>\n<p>发布订阅模式：定义了如何想一个内容节点发布和订阅消息，这个内容节点叫做主题，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布订阅模式在消息的一对多广播时采用。</p>\n<p>kafka同时支持两种消息投递模式。</p>\n<ul>\n<li>如果所有的消费者隶属于一个消费者组，那么所有的消息都会被均衡的投递给每一个消费者，即每条消息只会被一个消费者处理，这相当于点对点。</li>\n<li>如果所有的消费者隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息都会被所有的消费者处理，相当于发布订阅模式应用。</li>\n</ul>\n<p>消费组是一个逻辑概念，每个消费者在消费前需要指定所属消费组的名称，由<code>group.id</code>指定。消费者是实际的应用实例，可以是一个线程，也可以是一个进程，同一个消费组的消费者既可以部署在同一机器上，也可以部署在不同机器上。</p>\n<h2 id=\"客户端开发\"><a href=\"#客户端开发\" class=\"headerlink\" title=\"客户端开发\"></a>客户端开发</h2><ol>\n<li>配置消费者客户端参数以及创建相应的消费者实例</li>\n<li>订阅主题</li>\n<li>拉取消息并消费</li>\n<li>提交消费位移</li>\n<li>关闭消费者实例</li>\n</ol>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">KafkaConsumerAnalysis</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> String brokerList <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> Properties <span class=\"token function\">initConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"bootstrap.servers\"</span><span class=\"token punctuation\">,</span> brokerList<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        Properties props <span class=\"token operator\">=</span> <span class=\"token function\">initConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        KafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsmer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span>isRunning<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                ConsumerRecrds<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofMillis</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                log<span class=\"token punctuation\">.</span><span class=\"token function\">error</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n                consumer<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"必要的参数配置\"><a href=\"#必要的参数配置\" class=\"headerlink\" title=\"必要的参数配置\"></a>必要的参数配置</h3><p><code>bootstrap.servers</code> 集群broker地址</p>\n<p><code>group.id</code> 消费者组名称</p>\n<p><code>key.deserializer</code>  反序列化</p>\n<p><code>value.deserializer</code></p>\n<p>参数众多，直接使用org.apache.kafka.clients.consumer.ConsumerConfig</p>\n<p>每个参数在ConsumerConfig类中都有对应的名称</p>\n<p>如ConsumerConfig.GROUP_ID_CONFIG</p>\n<h3 id=\"订阅主题与分区\"><a href=\"#订阅主题与分区\" class=\"headerlink\" title=\"订阅主题与分区\"></a>订阅主题与分区</h3><p>一个消费者可以订阅一个或多个主题，subscribe的几个重载方法</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> topics<span class=\"token punctuation\">,</span> ConsumerRebalanceListener listener<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> topics<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Pattern pattern<span class=\"token punctuation\">,</span> ConsumerRebalanceListener listener<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Pattern pattern<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>1.集合方式，<code>subscribe(Collection&lt;String&gt; topics)</code>订阅了什么就消费什么主题的消息。</p>\n<p>2.正则表达式，如果采用正则表达式的方式，在之后如果有人创建了新的主题，且主题名字与正则表达式匹配，那么这个消费者就可以消费到新添加的主题中的消息。<br>例 <code>cosumer.subscribe(Pattern.compile(&quot;topic.*&quot;))</code><br>参数类型<code>ConsumerRebalanceListener</code>，设置的是再均衡监听器</p>\n<p>3.消费者还能直接订阅某些主题的特定分区</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">assign</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>例：<code>public List&lt;PartitionInfo&gt; partitionsFor(String topic)</code></p>\n<p>TopicPartition类表示分区</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TopicPartition</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Serializable</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> partition<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//分区</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String topic<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//主题</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>如果事先不知道主题中有多少分区，则使用partitionsFor()方法查询指定主题的元数据信息</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> List<span class=\"token operator\">&lt;</span>PartitionInfo<span class=\"token operator\">></span> <span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>String topic<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">PartitionInfo</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String topic<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> paitition<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Node leader<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Node<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> replicas<span class=\"token punctuation\">;</span>  <span class=\"token comment\" spellcheck=\"true\">//AR</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Node<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> inSyncReplicas<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//ISR</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Node offlineReplicas<span class=\"token punctuation\">;</span>  <span class=\"token comment\" spellcheck=\"true\">//OSR</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>取消订阅</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">consumer<span class=\"token punctuation\">.</span><span class=\"token function\">unsubscribe</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>如果没有订阅任何主题或分区，那么继续执行消费程序会报异常IllegalStateException</p>\n<p>订阅状态:<br>集合订阅  <code>AUTO_TOPICS</code><br>正则表达式订阅 <code>AUTO_PATTERN</code><br>指定分区订阅 <code>USER_ASSIGNED</code></p>\n<p>通过subscribe()方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下，可以根据分区分配策略来自动分配各个消费者与分区的关系。</p>\n<h3 id=\"反序列化\"><a href=\"#反序列化\" class=\"headerlink\" title=\"反序列化\"></a>反序列化</h3><p>反序列化器也实现了Deserializer接口，这个接口有以下三个方法：</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">configure</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> <span class=\"token operator\">?</span><span class=\"token operator\">></span> configs<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> isKey<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> T <span class=\"token function\">deserialize</span><span class=\"token punctuation\">(</span>String topic<span class=\"token punctuation\">,</span> <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> data<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"消息消费\"><a href=\"#消息消费\" class=\"headerlink\" title=\"消息消费\"></a>消息消费</h3><p>消费模式：推模式和拉模式<br>推模式：服务端主动将消息推送给消费者<br>拉模式：消费者主动向服务端发起请求来拉取消息</p>\n<p>poll方法定义:</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> ConsumerRecords<span class=\"token operator\">&lt;</span>K<span class=\"token punctuation\">,</span> V<span class=\"token operator\">></span> <span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> Duration timeout<span class=\"token punctuation\">)</span> <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>timeout参数用来控制poll方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞。</p>\n<p>ConsumerRecord定义</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">ConsumerRecord</span><span class=\"token operator\">&lt;</span>K<span class=\"token punctuation\">,</span> V<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String topic<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> partition<span class=\"token punctuation\">;</span> \n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> offset<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 消息所属分区的偏移量</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> timestamp<span class=\"token punctuation\">;</span> \n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> TimestampType timestampType<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> serializedKeySize<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> serializedValueSize<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Headers headers<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 消息的头部内容</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> K key<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> V value<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">volatile</span> Long checksum<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// CRC32的校验值</span>\n  <span class=\"token comment\" spellcheck=\"true\">// ...</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>它提供了iterator方法来循环遍历消息集内部的消息</p>\n<p><code>public Iterator&lt;ConsumerRecord&lt;K, V&gt;&gt; iterator()</code></p>\n<p>它提供了获取消息集中指定分区消息的方法<br><code>public List&lt;ConsumerRecord&lt;K, V&gt;&gt; records(TopicPartition partition)</code></p>\n<p>它还提供了按照主题维度来进行消费的方法<br><code>public Iterable&lt;ConsumerRecord&lt;K, V&gt;&gt; records(String topic)</code></p>\n<h3 id=\"位移提交\"><a href=\"#位移提交\" class=\"headerlink\" title=\"位移提交\"></a>位移提交</h3><p>对于kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。<br>笔者对于消息在分区中的位置，这个offset称为‘偏移量’<br>对于消费者消费到的位移，这个offset称为‘消费位移’</p>\n<p>在每次调用poll方法时，它返回的是还没有被消费过的消息集，要做到这一点就要记录上一次消费时的消费位移。<br>消费位移要持久化保存，这个消费位移存储在kafka内部主题 <code>_consumer_offsets</code>中。消费者在消费完消息后需要执行消费位移的提交。</p>\n<p>当前消费到的位移x，即lastConsumedOffset；已经提交过的消费位移，即commited offset<br>需要提交的位移 x + 1，表示下条需要拉去的消息的位置，即position<br>position = commited offset = lastConsumedOffset + 1</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">position</span><span class=\"token punctuation\">(</span>TopicPartition partition<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> OffsetAndMetadata <span class=\"token function\">committed</span><span class=\"token punctuation\">(</span>TopicPartition partition<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>位移提交的时机需要把握，否则很容易引入消费混乱现象<br>例：x 上一次提交的消费位移，[x, x+8]本次poll到的消息<br>重复消费：<br>如果是消费完所有拉取到的消息之后才执行提交，那么当消费到中间x+5消费者发生异常重启，则会重复从x开始拉取消费</p>\n<p> 消息丢失：<br>如果拉取到消息之后就进行了位移提交x+8，那么当消费到中间x+5消费者发生异常重启，则直接从x+8开始消费，发生了消息丢失</p>\n<p>在kafka中默认的消费位移提交为自动提交，由参数<code>enable.auto.commit</code>配置；这个默认提交是定期提交，由参数<code>auto.commit.interval.ms</code>配置，自动位移提交的动作是在poll方法的逻辑里完成的。</p>\n<p>自动提交消费位移也可能造成消费混乱现象：<br>重复消费：假设刚刚提交完消费位移，然后拉取一批消息进行消费，在下一次自动提交消费位移之前，消费者重启了，那么又得从上一次位移提交的地方重新开始消费。</p>\n<p>消息丢失；假设拉取线程A不断拉取存入本地缓存，消费线程B从缓存中读取，当已经提交的消费位移大于消费线程B消费到的消息，且发生重启时，就会发生消息丢失。</p>\n<p>手动提交方式：<br>同步提交：<br><code>public void commitSync</code><br><code>public void commitSync(final Map&lt;TopicOartition, OffsetAndMetadata&gt; offsets)</code></p>\n<p>异步提交：<br><code>public void commitAsync</code><br><code>public void commitAsync(OffsetCommitCallback callback)</code><br><code>public void commitAsync(final Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, OffsetCommitCallback callback)</code></p>\n<p>commitSync方法会根据poll方法拉取的最新位移来进行提交，只有没有发生不可恢复的错误，它就会阻塞消费者线程直至位移提交完成。</p>\n<p>带参数的commitSync方法提供了offsets参数，用来提交指定分区的位移。</p>\n<p>异步提交的方式在执行的时候消费者线程不会被阻塞，可能在提交消费位移的结果还未返回之前就开始了新一次的拉去操作。它提供的异步方法中支持指定回调函数，它会在位移提交完成后回调OffsetCommitCallback中的onComplete()方法。</p>\n<p>异步提交的时候同样会发生失败，如果消费位移提交了x失败， 下一次提交了x+y成功了，而这里前一步的提交x重试成功，那么消费位移又变成了x，这里消费者重启就会发生重复消费。<br>要避免这个问题可以在位移提交失败需要重试的时候检查提交位移和前一个位移的大小，当发现小于前一个提交的位移大小，则说明有更大的位移已经提交了，可以不用本次重试。</p>\n<h3 id=\"控制或关闭消费\"><a href=\"#控制或关闭消费\" class=\"headerlink\" title=\"控制或关闭消费\"></a>控制或关闭消费</h3><p>pause和resume来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">pause</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">resume</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>还可以检查被暂停的分区集合<br><code>public Set&lt;TopicPartition&gt; paused()</code></p>\n<p>kafka consumer提供了close方法来实现关闭</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span>Duration timeout<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> timeout<span class=\"token punctuation\">,</span> TimeUnit timeUnit<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>第一种方法没有timeout参数，并不意味着会无限制的等待，它内部设定了最长等待时间30s</p>\n<h3 id=\"指定位移消费\"><a href=\"#指定位移消费\" class=\"headerlink\" title=\"指定位移消费\"></a>指定位移消费</h3><p>当一个新的消费组建立的时候，它根本没有可以查找的消费位移。或者消费组内的一个消费者订阅了一个新的主题，它也没有可以查找的消费位移。当_consumer_offsets主题中有关这个消费组的位移信息过期而被删除后，它没有可以查找的消费位移。</p>\n<p><code>auto.offset.reset</code>参数配置当消费者查不到所记录的消费位移时，就会根据该配置来决定从何处开始消费<br>可配置的值：<br><code>latest</code> ：从分区末尾开始消费消息<br><code>earliest</code> ：从起始处开始消费消息<br><code>none</code> ： 不从末尾也不从开始处开始消费，报NoOffsetForPartitionException异常</p>\n<p>seek方法提供了从特定位移处开始拉去消息的功能</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>TopicPartition partition<span class=\"token punctuation\">,</span> <span class=\"token keyword\">long</span> offset<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>seek方法只能重置消费者分配到的分区的消费位置，而分区的分配是在poll方法的调用过程中实现的，也就是说，在执行seek方法之前需要先执行一次poll方法。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">KafkaConsumer <span class=\"token operator\">&lt;</span>String String<span class=\"token operator\">></span> consumer<span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span> <span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \ncosumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays <span class=\"token function\">asList</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duratio <span class=\"token function\">ofMillis</span><span class=\"token punctuation\">(</span><span class=\"token number\">10000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \nSet<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> assignment <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">assignment</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Top cPartition tp <span class=\"token operator\">:</span> assignment<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>tp <span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \nConsumerRecords<span class=\"token operator\">&lt;</span>String <span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token function\">DurationofMllis</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n<span class=\"token comment\" spellcheck=\"true\">//consume the record .</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>如果我们将代码清单 中第①行 poll （）方法的参数设置为 ，即这 行替换为<br><code>consumer poll(Duration.ofMillis(0)) ;</code></p>\n<p>此之后， 会发现 seek（） 方法并未有任何作用。因为当 poll （）方法中 参数为0时，此方法立刻返回，那么 poll （） 方法内部进行分区分配的逻辑就会来不及实施。</p>\n<p>如果对未分配到的分区执行 seek（） 方法 那么会报出IllegalStateException 的异常。类似在调用 subscrib （） 方法之后直接调用 seek（） 方法</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">consumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>会报出如下的异常<br>java.lang.I llegalStateException: No current assignment for partition topic- demo - 0</p>\n<p>seek的几个方法定义</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> Map<span class=\"token operator\">&lt;</span>Top cPartition Long<span class=\"token operator\">></span> <span class=\"token function\">endOffsets</span><span class=\"token punctuation\">(</span> Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">public</span> Map<span class=\"token operator\">&lt;</span>TopicPartition <span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> <span class=\"token function\">endOffsets</span><span class=\"token punctuation\">(</span> Collection<span class=\"token operator\">&lt;</span>Top cPartit on<span class=\"token operator\">></span> part tions\nDuration timeout<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">public</span> Map<span class=\"token operator\">&lt;</span>TopicPartition <span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> beginningOff <span class=\"token function\">sets</span> <span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">public</span> Map<span class=\"token operator\">&lt;</span>TopicPart tion Long<span class=\"token operator\">></span> <span class=\"token function\">beginningOffsets</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">,</span> \nDuration timeout<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">seekToBeginning</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> seekToEnd Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">public</span> Map<span class=\"token operator\">&lt;</span>TopicPartition <span class=\"token punctuation\">,</span> OffsetAndTimestamp<span class=\"token operator\">></span> <span class=\"token function\">offsetsForTimes</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> timestampsToSearch<span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">public</span> Map<span class=\"token operator\">&lt;</span>TopicPartition OffsetAndTimestamp<span class=\"token operator\">></span> <span class=\"token function\">offsetsForTimes</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> t imestampsToSearch<span class=\"token punctuation\">,</span>Duration timeout <span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"再均衡\"><a href=\"#再均衡\" class=\"headerlink\" title=\"再均衡\"></a>再均衡</h3><p>再均衡是指分区的所属权从一个消费者转移到另一消费者的行为。在再均衡发生期间，消费组内的消费者是无法读取消息的。 就是说，在再均衡发生期间的这一小段时内，消费组会变得不可用 。</p>\n<p>比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作 之后这个分区又被分配给了消费组 的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。</p>\n<p>再均衡监听器</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">void</span> <span class=\"token function\">onPartitionsRevoked</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">onPartitionsAssigned</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> partitions<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> currentOffsets <span class=\"token operator\">=</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ConsumerRebalanceListener</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n<span class=\"token annotation punctuation\">@Override</span> \n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onPartitionsRevoked</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token operator\">></span> part tions<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitSync</span><span class=\"token punctuation\">(</span>currentOffsets<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \ncurrentOffsets<span class=\"token punctuation\">.</span><span class=\"token function\">clear</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n<span class=\"token annotation punctuation\">@Override</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onPartitionsAssigned</span><span class=\"token punctuation\">(</span>Collection<span class=\"token operator\">&lt;</span>TopicPartition partitions<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n<span class=\"token comment\" spellcheck=\"true\">//do nothing . </span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"消费者拦截器\"><a href=\"#消费者拦截器\" class=\"headerlink\" title=\"消费者拦截器\"></a>消费者拦截器</h3><p>消费者拦截器需要自定义实现 org.apache.kafka.clients.consumer.Consumerlnterceptor 接口。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> ConsumerRecords<span class=\"token operator\">&lt;</span>K<span class=\"token punctuation\">,</span> V<span class=\"token operator\">></span> <span class=\"token function\">onConsume</span><span class=\"token punctuation\">(</span>ConsumerRecords<span class=\"token operator\">&lt;</span>K <span class=\"token punctuation\">,</span> V<span class=\"token operator\">></span> records<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onCommit</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> offsets<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>Kafkaconsumer 会在 poll （）方法返回之前调用拦截器的 Consume（） 方法来对消息进行相应<br>的定制 操作，KafkaConsumer 会在提交完消费位移之后调用拦截器的 onCommit（） 方法</p>\n<p>在消费者中也有拦截链的概念，和生产者的拦截链一样， 也是按照工interceptor classes参数配置的拦截器的顺序来一一执行的（配置的时候，各个拦截器之间使用逗号隔开）。同样也要提防“副作用”的发生 如果在拦截链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。</p>\n<h3 id=\"多线程实现\"><a href=\"#多线程实现\" class=\"headerlink\" title=\"多线程实现\"></a>多线程实现</h3><p>KatkaProducer 是线程安全的，然而 KafkaConsumer 却是非线程安全 KafkaConsumer定义了 acquire （） 方法，用来检测当前是否只有 个线程在操作，若有其他线程正在操作则会抛出 ConcurrentModifcationException 异常</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> AtomicLong currentThread <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Atom</span> <span class=\"token function\">cLong</span><span class=\"token punctuation\">(</span>NO CURRENT THREAD <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//Kaf aConsumer 中的成员变量</span>\n\n<span class=\"token keyword\">private</span> <span class=\"token keyword\">void</span> <span class=\"token function\">acquire</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n<span class=\"token keyword\">long</span> threadid <span class=\"token operator\">=</span> Thread<span class=\"token punctuation\">.</span><span class=\"token function\">currentThread</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>threadid <span class=\"token operator\">!=</span> currentThread<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token operator\">!</span>currentThread<span class=\"token punctuation\">.</span><span class=\"token function\">compareAndSet</span><span class=\"token punctuation\">(</span>NO_CURRENT THREAD<span class=\"token punctuation\">,</span> threadid<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">throw</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ConcurrentModificationException</span> \n<span class=\"token punctuation\">(</span><span class=\"token string\">\"KafkaConsumer is not safe for multi- threaded access \"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \nrefcount<span class=\"token punctuation\">.</span><span class=\"token function\">incrementAndGet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>acquire（）方法和 release （）方法成对出现，表示相应的加锁和解锁操作。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">private</span> <span class=\"token keyword\">void</span> <span class=\"token function\">release</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>refcount<span class=\"token punctuation\">.</span><span class=\"token function\">decrementAndGet</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    currentThread<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span>NO CURRENT THREAD<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>多线程的目的就是为了提高整体的消费能力。多线程的实现方式有多种，第一种也是最常见的方式 线程封闭，即为每个线程实例化一个 KafkaConsumer 对象。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030190716.png\" alt></p>\n<p>一个消费线程可消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数，当消费线程的个数大于分区数时 就有部分消费线程一直处于空闲的状态。</p>\n<p>多个消费线程同时消费同一个分区 ，这个通过 assign（）、 seek （）等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力 。不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n    Properties props <span class=\"token operator\">=</span> <span class=\"token function\">itConfig</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token keyword\">int</span> consumerThreadNum <span class=\"token operator\">=</span> <span class=\"token number\">4</span> <span class=\"token punctuation\">;</span> \n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i<span class=\"token operator\">=</span>O<span class=\"token punctuation\">;</span>i<span class=\"token operator\">&lt;</span>consumerThreadNum<span class=\"token punctuation\">;</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n    <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumerThread</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">,</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">KafkaConsumerThread</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> KafkaConsumer<span class=\"token operator\">&lt;</span>String <span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> kafkaConsumer<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">public</span> <span class=\"token function\">KafkaConsumerThread</span><span class=\"token punctuation\">(</span>Properties props<span class=\"token punctuation\">,</span> String topic<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n    <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>kafkaConsumer <span class=\"token operator\">=</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>kafkaConsumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays <span class=\"token function\">asList</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span> \n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span> \n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n        ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> \n        kafkaConsumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span> <span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofMill</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token number\">00</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> Stri g<span class=\"token operator\">></span> record <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n        <span class=\"token comment\" spellcheck=\"true\">// 处理消息模块 ① </span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n        e<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span> \n        kafkaConsumer<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别， 优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的TCP 连接 如果分区数和 consumerThreadNum 的值都很大，那么会造成不 的系统开销。</p>\n<p>这里的处理速度取决于处理消息模块，。一般 言， poll（）拉取消息的速度是相当快的 ，而整体消费的瓶颈是在处理消息这一块， 通过－定的方式来改进这一部分，那么就能带动整体消费性能提升。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030193459.png\" alt></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">    <span class=\"token annotation punctuation\">@Override</span> \n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span> \n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n        ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> \n        kafkaConsumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofMill</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token number\">00</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>records<span class=\"token punctuation\">.</span><span class=\"token function\">isEmpty</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n            executorService<span class=\"token punctuation\">.</span><span class=\"token function\">submit</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">RecordsHandler</span><span class=\"token punctuation\">(</span>records<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\" spellcheck=\"true\">// 调用各个hander处理消息</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n        e<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span> \n        kafkaConsumer<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">RecordsHandler</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">{</span> \n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records<span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">public</span> RecordsHandl <span class=\"token function\">er</span> <span class=\"token punctuation\">(</span>ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span> \n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>records <span class=\"token operator\">=</span>records<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span> \n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token comment\" spellcheck=\"true\">// 处理records</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>RecordHandler 类是用来处理消息的，而 KafraConsumerThread 类对应的是一个消费线程，里面通过线程池的方式来调用 RecordHandler 处理一批批的消息。</p>\n<p>引入一个共享<br>变量 offsets 来参与提交</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030200350.png\" alt></p>\n<p>每一个处理消息的 RecordHandler 类在处理完消息之后都将对应的消费位移保存到共享变量offsets 中， KafraConsumerThread 在每一次 poll （）方法之后都读取 offsets 中的内容并对其进行位移提交。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>TopicPartition tp <span class=\"token operator\">:</span> records <span class=\"token punctuation\">.</span><span class=\"token function\">partitions</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n    List<span class=\"token operator\">&lt;</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String <span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> tpRecords <span class=\"token operator\">=</span> records <span class=\"token punctuation\">.</span> <span class=\"token function\">records</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token comment\" spellcheck=\"true\">// 处 tpRec ords</span>\n    <span class=\"token keyword\">long</span> lastConsumedOffset <span class=\"token operator\">=</span> tpRecords <span class=\"token punctuation\">.</span> <span class=\"token function\">get</span> <span class=\"token punctuation\">(</span>tpRecords<span class=\"token punctuation\">.</span> <span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">.</span> <span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \n    <span class=\"token keyword\">synchronized</span> <span class=\"token punctuation\">(</span>offsets<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n        <span class=\"token keyword\">if</span> offsets<span class=\"token punctuation\">.</span>co ta 工口 <span class=\"token function\">sKey</span> <span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n            offsets<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">OffsetAndMetadata</span><span class=\"token punctuation\">(</span>lastConsumedOffset <span class=\"token operator\">+</span> l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span> \n            <span class=\"token keyword\">long</span> position <span class=\"token operator\">=</span> offsets <span class=\"token punctuation\">.</span> <span class=\"token function\">get</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> \n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>position <span class=\"token operator\">&lt;</span> lastConsumedOffset <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n            offsets<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">OffsetAndMetadata</span><span class=\"token punctuation\">(</span>lastConsumedOffset <span class=\"token operator\">+</span> l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">synchronized</span> <span class=\"token punctuation\">(</span>offsets<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>offsets<span class=\"token punctuation\">.</span> <span class=\"token function\">isEmpty</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n    kafkaConsumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitSync</span><span class=\"token punctuation\">(</span>offsets<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    offsets<span class=\"token punctuation\">.</span><span class=\"token function\">clear</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>假设一个处理线程 RecordHand erl 正在处理 offset 99消息，而另一个处理线程 RecordHand er2 己经处理完了 offset 100 99 的消息并进行了位移提交，此时如果 RecordHandler 发生异常，则之后的消费只能从 200 开始而无法再次消费 99的消息，从而造成了消息丢失的现象。这里虽然针对位移覆盖做了一定的处理，但还没有解决异常情况下的位移覆盖问题。</p>\n<p>通过消费者拉取分批次的消息，然后提交给多线程进行处理，而这里的滑动窗口式的实现方式是将拉取到的消息暂存起来， 多个消费线程可以拉取暂存的消息，这个用于暂存消息的缓存大小即为滑动窗口的大小， 总体上而言没有太多的变化 不同的是对于消费位移的把控。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030201350.png\" alt></p>\n<p>startOffset标注的是当前滑动 口的起始位置 endOffset 注的是末尾位置。每当 startOffset 指向的方格中的消息被消 费完成，就可以提交这部分的位移，与此同时，窗 口向 前滑动一格， 除原来startOffset 所指方格中对应的消息 并且拉取新的消息进入窗口。</p>\n<p>滑动窗口的大小固定，所对应的用来暂 消息的缓存大小也就固定了，这部分内存开销可控。方格大小和滑动窗口的大小同决定了消费线程的并发数。</p>\n<p>如果 个方格内的消 息无法被标记为消费完成，那么就会造成 startOffset 悬停。为了使窗口能够继续向前滑动 那么就需要设定 个闹值，当 startOffset 悬停一定的时间后就对这部分消息进行本地重试消费，如果重试失败就转入重试队列，如果还不奏效就转入死信队列。</p>\n<h3 id=\"重要的消费者参数\"><a href=\"#重要的消费者参数\" class=\"headerlink\" title=\"重要的消费者参数\"></a>重要的消费者参数</h3><p><code>fetch.min.bytes</code>：Consumer 在一次拉取请求（调用 poll （） 方法）中能从 Kafka 中拉取的最小<br>数据量，默认值为 1B。</p>\n<p><code>fetch .max.bytes</code>：配置 Consumer 在一次拉取请求中从 Kafka中拉取的最大数据 ，默认值为 52428800 ，也就是 50MB</p>\n<p><code>fetch.max.wait.ms</code>：于指定 Kafka 的等待时间，默认值为 500ms</p>\n<p><code>max.partition.fetch.bytes</code>：配置从每个分区里返回给 Consumer的最大数据 ，默认值为 1048576 (B)</p>\n<p><code>max.poll.records</code>：配置 Consumer 次拉取请求中拉取的最大消息数，默认值为 500 （条）</p>\n<p><code>connections.max.idle.ms</code>：指定在多久之后关闭限制的连接，默认值是 540000 (ms ），即 分钟。</p>\n<p><code>exclude.internal.topics</code>：Kafka 中有两个内部的主题：_consumer_offsets 和 _transaction_state。 exclude.internal.topics用来指定 Kafka 中的内部主题是否可以向消费者公开，默认值为 true 。</p>\n<p><code>receive.buffer.bytes</code>：这个参数用来设置 Socket 接收消息缓冲区的大小，默认值为 65536 (B)</p>\n<p><code>send.buffer.bytes</code>：设置 Socket 发送消息缓冲区的大小，默认13 1072 (B)</p>\n<p><code>request.timeout.ms</code>：来配置 Consumer 等待请求响应的最长时间，默认值为 30000ms</p>\n<p><code>metadata.max.age.ms</code>：用来配置元数据的过期时间，默认值为 300000 ms</p>\n<p><code>reconnect.backoff.ms</code>：配置尝试重新连接指定主机之前的等待时间，默认值为50ms</p>\n<p><code>retry.backo ms</code>：配置尝试重新发送失败的请求到指定的主题分区之前的等待（退避〉时间，</p>\n<p><code>isolation.level</code>：配置消费者的事务隔离级别。有效值为“read uncommitted ，，和<br>“ read committed ＂</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030202942.png\" alt></p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030202957.png\" alt></p>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<p>kafka角色：</p>\n<ul>\n<li>消息系统：Kafka和传统的消息系统都具备系统解耦性、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。Kafka还提供大多数消息系统难以实现的消息顺序性保障和回溯消费功能</li>\n<li>存储系统：Kafka把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于Kafka的消息持久化功能和多副本机制，我们可以吧Kafka作为长期对的数据存储系统来使用。</li>\n<li>流式处理平台：Kafka不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库</li>\n</ul>\n<h1 id=\"初识Kafka\"><a href=\"#初识Kafka\" class=\"headerlink\" title=\"初识Kafka\"></a>初识Kafka</h1><h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><ul>\n<li>Producer：生产者，也就是发送消息的一方，生产者负责创建消息，然后将其投递到Kafka中</li>\n<li>Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理</li>\n<li>Broker：服务代理结点：对于Kafka而言，Broker可以简单的看做一个独立的Kafka服务结点或Kafka服务实例。</li>\n<li>主题：Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题，而消费者负责订阅主题并进行消费</li>\n<li>分区：一个分区只属于单个主题，同一主题下不同分区包含的消息是不同的，分区在存储层面可以看做一个可追加的日志文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量。如果一个主题只对应一个文件，那么这个文件所在的机器IO将会成功这个主题的性能瓶颈，而通过增加分区的数量可以实现水平扩展。</li>\n<li>Offset偏移量：offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，Kafka保证分区有序而不是主题有序</li>\n<li>副本因子：副本个数；通过增加副本数量可以提升容灾能力，leader副本负责处理读写请求，follower副本负责与leader副本消息同步。当leader副本出现故障时，从follower副本中重新选举leader副本对外提供服务。kafka通过多副本机制实现了故障的自动转移。</li>\n<li>AR：分区内所有副本(assigned replicas)</li>\n<li>ISR:所有与leader副本保持一定程度同步的副本(in-sync replicas)</li>\n<li>OSR:与leader副本同步滞后过多的副本 (out-of-sync replicas)</li>\n<li>HW:高水位：标识一个特定的offset，消费者只能拉取到这个offset之前的消息 (high watermark)</li>\n<li>LEO: 标识当前日志文件中下一条待写入消息的offset (Log End Offset)</li>\n</ul>\n<p>新产生的消息会先写入leader副本，然后follower副本会发送拉取请求来拉取落后的消息来进行消息同步。<br>当同步完成后，消费者才可以消费这条消息(为了防止leader副本宕机造成消息丢失)<br>kafka的复制机制既不是完全的同步复制，也不是单纯的落后复制。同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认为已成功提交，这种方式极大的影响了性能。而在异步复制方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就认为已经成功提交。(在这种情况下，如果follower副本都还没有复制完而落后与leader副本，突然leader副本宕机，则会造成数据丢失)。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221016191323.png\" alt></p>\n<h2 id=\"生产与消费\"><a href=\"#生产与消费\" class=\"headerlink\" title=\"生产与消费\"></a>生产与消费</h2><pre><code>./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-demo --replication-factor 3 --partitions 4\n\n\n./bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-demo \n\n./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic-demo\n\n./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic-demo</code></pre><p><code>zookeeper.connect</code>  zk集群服务地址<br><code>listeners</code> broker监听客户端连接的地址列表<br><code>broker.id</code> broker的唯一标识<br><code>log.dir</code> kafka日志文件存放的目录，默认/tmp/kafka-logs<br><code>log.dirs</code> 优先级高<br><code>message.max.bytes</code> broker所能接收消息的最大值</p>\n<h1 id=\"生产者\"><a href=\"#生产者\" class=\"headerlink\" title=\"生产者\"></a>生产者</h1><h2 id=\"生产者客户端开发\"><a href=\"#生产者客户端开发\" class=\"headerlink\" title=\"生产者客户端开发\"></a>生产者客户端开发</h2><p>步骤：</p>\n<ol>\n<li>配置生产者客户端参数及创建相应的生产者实例</li>\n<li>构建待发送的消息</li>\n<li>发送消息</li>\n<li>关闭生产者实例</li>\n</ol>\n<pre><code class=\"java\">public static Properties initConfig() {\n    Properties props = new Properties();\n    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n}\n\npublic static void main(String[] args) {\n    Properties props = initConfig();\n    KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n    ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;Hello, Kafka&quot;);\n\n    try {\n        producer.send(record);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}</code></pre>\n<p>消息对象ProducerRecord 并不是单纯意义上的消息，包含了多个属性</p>\n<pre><code class=\"java\">public class ProducerRecord&lt;K, V&gt; {\n    private final String topic;\n    private final Integer paitition;\n    private final Headers headers;\n    private final K key;\n    private final V value;\n    private final Long timestamp;\n}</code></pre>\n<p><code>bootstrap.servers</code> 指定生产者客户端连接kafka所需的broker地址清单<br><code>key.serializer</code> 序列化成字节数组<br><code>value.serializer</code></p>\n<ul>\n<li><p>KafkaProducer是线程安全的，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化来供其他线程调用</p>\n</li>\n<li><p>构建ProducerRecord 对象，topic属性和value属性是必填，其他选填</p>\n</li>\n</ul>\n<h3 id=\"发送消息\"><a href=\"#发送消息\" class=\"headerlink\" title=\"发送消息\"></a>发送消息</h3><p>发送消息的三种模式<br>发后即忘：send方法不指定Callback，性能最高，可靠性最差</p>\n<p>同步：send方法利用返回的Future对象，阻塞等待Kafka响应</p>\n<p>异步：send方法，指定Callback回调函数</p>\n<p>可重试异常和不可重试异常</p>\n<p>对于可重试异常，如果配置了retries参数，那么只要在规定的重试次数内自行恢复，就不会抛出异常</p>\n<p>对于不可重试的异常，则直接抛出异常，不进行重试</p>\n<p>对于同一个分区而言，如果消息record1先与record2发送，那么KafkaProducer就可以保证对应的callback1先与callback2调用</p>\n<h3 id=\"序列化器\"><a href=\"#序列化器\" class=\"headerlink\" title=\"序列化器\"></a>序列化器</h3><p>生产者需要使用序列化器将对象转换成字节数组，才能通过网络发送给Kafka，在对端消费者使用反序列化器把Kafka转换成相应的对象</p>\n<p>序列化器实现了org.apache.kafka.common.serialization.Serializer接口</p>\n<p>一般要实现</p>\n<pre><code class=\"java\">public void configure(Map&lt;String, ?&gt;configs,boolean isKey)\npublic byte[]serialize(String topic, T data)\npublic void close()</code></pre>\n<p>可以使用Avro、JSON、Thrift、Protobuf、Protostuff等通用工具来实现</p>\n<h3 id=\"分区器\"><a href=\"#分区器\" class=\"headerlink\" title=\"分区器\"></a>分区器</h3><pre><code class=\"java\">public int partition(String topic, Object key,byte[] keyBytes, Object Value, byte[] valueBytes,Cluster cluster);\npublic void close();</code></pre>\n<ul>\n<li><p>如果ProducerRecord中指定了partition字段，则不需要分区器，partition字段就是要发往的分区号</p>\n</li>\n<li><p>如果没有指定分区器，就需要分区器根据key字段来计算partition值。Kafka的默认分区器实现了 xx.Partitioner接口，接口中有partition方法和close方法<br>默认分区器会判断key不为null，则对key进行哈希，最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息会以轮询的方式发往主题内的某一个可用分区</p>\n</li>\n</ul>\n<p>  自定义分区器也只需实现上述接口即可</p>\n<h3 id=\"生产者拦截器\"><a href=\"#生产者拦截器\" class=\"headerlink\" title=\"生产者拦截器\"></a>生产者拦截器</h3><p>消息发送前做一些过滤，修改等等</p>\n<p>需要自定义实现ProducerInterceptor接口</p>\n<p>KafkaProducer会在消息被应答之前或消息发送失败时调用拦截器的onAcknowledgement方法，优于用户设定的Callback之前执行。</p>\n<pre><code class=\"java\">public ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; record);\npublic void onAcknowledgement(RecordMetadata metadata, Exception exception);\npublic void close();</code></pre>\n<p>可以指定一个拦截链，KafkaProducer按照interceptor.classes参数配置的拦截器的顺序来一一执行（各个拦截器按逗号隔开）</p>\n<h2 id=\"原理分析\"><a href=\"#原理分析\" class=\"headerlink\" title=\"原理分析\"></a>原理分析</h2><h3 id=\"整体架构\"><a href=\"#整体架构\" class=\"headerlink\" title=\"整体架构\"></a>整体架构</h3><p><img src=\"/2022/10/16/kafka-producer-consumer/producer-structure.jpg\" alt=\"生产者客户端整体架构\"></p>\n<p>生产者客户端有两个线程，主线程和Sender线程。主线程生产消息经过拦截器、序列化器、分区器缓存到消息累加器中，Sender线程从RecordAccumulator中获取消息并发往Kafka中</p>\n<p><code>buffer.memory</code>： 指定RecordAccumulator缓存的大小</p>\n<p><code>max.block.ms</code>：指定生产者发送太快，缓冲区满了，阻塞的最大时间</p>\n<p>RecordAccumulator缓存的大小由buffer.memory配置；如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时候producer的send方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的设置。</p>\n<p>RecordAccumulator为每个分区维护一个双端队列，队列内容为ProducerBatch，ProducerBatch为一个至多个ProducerRecord；可以使得生产者创建的消息组成一个批次，更为紧凑。</p>\n<p>消息在网络上传输是以字节传输的，发送之前要创建内存区域。kafka生产者中，通过java.io.ByteBuffer实现消息内存创建和释放。RecordAccumulator内部还有一个BufferPool，实现ByteBuffer的复用。BufferPool只针对特定大小的ByteBuffer进行管理，这个大小由<code>batch.size</code>指定。</p>\n<p><code>batch.size</code> 指定ByteBuffer的大小</p>\n<p>ProducerBatch的大小和batch.size相关。当一条ProducerRecord消息到了RecordAccumulator，会先寻找与分区对应的双端队列(如果没有则新建)，再从尾部获取一个ProducerBatch，查看该ProducerBatch中是否还可以写入这个ProducerRecord，可以写入则写入，不可以写入则新建ProducerBatch。</p>\n<p>新建ProducerBatch时，判断这条ProducerRecord消息大小是否超过batch.size没超过，则就以batch.size的大小新建ProducerBatch，这段内存还可以由ByterBuffer复用；如果超过了则以评估的大小新建ProducerBatch，这段内存不会被复用。</p>\n<p>Sender从RecordAccumulator获取缓存的消息后，进一步将原本的<code>&lt;分区，Deque&lt;ProducerBatch&gt;&gt;</code> 转换为 <code>&lt;Node, List&lt;ProducerBatch&gt;&gt;</code>Node表示kafka集群的结点。生产者向具体的broker结点发消息。</p>\n<p>Sender还会进一步封装为<code>&lt;Node, Request&gt;</code>才发往各个Node，请求在从Sender发往kafka之前会保存到InFlightRequests中，保存形式为<code>Map&lt;NodeId, Deque&lt;Request&gt;&gt;</code>主要作用是缓存了已经发出去，但是还没有收到响应的请求。</p>\n<p>这里限制了每个连接最多缓存的请求数，由<code>max.in.flight.requests.per.connecttion</code>指定，默认为5</p>\n<h3 id=\"元数据的更新\"><a href=\"#元数据的更新\" class=\"headerlink\" title=\"元数据的更新\"></a>元数据的更新</h3><p>Node中未确认的请求越多，则认为负载越大。</p>\n<p>选择leastLoadedNode发送请求可以使它能尽快发出，避免网络拥塞等异常的影响。<br>leastLoadedNode，即所有Node中负载最小的。</p>\n<p>leastLoadedNode还可以用于<strong>元数据请求</strong>、<strong>消费者组播协议的交互</strong></p>\n<p>如果发送一个很简单的消息</p>\n<pre><code>ProducerRecord&lt;string, string&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello&quot;);</code></pre><p>这里只有主题和消息<br>KafkaProducer需要将消息追加到指定主题的某个分区的对应leader副本之前。需要知道分区数目，计算出目标分区，需要知道目标分区的leader副本所在broker结点的地址、端口信息。这些需要的信息都属于<strong>元数据信息</strong>。</p>\n<p>bootstrap.servers参数只需要配置部分broker结点的地址，客户端可以发现其他broker结点的地址，这一过程属于元数据更新。</p>\n<p>客户端没有元数据信息时，会先选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作由Sender线程发起，在创建完MetadataRequest后同样会存入inFlightRequests。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里数据同步通过synchronized 和 final关键字保障。</p>\n<h3 id=\"重要的生产者参数\"><a href=\"#重要的生产者参数\" class=\"headerlink\" title=\"重要的生产者参数\"></a>重要的生产者参数</h3><p><code>acks</code>：指定分区中必须要有多少副本收到这条消息，之后生产者才会认为这条消息是成功写入的。</p>\n<p>默认acks = 1</p>\n<p>acks = 0 生产者发送消息之后不需要等待任何服务端响应</p>\n<p><code>max.request.size</code> 客户端能发送消息的最大值</p>\n<p>retries 和 retry.backoff.ms</p>\n<p><code>retries</code>是生产者重试的次数</p>\n<p><code>retry.backoff.ms</code> 两次重试之间的间隔，默认100ms</p>\n<p><code>compression.type</code> 默认值为none，指定消息压缩</p>\n<p><code>connections.max.idle.ms</code> 指定在多久之后关闭闲置的连接</p>\n<p><code>linger.ms</code> 指定生产者发送ProducerBatch之前等待更多ProducerRecord加入的时间</p>\n<p><code>receive.buffer.bytes</code> 设置Socket接收消息缓冲区大小  默认32kb</p>\n<p><code>send.buffer.bytes</code> Socket发送消息缓冲区大小</p>\n<p><code>request.timeout.ms</code> 配置Producer等待请求响应的最长时间，默认30000ms</p>\n<h1 id=\"消费者\"><a href=\"#消费者\" class=\"headerlink\" title=\"消费者\"></a>消费者</h1><h2 id=\"消费者与消费者组\"><a href=\"#消费者与消费者组\" class=\"headerlink\" title=\"消费者与消费者组\"></a>消费者与消费者组</h2><p>每个消费者都有一个对应的消费者组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。</p>\n<p>每个消费组消费全部分区的消息。</p>\n<p>消费者与消费组这种模型又可以让整体的消费能力具备横向伸缩性，我们可以增加消费者的个数来提高整体的消费能力。对于分区数固定的情况，一直增加消费者，到消费者个数超过分区数，就会有消费者分配不到分区。</p>\n<p>消息投递模式：<br>点对点模式：基于队列，消息生产者发送消息到队列，消费者从消息队列中接收消息。</p>\n<p>发布订阅模式：定义了如何想一个内容节点发布和订阅消息，这个内容节点叫做主题，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布订阅模式在消息的一对多广播时采用。</p>\n<p>kafka同时支持两种消息投递模式。</p>\n<ul>\n<li>如果所有的消费者隶属于一个消费者组，那么所有的消息都会被均衡的投递给每一个消费者，即每条消息只会被一个消费者处理，这相当于点对点。</li>\n<li>如果所有的消费者隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息都会被所有的消费者处理，相当于发布订阅模式应用。</li>\n</ul>\n<p>消费组是一个逻辑概念，每个消费者在消费前需要指定所属消费组的名称，由<code>group.id</code>指定。消费者是实际的应用实例，可以是一个线程，也可以是一个进程，同一个消费组的消费者既可以部署在同一机器上，也可以部署在不同机器上。</p>\n<h2 id=\"客户端开发\"><a href=\"#客户端开发\" class=\"headerlink\" title=\"客户端开发\"></a>客户端开发</h2><ol>\n<li>配置消费者客户端参数以及创建相应的消费者实例</li>\n<li>订阅主题</li>\n<li>拉取消息并消费</li>\n<li>提交消费位移</li>\n<li>关闭消费者实例</li>\n</ol>\n<pre><code class=\"java\">public class KafkaConsumerAnalysis {\n    public static final String brokerList = &quot;&quot;;\n    ...\n\n    public static Properties initConfig() {\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;, brokerList);\n    }\n\n    public static void main() {\n        Properties props = initConfig();\n        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsmer&lt;&gt;(props);\n        consumer.subscribe(Arrays.asList(topic));\n\n        try {\n            while(isRunning.get()) {\n                ConsumerRecrds&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000));\n\n            } catch (Exception e) {\n                log.error(&quot;&quot;);\n            } finally {\n                consumer.close();\n            }\n        }\n    }\n}</code></pre>\n<h3 id=\"必要的参数配置\"><a href=\"#必要的参数配置\" class=\"headerlink\" title=\"必要的参数配置\"></a>必要的参数配置</h3><p><code>bootstrap.servers</code> 集群broker地址</p>\n<p><code>group.id</code> 消费者组名称</p>\n<p><code>key.deserializer</code>  反序列化</p>\n<p><code>value.deserializer</code></p>\n<p>参数众多，直接使用org.apache.kafka.clients.consumer.ConsumerConfig</p>\n<p>每个参数在ConsumerConfig类中都有对应的名称</p>\n<p>如ConsumerConfig.GROUP_ID_CONFIG</p>\n<h3 id=\"订阅主题与分区\"><a href=\"#订阅主题与分区\" class=\"headerlink\" title=\"订阅主题与分区\"></a>订阅主题与分区</h3><p>一个消费者可以订阅一个或多个主题，subscribe的几个重载方法</p>\n<pre><code class=\"java\">public void subscribe(Collection&lt;String&gt; topics, ConsumerRebalanceListener listener);\npublic void subscribe(Collection&lt;String&gt; topics);\npublic void subscribe(Pattern pattern, ConsumerRebalanceListener listener);\npublic void subscribe(Pattern pattern);</code></pre>\n<p>1.集合方式，<code>subscribe(Collection&lt;String&gt; topics)</code>订阅了什么就消费什么主题的消息。</p>\n<p>2.正则表达式，如果采用正则表达式的方式，在之后如果有人创建了新的主题，且主题名字与正则表达式匹配，那么这个消费者就可以消费到新添加的主题中的消息。<br>例 <code>cosumer.subscribe(Pattern.compile(&quot;topic.*&quot;))</code><br>参数类型<code>ConsumerRebalanceListener</code>，设置的是再均衡监听器</p>\n<p>3.消费者还能直接订阅某些主题的特定分区</p>\n<pre><code class=\"java\">public void assign(Collection&lt;TopicPartition&gt; partitions);</code></pre>\n<p>例：<code>public List&lt;PartitionInfo&gt; partitionsFor(String topic)</code></p>\n<p>TopicPartition类表示分区</p>\n<pre><code class=\"java\">public final class TopicPartition implements Serializable {\n    private final int partition; //分区\n    private final String topic; //主题\n    ...\n}</code></pre>\n<p>如果事先不知道主题中有多少分区，则使用partitionsFor()方法查询指定主题的元数据信息</p>\n<pre><code class=\"java\">public List&lt;PartitionInfo&gt; partitionsFor(String topic)\n\npublic class PartitionInfo {\n    private final String topic;\n    private final int paitition;\n    private final Node leader;\n    private final Node[] replicas;  //AR\n    private final Node[] inSyncReplicas; //ISR\n    private final Node offlineReplicas;  //OSR\n}</code></pre>\n<p>取消订阅</p>\n<pre><code class=\"java\">consumer.unsubscribe()</code></pre>\n<p>如果没有订阅任何主题或分区，那么继续执行消费程序会报异常IllegalStateException</p>\n<p>订阅状态:<br>集合订阅  <code>AUTO_TOPICS</code><br>正则表达式订阅 <code>AUTO_PATTERN</code><br>指定分区订阅 <code>USER_ASSIGNED</code></p>\n<p>通过subscribe()方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下，可以根据分区分配策略来自动分配各个消费者与分区的关系。</p>\n<h3 id=\"反序列化\"><a href=\"#反序列化\" class=\"headerlink\" title=\"反序列化\"></a>反序列化</h3><p>反序列化器也实现了Deserializer接口，这个接口有以下三个方法：</p>\n<pre><code class=\"java\">public void configure(Map&lt;String, ?&gt; configs, boolean isKey)\npublic T deserialize(String topic, byte[] data)\npublic void close()</code></pre>\n<h3 id=\"消息消费\"><a href=\"#消息消费\" class=\"headerlink\" title=\"消息消费\"></a>消息消费</h3><p>消费模式：推模式和拉模式<br>推模式：服务端主动将消息推送给消费者<br>拉模式：消费者主动向服务端发起请求来拉取消息</p>\n<p>poll方法定义:</p>\n<pre><code class=\"java\">public ConsumerRecords&lt;K, V&gt; poll(final Duration timeout) </code></pre>\n<p>timeout参数用来控制poll方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞。</p>\n<p>ConsumerRecord定义</p>\n<pre><code class=\"java\">public class ConsumerRecord&lt;K, V&gt; {\n  private final String topic;\n  private final int partition; \n  private final long offset; // 消息所属分区的偏移量\n  private final timestamp; \n  private final TimestampType timestampType;\n  private final int serializedKeySize;\n  private final int serializedValueSize;\n  private final Headers headers; // 消息的头部内容\n  private final K key;\n  private final V value;\n  private volatile Long checksum; // CRC32的校验值\n  // ...\n}</code></pre>\n<p>它提供了iterator方法来循环遍历消息集内部的消息</p>\n<p><code>public Iterator&lt;ConsumerRecord&lt;K, V&gt;&gt; iterator()</code></p>\n<p>它提供了获取消息集中指定分区消息的方法<br><code>public List&lt;ConsumerRecord&lt;K, V&gt;&gt; records(TopicPartition partition)</code></p>\n<p>它还提供了按照主题维度来进行消费的方法<br><code>public Iterable&lt;ConsumerRecord&lt;K, V&gt;&gt; records(String topic)</code></p>\n<h3 id=\"位移提交\"><a href=\"#位移提交\" class=\"headerlink\" title=\"位移提交\"></a>位移提交</h3><p>对于kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。<br>笔者对于消息在分区中的位置，这个offset称为‘偏移量’<br>对于消费者消费到的位移，这个offset称为‘消费位移’</p>\n<p>在每次调用poll方法时，它返回的是还没有被消费过的消息集，要做到这一点就要记录上一次消费时的消费位移。<br>消费位移要持久化保存，这个消费位移存储在kafka内部主题 <code>_consumer_offsets</code>中。消费者在消费完消息后需要执行消费位移的提交。</p>\n<p>当前消费到的位移x，即lastConsumedOffset；已经提交过的消费位移，即commited offset<br>需要提交的位移 x + 1，表示下条需要拉去的消息的位置，即position<br>position = commited offset = lastConsumedOffset + 1</p>\n<pre><code class=\"java\">public long position(TopicPartition partition)\npublic OffsetAndMetadata committed(TopicPartition partition)</code></pre>\n<p>位移提交的时机需要把握，否则很容易引入消费混乱现象<br>例：x 上一次提交的消费位移，[x, x+8]本次poll到的消息<br>重复消费：<br>如果是消费完所有拉取到的消息之后才执行提交，那么当消费到中间x+5消费者发生异常重启，则会重复从x开始拉取消费</p>\n<p> 消息丢失：<br>如果拉取到消息之后就进行了位移提交x+8，那么当消费到中间x+5消费者发生异常重启，则直接从x+8开始消费，发生了消息丢失</p>\n<p>在kafka中默认的消费位移提交为自动提交，由参数<code>enable.auto.commit</code>配置；这个默认提交是定期提交，由参数<code>auto.commit.interval.ms</code>配置，自动位移提交的动作是在poll方法的逻辑里完成的。</p>\n<p>自动提交消费位移也可能造成消费混乱现象：<br>重复消费：假设刚刚提交完消费位移，然后拉取一批消息进行消费，在下一次自动提交消费位移之前，消费者重启了，那么又得从上一次位移提交的地方重新开始消费。</p>\n<p>消息丢失；假设拉取线程A不断拉取存入本地缓存，消费线程B从缓存中读取，当已经提交的消费位移大于消费线程B消费到的消息，且发生重启时，就会发生消息丢失。</p>\n<p>手动提交方式：<br>同步提交：<br><code>public void commitSync</code><br><code>public void commitSync(final Map&lt;TopicOartition, OffsetAndMetadata&gt; offsets)</code></p>\n<p>异步提交：<br><code>public void commitAsync</code><br><code>public void commitAsync(OffsetCommitCallback callback)</code><br><code>public void commitAsync(final Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, OffsetCommitCallback callback)</code></p>\n<p>commitSync方法会根据poll方法拉取的最新位移来进行提交，只有没有发生不可恢复的错误，它就会阻塞消费者线程直至位移提交完成。</p>\n<p>带参数的commitSync方法提供了offsets参数，用来提交指定分区的位移。</p>\n<p>异步提交的方式在执行的时候消费者线程不会被阻塞，可能在提交消费位移的结果还未返回之前就开始了新一次的拉去操作。它提供的异步方法中支持指定回调函数，它会在位移提交完成后回调OffsetCommitCallback中的onComplete()方法。</p>\n<p>异步提交的时候同样会发生失败，如果消费位移提交了x失败， 下一次提交了x+y成功了，而这里前一步的提交x重试成功，那么消费位移又变成了x，这里消费者重启就会发生重复消费。<br>要避免这个问题可以在位移提交失败需要重试的时候检查提交位移和前一个位移的大小，当发现小于前一个提交的位移大小，则说明有更大的位移已经提交了，可以不用本次重试。</p>\n<h3 id=\"控制或关闭消费\"><a href=\"#控制或关闭消费\" class=\"headerlink\" title=\"控制或关闭消费\"></a>控制或关闭消费</h3><p>pause和resume来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。</p>\n<pre><code class=\"java\">public void pause(Collection&lt;TopicPartition&gt; partitions)\npublic void resume(Collection&lt;TopicPartition&gt; partitions)</code></pre>\n<p>还可以检查被暂停的分区集合<br><code>public Set&lt;TopicPartition&gt; paused()</code></p>\n<p>kafka consumer提供了close方法来实现关闭</p>\n<pre><code class=\"java\">public void close()\npublic void close(Duration timeout)\npublic void close(long timeout, TimeUnit timeUnit)</code></pre>\n<p>第一种方法没有timeout参数，并不意味着会无限制的等待，它内部设定了最长等待时间30s</p>\n<h3 id=\"指定位移消费\"><a href=\"#指定位移消费\" class=\"headerlink\" title=\"指定位移消费\"></a>指定位移消费</h3><p>当一个新的消费组建立的时候，它根本没有可以查找的消费位移。或者消费组内的一个消费者订阅了一个新的主题，它也没有可以查找的消费位移。当_consumer_offsets主题中有关这个消费组的位移信息过期而被删除后，它没有可以查找的消费位移。</p>\n<p><code>auto.offset.reset</code>参数配置当消费者查不到所记录的消费位移时，就会根据该配置来决定从何处开始消费<br>可配置的值：<br><code>latest</code> ：从分区末尾开始消费消息<br><code>earliest</code> ：从起始处开始消费消息<br><code>none</code> ： 不从末尾也不从开始处开始消费，报NoOffsetForPartitionException异常</p>\n<p>seek方法提供了从特定位移处开始拉去消息的功能</p>\n<pre><code class=\"java\">public void seek(TopicPartition partition, long offset)</code></pre>\n<p>seek方法只能重置消费者分配到的分区的消费位置，而分区的分配是在poll方法的调用过程中实现的，也就是说，在执行seek方法之前需要先执行一次poll方法。</p>\n<pre><code class=\"java\">KafkaConsumer &lt;String String&gt; consumer= new KafkaConsumer&lt;&gt; (props); \ncosumer.subscribe(Arrays asList(topic));\nconsumer.poll(Duratio ofMillis(10000) ; \nSet&lt;TopicPartition&gt; assignment = consumer.assignment(); \nfor (Top cPartition tp : assignment) { \nconsumer.seek(tp , 10); \nwhile (true) { \nConsumerRecords&lt;String , String&gt; records = consumer.poll(DurationofMllis(1000)); \n//consume the record .\n}</code></pre>\n<p>如果我们将代码清单 中第①行 poll （）方法的参数设置为 ，即这 行替换为<br><code>consumer poll(Duration.ofMillis(0)) ;</code></p>\n<p>此之后， 会发现 seek（） 方法并未有任何作用。因为当 poll （）方法中 参数为0时，此方法立刻返回，那么 poll （） 方法内部进行分区分配的逻辑就会来不及实施。</p>\n<p>如果对未分配到的分区执行 seek（） 方法 那么会报出IllegalStateException 的异常。类似在调用 subscrib （） 方法之后直接调用 seek（） 方法</p>\n<pre><code class=\"java\">consumer.subscribe(Arrays.asList(topic)) ; \nconsumer.seek(new TopicPartition(topic, 0), 10 );</code></pre>\n<p>会报出如下的异常<br>java.lang.I llegalStateException: No current assignment for partition topic- demo - 0</p>\n<p>seek的几个方法定义</p>\n<pre><code class=\"java\">public Map&lt;Top cPartition Long&gt; endOffsets( Collection&lt;TopicPartition&gt; partitions) \npublic Map&lt;TopicPartition , Long&gt; endOffsets( Collection&lt;Top cPartit on&gt; part tions\nDuration timeout)\n\npublic Map&lt;TopicPartition , Long&gt; beginningOff sets (Collection&lt;TopicPartition&gt; partitions) \npublic Map&lt;TopicPart tion Long&gt; beginningOffsets(Collection&lt;TopicPartition&gt; partitions, \nDuration timeout)\n\npublic void seekToBeginning(Collection&lt;TopicPartition&gt; partitions) \npublic void seekToEnd Collection&lt;TopicPartition&gt; partitions)\n\npublic Map&lt;TopicPartition , OffsetAndTimestamp&gt; offsetsForTimes(Map&lt;TopicPartition, Long&gt; timestampsToSearch) \npublic Map&lt;TopicPartition OffsetAndTimestamp&gt; offsetsForTimes(Map&lt;TopicPartition, Long&gt; t imestampsToSearch,Duration timeout )</code></pre>\n<h3 id=\"再均衡\"><a href=\"#再均衡\" class=\"headerlink\" title=\"再均衡\"></a>再均衡</h3><p>再均衡是指分区的所属权从一个消费者转移到另一消费者的行为。在再均衡发生期间，消费组内的消费者是无法读取消息的。 就是说，在再均衡发生期间的这一小段时内，消费组会变得不可用 。</p>\n<p>比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作 之后这个分区又被分配给了消费组 的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。</p>\n<p>再均衡监听器</p>\n<pre><code class=\"java\">void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions)\nvoid onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions)</code></pre>\n<pre><code class=\"java\">Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets =new HashMap&lt;&gt;() ; \nconsumer.subscribe(Arrays.asList(topic) , new ConsumerRebalanceListener () { \n@Override \npublic void onPartitionsRevoked(Collection&lt;TopicPartition&gt; part tions) { \nconsumer.commitSync(currentOffsets) ; \ncurrentOffsets.clear(); \n@Override\npublic void onPartitionsAssigned(Collection&lt;TopicPartition partitions) { \n//do nothing . \n}) .,</code></pre>\n<h3 id=\"消费者拦截器\"><a href=\"#消费者拦截器\" class=\"headerlink\" title=\"消费者拦截器\"></a>消费者拦截器</h3><p>消费者拦截器需要自定义实现 org.apache.kafka.clients.consumer.Consumerlnterceptor 接口。</p>\n<pre><code class=\"java\">public ConsumerRecords&lt;K, V&gt; onConsume(ConsumerRecords&lt;K , V&gt; records);\npublic void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets);\npublic void close();</code></pre>\n<p>Kafkaconsumer 会在 poll （）方法返回之前调用拦截器的 Consume（） 方法来对消息进行相应<br>的定制 操作，KafkaConsumer 会在提交完消费位移之后调用拦截器的 onCommit（） 方法</p>\n<p>在消费者中也有拦截链的概念，和生产者的拦截链一样， 也是按照工interceptor classes参数配置的拦截器的顺序来一一执行的（配置的时候，各个拦截器之间使用逗号隔开）。同样也要提防“副作用”的发生 如果在拦截链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。</p>\n<h3 id=\"多线程实现\"><a href=\"#多线程实现\" class=\"headerlink\" title=\"多线程实现\"></a>多线程实现</h3><p>KatkaProducer 是线程安全的，然而 KafkaConsumer 却是非线程安全 KafkaConsumer定义了 acquire （） 方法，用来检测当前是否只有 个线程在操作，若有其他线程正在操作则会抛出 ConcurrentModifcationException 异常</p>\n<pre><code class=\"java\">private final AtomicLong currentThread = new Atom cLong(NO CURRENT THREAD ); //Kaf aConsumer 中的成员变量\n\nprivate void acquire() { \nlong threadid = Thread.currentThread().getid();\nif (threadid != currentThread.get() &amp;&amp; !currentThread.compareAndSet(NO_CURRENT THREAD, threadid) ) \nthrow new ConcurrentModificationException \n(&quot;KafkaConsumer is not safe for multi- threaded access &quot;) ; \nrefcount.incrementAndGet();\n}</code></pre>\n<p>acquire（）方法和 release （）方法成对出现，表示相应的加锁和解锁操作。</p>\n<pre><code class=\"java\">private void release() \nif (refcount.decrementAndGet () == 0) {\n    currentThread.set(NO CURRENT THREAD);\n}</code></pre>\n<p>多线程的目的就是为了提高整体的消费能力。多线程的实现方式有多种，第一种也是最常见的方式 线程封闭，即为每个线程实例化一个 KafkaConsumer 对象。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030190716.png\" alt></p>\n<p>一个消费线程可消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数，当消费线程的个数大于分区数时 就有部分消费线程一直处于空闲的状态。</p>\n<p>多个消费线程同时消费同一个分区 ，这个通过 assign（）、 seek （）等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力 。不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，</p>\n<pre><code class=\"java\">public static void main(String[] args) { \n    Properties props = itConfig (); \n    int consumerThreadNum = 4 ; \n    for(int i=O;i&lt;consumerThreadNum;i++) { \n    new KafkaConsumerThread(props,topic).start();\n    }\n}\n\npublic static class KafkaConsumerThread extends Thread{\n    private KafkaConsumer&lt;String , String&gt; kafkaConsumer;\n    public KafkaConsumerThread(Properties props, String topic) { \n    this.kafkaConsumer =new KafkaConsumer&lt;&gt;(props); \n    this.kafkaConsumer.subscribe(Arrays asList(topic));\n}\n\n    @Override \n    public void run() {\n    try { \n        while (true) { \n        ConsumerRecords&lt;String, String&gt; records = \n        kafkaConsumer.poll (Duration.ofMill (1 00)) ; \n        for (ConsumerRecord&lt;String, Stri g&gt; record : records) { \n        // 处理消息模块 ① \n        }\n    }\n    } catch (Exception e) { \n        e.printStackTrace(); \n    } finally { \n        kafkaConsumer.close();\n    }\n    }</code></pre>\n<p>上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别， 优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的TCP 连接 如果分区数和 consumerThreadNum 的值都很大，那么会造成不 的系统开销。</p>\n<p>这里的处理速度取决于处理消息模块，。一般 言， poll（）拉取消息的速度是相当快的 ，而整体消费的瓶颈是在处理消息这一块， 通过－定的方式来改进这一部分，那么就能带动整体消费性能提升。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030193459.png\" alt></p>\n<pre><code class=\"java\">    @Override \n    public void run() {\n    try { \n        while (true) { \n        ConsumerRecords&lt;String, String&gt; records = \n        kafkaConsumer.poll(Duration.ofMill (1 00)) ; \n        if (!records.isEmpty () ) { \n            executorService.submit(new RecordsHandler(records));  // 调用各个hander处理消息\n        }\n    }\n    } catch (Exception e) { \n        e.printStackTrace(); \n    } finally { \n        kafkaConsumer.close();\n    }\n    }\n\n    public static class RecordsHandler extends Thread{ \n    public final ConsumerRecords&lt;String, String&gt; records;\n\n    public RecordsHandl er (ConsumerRecords&lt;String, String&gt; records) ( \n        this.records =records;\n    }\n\n    @Override \n    public void run() {\n        // 处理records\n    }\n    }\n</code></pre>\n<p>RecordHandler 类是用来处理消息的，而 KafraConsumerThread 类对应的是一个消费线程，里面通过线程池的方式来调用 RecordHandler 处理一批批的消息。</p>\n<p>引入一个共享<br>变量 offsets 来参与提交</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030200350.png\" alt></p>\n<p>每一个处理消息的 RecordHandler 类在处理完消息之后都将对应的消费位移保存到共享变量offsets 中， KafraConsumerThread 在每一次 poll （）方法之后都读取 offsets 中的内容并对其进行位移提交。</p>\n<pre><code class=\"java\">for (TopicPartition tp : records .partitions()) { \n    List&lt;ConsumerRecord&lt;String , String&gt; tpRecords = records . records(tp); \n    // 处 tpRec ords\n    long lastConsumedOffset = tpRecords . get (tpRecords. size() - 1) . offset() ; \n    synchronized (offsets) { \n        if offsets.co ta 工口 sKey (tp)) { \n            offsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + l)) ; \n        } else { \n            long position = offsets . get(tp) .offset() ; \n            if (position &lt; lastConsumedOffset + 1) { \n            offsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + l))\n            }\n        }\n    }\n}</code></pre>\n<pre><code class=\"java\">synchronized (offsets) { \nif (!offsets. isEmpty () ) { \n    kafkaConsumer.commitSync(offsets); \n    offsets.clear();\n    }\n}</code></pre>\n<p>假设一个处理线程 RecordHand erl 正在处理 offset 99消息，而另一个处理线程 RecordHand er2 己经处理完了 offset 100 99 的消息并进行了位移提交，此时如果 RecordHandler 发生异常，则之后的消费只能从 200 开始而无法再次消费 99的消息，从而造成了消息丢失的现象。这里虽然针对位移覆盖做了一定的处理，但还没有解决异常情况下的位移覆盖问题。</p>\n<p>通过消费者拉取分批次的消息，然后提交给多线程进行处理，而这里的滑动窗口式的实现方式是将拉取到的消息暂存起来， 多个消费线程可以拉取暂存的消息，这个用于暂存消息的缓存大小即为滑动窗口的大小， 总体上而言没有太多的变化 不同的是对于消费位移的把控。</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030201350.png\" alt></p>\n<p>startOffset标注的是当前滑动 口的起始位置 endOffset 注的是末尾位置。每当 startOffset 指向的方格中的消息被消 费完成，就可以提交这部分的位移，与此同时，窗 口向 前滑动一格， 除原来startOffset 所指方格中对应的消息 并且拉取新的消息进入窗口。</p>\n<p>滑动窗口的大小固定，所对应的用来暂 消息的缓存大小也就固定了，这部分内存开销可控。方格大小和滑动窗口的大小同决定了消费线程的并发数。</p>\n<p>如果 个方格内的消 息无法被标记为消费完成，那么就会造成 startOffset 悬停。为了使窗口能够继续向前滑动 那么就需要设定 个闹值，当 startOffset 悬停一定的时间后就对这部分消息进行本地重试消费，如果重试失败就转入重试队列，如果还不奏效就转入死信队列。</p>\n<h3 id=\"重要的消费者参数\"><a href=\"#重要的消费者参数\" class=\"headerlink\" title=\"重要的消费者参数\"></a>重要的消费者参数</h3><p><code>fetch.min.bytes</code>：Consumer 在一次拉取请求（调用 poll （） 方法）中能从 Kafka 中拉取的最小<br>数据量，默认值为 1B。</p>\n<p><code>fetch .max.bytes</code>：配置 Consumer 在一次拉取请求中从 Kafka中拉取的最大数据 ，默认值为 52428800 ，也就是 50MB</p>\n<p><code>fetch.max.wait.ms</code>：于指定 Kafka 的等待时间，默认值为 500ms</p>\n<p><code>max.partition.fetch.bytes</code>：配置从每个分区里返回给 Consumer的最大数据 ，默认值为 1048576 (B)</p>\n<p><code>max.poll.records</code>：配置 Consumer 次拉取请求中拉取的最大消息数，默认值为 500 （条）</p>\n<p><code>connections.max.idle.ms</code>：指定在多久之后关闭限制的连接，默认值是 540000 (ms ），即 分钟。</p>\n<p><code>exclude.internal.topics</code>：Kafka 中有两个内部的主题：_consumer_offsets 和 _transaction_state。 exclude.internal.topics用来指定 Kafka 中的内部主题是否可以向消费者公开，默认值为 true 。</p>\n<p><code>receive.buffer.bytes</code>：这个参数用来设置 Socket 接收消息缓冲区的大小，默认值为 65536 (B)</p>\n<p><code>send.buffer.bytes</code>：设置 Socket 发送消息缓冲区的大小，默认13 1072 (B)</p>\n<p><code>request.timeout.ms</code>：来配置 Consumer 等待请求响应的最长时间，默认值为 30000ms</p>\n<p><code>metadata.max.age.ms</code>：用来配置元数据的过期时间，默认值为 300000 ms</p>\n<p><code>reconnect.backoff.ms</code>：配置尝试重新连接指定主机之前的等待时间，默认值为50ms</p>\n<p><code>retry.backo ms</code>：配置尝试重新发送失败的请求到指定的主题分区之前的等待（退避〉时间，</p>\n<p><code>isolation.level</code>：配置消费者的事务隔离级别。有效值为“read uncommitted ，，和<br>“ read committed ＂</p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030202942.png\" alt></p>\n<p><img src=\"/2022/10/16/kafka-producer-consumer/img-20221030202957.png\" alt></p>\n"},{"title":"kafka - 主题与分区","img":"/medias/files/kafka-topic-partition.jpg","summary":"主题和分区是 Kafka 的两个核心概念","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-10-30T13:00:34.000Z","password":null,"_content":"\n分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。\n\n# 主题的管理\n\n主题的管理包括创建主题、 查看主题信息、修改主题和删除主题等操作。\n\n## 创建主题\n\n如果 broker 端配置参数 auto.create.topics.enable 设置 true （默认值就是 true) , 那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数为 num.partitions（默认值为1 ）、副本因子为 default.replication.factor （默认值为1 ）的主题。\n\n例：\n```\nbin/kafka-top cs .sh - zookeeper localhost: 2181/kafka \n--create --topic top create --partitions 4 --replication-factor 2\n```\n\n在执行完脚本之后， Kafka 会在 log.dir log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为／tmp/kafka-logs／\n![](kafka-topic-and-partition/img-20221030211533.png)\n\n\ntopic-create-0 topic-create-1对应了主题的两个分区，其余两个分区被创建到了别的节点\n![](kafka-topic-and-partition/img-20221030211753.png)\n\n主题、分区、副本和 Log （日志）的关系如下\n![](kafka-topic-and-partition/img-20221030211824.png)\n\n我们不仅可以通过日志文件的根目录来查看集群中各个 broker 的分区副本的分配情况，还可以通过 ZooKeeper 客户端来获取。\n当创建一个主题时会在 zooKeeper 的／ brokers/topics/ 目录下创建一个同名的实节点，该节点记录了该主题的分区副本分配方案。\n![](kafka-topic-and-partition/img-20221030212257.png)\n\n示例数据中的 \"2\"：[1, 2] 表示分区2 分配了2个副本，分别在 brokerld 1和 brokerId 2节点中。\n\nkafka topics脚本中还提供了 replica-assignment 参数来手动指定分区副本的分配方案。\nreplica assignment 参数的用法归纳如下：\n`-- replica-assignment <String : broker_id_ for_part1_replica1: broker_id for \npartl_replica2 , broker_id _for_part2_replica1: broker_ id_ for _part2_replica2 , ... >`\n这种方式根据分区号的数值大小按照从小到大的顺序进行排列 分区与分区 逗号 “，”\n隔开，分区内多个副本用冒号“：”隔开\n\n创建主题时不能存在同名的主题，如果指定参数`if-not-exists`则在冲突时不做处理。\n内部主题一般以双下划线开头'__'\n\n## 分区副本的分配\n\n分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个 broker 中创建哪些分区的副本。\n\n在创建主题时，如果使用了 replica assignment 参数，那么就按照指定的方案来进分区副本的创建；如果没有使用 replica-assignment 参数，那么就需要按照内部的逻辑来计算分配方案了\n\n使用 kafka-topics.sh 脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略 朱指定机架信息和指定机架信息 如果集群中所有的 brok 节点都没有配置broker.rack 参数，或者使用 disable-rack aware 参数来 建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。\n\n```java\nprivate def assignRepl casToBrokersRackUnaware(\n  nPartit ons: Int , ／／分区数\n  replicat on Factor: Int , ／／副本 因子\n  brokerList : “ q[Int] , ／／；集群中 broker 列表\n  fixedStartindex: Int , ／／起始索 引，即 一个副本分自己的位置，默认值为\n  startPartitionid: Int): ／／起始分 编号，默认值为\n  Map[Int, Seq[Int]] = { \n    val ret = mutable.Map[Int, Seg[Int]] () ／／保存分自己结果的集合\n    val brokerArray = brokerList.toArray //brokerid 的列表\n    ／／如果起始索 fixedStartindex 小于0 ，则根据 broker 列表长度随机生成一个，以此来保证是\n    ／／；有效的 broker Id \n    val startIndex = if (fixedStartindex >= 0) fixedStartindex \n      else rand.nextint(brokerArray.length) \n    ／／确保起始分区号不小于0\n    var currentPartitionId = math.max(O , startPartitionid)\n    ／／指定了副本的间隔，目的是为了更均匀地将副本分配到不同的 broker\n    var nextReplicaShift = if xedStartindex >= 0) fixedStartindex\n      else rand.nextint(brokerArray.length) \n    ／／轮询所有分区， 将每个分区的副本分配到不同的 broker\n    for (_ <- 0 until nPartitions) ( \n      if (currentPartitionid > 0 && (currentPartitonId % brokerArray. length == 0) ) \n      nextReplicaShift += 1 \n      val firstReplicaindex = (currentPartitionid + startindex ）% brokerArray.length\n      val replicaBuffer = mutable . ArrayBuffer(brokerArray(firstReplicaindex)) \n      ／／保存该分区所有副本分自己的 br oker集合\n      for (j <- 0 until replicatFactor - 1) \n        replicaBuffer += brokerArray ( \n        replicaIndex(firstReplicaIndex ，nextReplicaShift\n        j, brokerArray.length)) ／／ 为其余的副本分配 broker\n        ／／保存该分区所有副本的分配信息\n        ret.put(currentPartitionid, replicaBuffer) \n        ／／继续为 下一个分区分配副本\n        currentPartitionid += 1\n      }\n    ret\n    }\n```\n\n\n## 查看主题\n\nkafka-topics. 脚本有4种指令类型： create list describe alter\n其中list describe 指令可用来方便地查看主题信息\n\n增加 topics-with-overrides 参数可以找 所有 含覆盖配置 主题 它只会列出包含了与集群不一样配置的主题\n\nunder-replicated-partitions 和 unavai able-partitions 参数可以找出有问题的分区。\n\n## 修改主题\n\n当一个主题被创建之后 依然允许对其做一定的修改，比如修改分区个数、修改配置。这是由alert指令提供的\n\n增加主题的分区数目后，当主题中的消息包含 key 时（即 key 不为 null 根据 key计算分区的行为就会受到影响。\n\n## 配置管理\n\nkafka-configs 脚本是专门用来对配置进行操作的，这里的操作是指在运行状态下修改原有的配置，如此可以达到动态变更的目的。\n\nkafka configs.sh 脚本不仅可以支持操作主题相关的配置，还支持操作broker 、用户和客户端这三个类型 配置。\n\n## 主题端参数\n\n与主题相关的所有配置参数在 broker 层面都有对应参数， \n比如主题端参数 cleanup.policy 对应 broker 层面的 log.cleanup policy\n\n![](kafka-topic-and-partition/img-20221106222237.png)\n\n![](kafka-topic-and-partition/img-20221106222301.png)\n\n![](kafka-topic-and-partition/img-20221106222336.png)\n\n![](kafka-topic-and-partition/img-20221106222348.png)\n\n## 删除主题\n\nkafka-topics.sh 脚本中的 delete 令就可以用来删除主题\n\n\n使用 kafka_topics.sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的 /admin/delete_topics 路径下 建一个与待删除主题同名的节点，以 标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由 Kafka 的控制器负责完成的。\n\n![](kafka-topic-and-partition/img-20221106222536.png)\n\n![](kafka-topic-and-partition/img-20221106222544.png)\n\n# 初识 KafkaAdminClient\n\n## 基本使用\n\n和脚本类似，可以使用Topicommand类创建主题等。\n\n- 创建主题 CreateTopicsResult createTopics(Collection<NewTopic> newTopics)\n- 删除主题 DeleteTopicsResult deleteTopics(Collection<String> topics)\n- 列出所有可用的主题： ListTopicsResult listTopics()\n- 查看主题的信息： DescribeTopicsResult describeTopics(Collection<String> topicNames)\n- 查询配置信息 escribeConfigsResult describeConfigs(Collection<ConfigResource> resources)\n- 修改配置信息： AlterConfigsResult alterConfigs(Map<ConfigResource, Config> configs)\n- 增加分区 CreatePartitionsResult createPartitions(Map<String, NewPartitions> new Partitions)\n\n## 主题合法性验证\n\nKafka broker 端有－个这样的参数 create.topic.policy.class.name，默认值为null\n它提供了一个入口用来验证主题创建的合法性。使用方式很简单，只需要自定义实现org.apache.kafka.server.policy.CreateTopicPolicy 接口\n\n例：\n![](kafka-topic-and-partition/img-20221106223639.png)\n\n# 分区的管理\n\n## 优先副本的选举\n分区使用多副本机制来提升可靠性，但只有 leader 副本对外提供读写服务，而 follower本只负责在内部进行消息的同步。\n\n优先副本选举是指通过一定的方法促使副本选举为 leader ，以此来促进集群负载均衡 行为 可以称为“分区平衡”\n\nKafka 中可以提供分区自动平衡的功能，与此对应的 broker 端参数是 auto.leader.rebalance.enable ，此参数的默认值为 true。Kafka 的控制器会启动一个定时任务，默认5分钟执行一次，这个定时任务会轮询所有的 broker节点，计算每个 broker 节点的分区不平衡率是否超过默认值10%\n\nkafka-perferred-replica election.sh 脚本提供了对分区 leader 副本进行重新平衡的功能。\n\n## 分区重分配\n\n当集群中的一个节点突然若机下线时，如果节点上的分区是单副本的，那么这些分区就变得不可用了，在节点恢复前，相应的数据也就处于丢失状态；如果节点上的分区是多副本的，那么位于这个节点上的 leader 副本的角色会转交到集群的其他 follower 副本 。\n\n当集群中新增 roker 节点时，只有新创建的主题分区才有可能被分配到这个节点上，而之前的主题分区并不会自动分配到新加入的节点中，因为在它们被创建时还没有这个新节点，这样新节点的负载和原先节点的负载之间严重不均衡。\n\nKafka提供了 kafka-reassin-partitions.sh 脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。\n\n\n\n## 复制限流\n\n分区重分配本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终的目的。\n\n副本间的复制限流有两种实现方式： kafka-config.sh 脚本和 kafka-reassign-partitions.sh脚本\n\n- kafka-config.sh脚本主要 以动态配置的方式来达到限流的目的，在 broker 级别有两个与复制限流相关的配置参数 follower.replication.throttled.rate 和 leader.replication.throttled.rate ，前者用于设置 follower 副本复制的速度，后者用于设置 leader 副本传输的速度，它们的单位都是B/s 。\n\n- kafka reassign-partitions.sh 脚本本身也提供了限流的功能，只需一个 throttle 参数即可，\n\n\n## 修改副本因子\n\n修改副本因子的功能也是通过重分配所使用的 kafka-reassign-partition.sh 脚本实现的\n\n# 如何选择合适的分区数\n\n## 性能测试工具\n\nKafka 本身提供的用于生产者性能测试 kafka-producer-perf-test.sh 和用于消费者性能测试的kafka-consumer-perf-test.sh\n\n##  分区数越多吞吐量就越高吗\n\n对生产者而言，每一个分区的数据写入是完全可以并行\n对消费者而言， Kafka 只允许单个分区中的消息被一个消费者线程消费， 一个消费组的消费并行度完全依赖于所消费的分区数\n\n消息中间件的性能 般是指吞吐量（广义来说还包括延迟）。抛开硬件资源的影响，消息\n写入的吞吐量还会受到消息大小、消息压缩方式、消息发送方式（同步 异步）、消息确认类型\nacks、副本因子等参数影 响， 消息消费 吞吐量还会受到应用逻辑、处理速度的影响\n\n![](kafka-topic-and-partition/img-20221106230140.png)\n分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量跟着上涨。一旦分区数超过了某个阔值之后，整体的吞吐量是不升反降的。\n\n![](kafka-topic-and-partition/img-20221106230222.png)\n随着分区数的增加，相应的吞吐量也会有所增长。一旦分区数超过了某个阈值之后，整体的吞吐量也是不升反降的\n\n## 分区数的上限\n\n一味的增加分区数并不能使吞吐量一直得到提升，并且分区数也并不能一直增加，如果超默认配置值，还会引起 Kafka 进程的崩溃\n\n创建过多分区会有异常，最关键的信息是“Too many open flies ”，这是一种常见的 Linux 系统错误，通常意文件描述符不足，它一般发生在创建线程、创建 Socket 、打开文件这些场景下 Linux系统的默认设置下，这个 件描述符的个数不是很 ，通过 ulimit 命令可以查看。\n\nulimit 是在系统允许的情况下，提供对特定 shell 可利用的资源的控制。-H和-S选项指定资源的硬限制和软限制\n\n## 考量因素\n\n从吞吐方面考虑，增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求 则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。","source":"_posts/kafka-topic-and-partition.md","raw":"---\ntitle: kafka - 主题与分区\nimg: /medias/files/kafka-topic-partition.jpg\nsummary: 主题和分区是 Kafka 的两个核心概念\ntags:\n  - 博客\n  - Kafka\ncategories:\n  - 随笔\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-10-30 21:00:34\npassword:\n---\n\n分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。\n\n# 主题的管理\n\n主题的管理包括创建主题、 查看主题信息、修改主题和删除主题等操作。\n\n## 创建主题\n\n如果 broker 端配置参数 auto.create.topics.enable 设置 true （默认值就是 true) , 那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数为 num.partitions（默认值为1 ）、副本因子为 default.replication.factor （默认值为1 ）的主题。\n\n例：\n```\nbin/kafka-top cs .sh - zookeeper localhost: 2181/kafka \n--create --topic top create --partitions 4 --replication-factor 2\n```\n\n在执行完脚本之后， Kafka 会在 log.dir log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为／tmp/kafka-logs／\n![](kafka-topic-and-partition/img-20221030211533.png)\n\n\ntopic-create-0 topic-create-1对应了主题的两个分区，其余两个分区被创建到了别的节点\n![](kafka-topic-and-partition/img-20221030211753.png)\n\n主题、分区、副本和 Log （日志）的关系如下\n![](kafka-topic-and-partition/img-20221030211824.png)\n\n我们不仅可以通过日志文件的根目录来查看集群中各个 broker 的分区副本的分配情况，还可以通过 ZooKeeper 客户端来获取。\n当创建一个主题时会在 zooKeeper 的／ brokers/topics/ 目录下创建一个同名的实节点，该节点记录了该主题的分区副本分配方案。\n![](kafka-topic-and-partition/img-20221030212257.png)\n\n示例数据中的 \"2\"：[1, 2] 表示分区2 分配了2个副本，分别在 brokerld 1和 brokerId 2节点中。\n\nkafka topics脚本中还提供了 replica-assignment 参数来手动指定分区副本的分配方案。\nreplica assignment 参数的用法归纳如下：\n`-- replica-assignment <String : broker_id_ for_part1_replica1: broker_id for \npartl_replica2 , broker_id _for_part2_replica1: broker_ id_ for _part2_replica2 , ... >`\n这种方式根据分区号的数值大小按照从小到大的顺序进行排列 分区与分区 逗号 “，”\n隔开，分区内多个副本用冒号“：”隔开\n\n创建主题时不能存在同名的主题，如果指定参数`if-not-exists`则在冲突时不做处理。\n内部主题一般以双下划线开头'__'\n\n## 分区副本的分配\n\n分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个 broker 中创建哪些分区的副本。\n\n在创建主题时，如果使用了 replica assignment 参数，那么就按照指定的方案来进分区副本的创建；如果没有使用 replica-assignment 参数，那么就需要按照内部的逻辑来计算分配方案了\n\n使用 kafka-topics.sh 脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略 朱指定机架信息和指定机架信息 如果集群中所有的 brok 节点都没有配置broker.rack 参数，或者使用 disable-rack aware 参数来 建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。\n\n```java\nprivate def assignRepl casToBrokersRackUnaware(\n  nPartit ons: Int , ／／分区数\n  replicat on Factor: Int , ／／副本 因子\n  brokerList : “ q[Int] , ／／；集群中 broker 列表\n  fixedStartindex: Int , ／／起始索 引，即 一个副本分自己的位置，默认值为\n  startPartitionid: Int): ／／起始分 编号，默认值为\n  Map[Int, Seq[Int]] = { \n    val ret = mutable.Map[Int, Seg[Int]] () ／／保存分自己结果的集合\n    val brokerArray = brokerList.toArray //brokerid 的列表\n    ／／如果起始索 fixedStartindex 小于0 ，则根据 broker 列表长度随机生成一个，以此来保证是\n    ／／；有效的 broker Id \n    val startIndex = if (fixedStartindex >= 0) fixedStartindex \n      else rand.nextint(brokerArray.length) \n    ／／确保起始分区号不小于0\n    var currentPartitionId = math.max(O , startPartitionid)\n    ／／指定了副本的间隔，目的是为了更均匀地将副本分配到不同的 broker\n    var nextReplicaShift = if xedStartindex >= 0) fixedStartindex\n      else rand.nextint(brokerArray.length) \n    ／／轮询所有分区， 将每个分区的副本分配到不同的 broker\n    for (_ <- 0 until nPartitions) ( \n      if (currentPartitionid > 0 && (currentPartitonId % brokerArray. length == 0) ) \n      nextReplicaShift += 1 \n      val firstReplicaindex = (currentPartitionid + startindex ）% brokerArray.length\n      val replicaBuffer = mutable . ArrayBuffer(brokerArray(firstReplicaindex)) \n      ／／保存该分区所有副本分自己的 br oker集合\n      for (j <- 0 until replicatFactor - 1) \n        replicaBuffer += brokerArray ( \n        replicaIndex(firstReplicaIndex ，nextReplicaShift\n        j, brokerArray.length)) ／／ 为其余的副本分配 broker\n        ／／保存该分区所有副本的分配信息\n        ret.put(currentPartitionid, replicaBuffer) \n        ／／继续为 下一个分区分配副本\n        currentPartitionid += 1\n      }\n    ret\n    }\n```\n\n\n## 查看主题\n\nkafka-topics. 脚本有4种指令类型： create list describe alter\n其中list describe 指令可用来方便地查看主题信息\n\n增加 topics-with-overrides 参数可以找 所有 含覆盖配置 主题 它只会列出包含了与集群不一样配置的主题\n\nunder-replicated-partitions 和 unavai able-partitions 参数可以找出有问题的分区。\n\n## 修改主题\n\n当一个主题被创建之后 依然允许对其做一定的修改，比如修改分区个数、修改配置。这是由alert指令提供的\n\n增加主题的分区数目后，当主题中的消息包含 key 时（即 key 不为 null 根据 key计算分区的行为就会受到影响。\n\n## 配置管理\n\nkafka-configs 脚本是专门用来对配置进行操作的，这里的操作是指在运行状态下修改原有的配置，如此可以达到动态变更的目的。\n\nkafka configs.sh 脚本不仅可以支持操作主题相关的配置，还支持操作broker 、用户和客户端这三个类型 配置。\n\n## 主题端参数\n\n与主题相关的所有配置参数在 broker 层面都有对应参数， \n比如主题端参数 cleanup.policy 对应 broker 层面的 log.cleanup policy\n\n![](kafka-topic-and-partition/img-20221106222237.png)\n\n![](kafka-topic-and-partition/img-20221106222301.png)\n\n![](kafka-topic-and-partition/img-20221106222336.png)\n\n![](kafka-topic-and-partition/img-20221106222348.png)\n\n## 删除主题\n\nkafka-topics.sh 脚本中的 delete 令就可以用来删除主题\n\n\n使用 kafka_topics.sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的 /admin/delete_topics 路径下 建一个与待删除主题同名的节点，以 标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由 Kafka 的控制器负责完成的。\n\n![](kafka-topic-and-partition/img-20221106222536.png)\n\n![](kafka-topic-and-partition/img-20221106222544.png)\n\n# 初识 KafkaAdminClient\n\n## 基本使用\n\n和脚本类似，可以使用Topicommand类创建主题等。\n\n- 创建主题 CreateTopicsResult createTopics(Collection<NewTopic> newTopics)\n- 删除主题 DeleteTopicsResult deleteTopics(Collection<String> topics)\n- 列出所有可用的主题： ListTopicsResult listTopics()\n- 查看主题的信息： DescribeTopicsResult describeTopics(Collection<String> topicNames)\n- 查询配置信息 escribeConfigsResult describeConfigs(Collection<ConfigResource> resources)\n- 修改配置信息： AlterConfigsResult alterConfigs(Map<ConfigResource, Config> configs)\n- 增加分区 CreatePartitionsResult createPartitions(Map<String, NewPartitions> new Partitions)\n\n## 主题合法性验证\n\nKafka broker 端有－个这样的参数 create.topic.policy.class.name，默认值为null\n它提供了一个入口用来验证主题创建的合法性。使用方式很简单，只需要自定义实现org.apache.kafka.server.policy.CreateTopicPolicy 接口\n\n例：\n![](kafka-topic-and-partition/img-20221106223639.png)\n\n# 分区的管理\n\n## 优先副本的选举\n分区使用多副本机制来提升可靠性，但只有 leader 副本对外提供读写服务，而 follower本只负责在内部进行消息的同步。\n\n优先副本选举是指通过一定的方法促使副本选举为 leader ，以此来促进集群负载均衡 行为 可以称为“分区平衡”\n\nKafka 中可以提供分区自动平衡的功能，与此对应的 broker 端参数是 auto.leader.rebalance.enable ，此参数的默认值为 true。Kafka 的控制器会启动一个定时任务，默认5分钟执行一次，这个定时任务会轮询所有的 broker节点，计算每个 broker 节点的分区不平衡率是否超过默认值10%\n\nkafka-perferred-replica election.sh 脚本提供了对分区 leader 副本进行重新平衡的功能。\n\n## 分区重分配\n\n当集群中的一个节点突然若机下线时，如果节点上的分区是单副本的，那么这些分区就变得不可用了，在节点恢复前，相应的数据也就处于丢失状态；如果节点上的分区是多副本的，那么位于这个节点上的 leader 副本的角色会转交到集群的其他 follower 副本 。\n\n当集群中新增 roker 节点时，只有新创建的主题分区才有可能被分配到这个节点上，而之前的主题分区并不会自动分配到新加入的节点中，因为在它们被创建时还没有这个新节点，这样新节点的负载和原先节点的负载之间严重不均衡。\n\nKafka提供了 kafka-reassin-partitions.sh 脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。\n\n\n\n## 复制限流\n\n分区重分配本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终的目的。\n\n副本间的复制限流有两种实现方式： kafka-config.sh 脚本和 kafka-reassign-partitions.sh脚本\n\n- kafka-config.sh脚本主要 以动态配置的方式来达到限流的目的，在 broker 级别有两个与复制限流相关的配置参数 follower.replication.throttled.rate 和 leader.replication.throttled.rate ，前者用于设置 follower 副本复制的速度，后者用于设置 leader 副本传输的速度，它们的单位都是B/s 。\n\n- kafka reassign-partitions.sh 脚本本身也提供了限流的功能，只需一个 throttle 参数即可，\n\n\n## 修改副本因子\n\n修改副本因子的功能也是通过重分配所使用的 kafka-reassign-partition.sh 脚本实现的\n\n# 如何选择合适的分区数\n\n## 性能测试工具\n\nKafka 本身提供的用于生产者性能测试 kafka-producer-perf-test.sh 和用于消费者性能测试的kafka-consumer-perf-test.sh\n\n##  分区数越多吞吐量就越高吗\n\n对生产者而言，每一个分区的数据写入是完全可以并行\n对消费者而言， Kafka 只允许单个分区中的消息被一个消费者线程消费， 一个消费组的消费并行度完全依赖于所消费的分区数\n\n消息中间件的性能 般是指吞吐量（广义来说还包括延迟）。抛开硬件资源的影响，消息\n写入的吞吐量还会受到消息大小、消息压缩方式、消息发送方式（同步 异步）、消息确认类型\nacks、副本因子等参数影 响， 消息消费 吞吐量还会受到应用逻辑、处理速度的影响\n\n![](kafka-topic-and-partition/img-20221106230140.png)\n分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量跟着上涨。一旦分区数超过了某个阔值之后，整体的吞吐量是不升反降的。\n\n![](kafka-topic-and-partition/img-20221106230222.png)\n随着分区数的增加，相应的吞吐量也会有所增长。一旦分区数超过了某个阈值之后，整体的吞吐量也是不升反降的\n\n## 分区数的上限\n\n一味的增加分区数并不能使吞吐量一直得到提升，并且分区数也并不能一直增加，如果超默认配置值，还会引起 Kafka 进程的崩溃\n\n创建过多分区会有异常，最关键的信息是“Too many open flies ”，这是一种常见的 Linux 系统错误，通常意文件描述符不足，它一般发生在创建线程、创建 Socket 、打开文件这些场景下 Linux系统的默认设置下，这个 件描述符的个数不是很 ，通过 ulimit 命令可以查看。\n\nulimit 是在系统允许的情况下，提供对特定 shell 可利用的资源的控制。-H和-S选项指定资源的硬限制和软限制\n\n## 考量因素\n\n从吞吐方面考虑，增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求 则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。","slug":"kafka-topic-and-partition","published":1,"updated":"2022-11-27T07:25:03.759Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9x000fagvtqfxgev52","content":"<p>分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。</p>\n<h1 id=\"主题的管理\"><a href=\"#主题的管理\" class=\"headerlink\" title=\"主题的管理\"></a>主题的管理</h1><p>主题的管理包括创建主题、 查看主题信息、修改主题和删除主题等操作。</p>\n<h2 id=\"创建主题\"><a href=\"#创建主题\" class=\"headerlink\" title=\"创建主题\"></a>创建主题</h2><p>如果 broker 端配置参数 auto.create.topics.enable 设置 true （默认值就是 true) , 那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数为 num.partitions（默认值为1 ）、副本因子为 default.replication.factor （默认值为1 ）的主题。</p>\n<p>例：</p>\n<pre><code>bin/kafka-top cs .sh - zookeeper localhost: 2181/kafka \n--create --topic top create --partitions 4 --replication-factor 2</code></pre><p>在执行完脚本之后， Kafka 会在 log.dir log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为／tmp/kafka-logs／<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030211533.png\" alt></p>\n<p>topic-create-0 topic-create-1对应了主题的两个分区，其余两个分区被创建到了别的节点<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030211753.png\" alt></p>\n<p>主题、分区、副本和 Log （日志）的关系如下<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030211824.png\" alt></p>\n<p>我们不仅可以通过日志文件的根目录来查看集群中各个 broker 的分区副本的分配情况，还可以通过 ZooKeeper 客户端来获取。<br>当创建一个主题时会在 zooKeeper 的／ brokers/topics/ 目录下创建一个同名的实节点，该节点记录了该主题的分区副本分配方案。<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030212257.png\" alt></p>\n<p>示例数据中的 “2”：[1, 2] 表示分区2 分配了2个副本，分别在 brokerld 1和 brokerId 2节点中。</p>\n<p>kafka topics脚本中还提供了 replica-assignment 参数来手动指定分区副本的分配方案。<br>replica assignment 参数的用法归纳如下：<br><code>-- replica-assignment &lt;String : broker_id_ for_part1_replica1: broker_id for \npartl_replica2 , broker_id _for_part2_replica1: broker_ id_ for _part2_replica2 , ... &gt;</code><br>这种方式根据分区号的数值大小按照从小到大的顺序进行排列 分区与分区 逗号 “，”<br>隔开，分区内多个副本用冒号“：”隔开</p>\n<p>创建主题时不能存在同名的主题，如果指定参数<code>if-not-exists</code>则在冲突时不做处理。<br>内部主题一般以双下划线开头’__’</p>\n<h2 id=\"分区副本的分配\"><a href=\"#分区副本的分配\" class=\"headerlink\" title=\"分区副本的分配\"></a>分区副本的分配</h2><p>分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个 broker 中创建哪些分区的副本。</p>\n<p>在创建主题时，如果使用了 replica assignment 参数，那么就按照指定的方案来进分区副本的创建；如果没有使用 replica-assignment 参数，那么就需要按照内部的逻辑来计算分配方案了</p>\n<p>使用 kafka-topics.sh 脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略 朱指定机架信息和指定机架信息 如果集群中所有的 brok 节点都没有配置broker.rack 参数，或者使用 disable-rack aware 参数来 建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">private</span> def assignRepl <span class=\"token function\">casToBrokersRackUnaware</span><span class=\"token punctuation\">(</span>\n  nPartit ons<span class=\"token operator\">:</span> Int <span class=\"token punctuation\">,</span> ／／分区数\n  replicat on Factor<span class=\"token operator\">:</span> Int <span class=\"token punctuation\">,</span> ／／副本 因子\n  brokerList <span class=\"token operator\">:</span> “ q<span class=\"token punctuation\">[</span>Int<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">,</span> ／／；集群中 broker 列表\n  fixedStartindex<span class=\"token operator\">:</span> Int <span class=\"token punctuation\">,</span> ／／起始索 引，即 一个副本分自己的位置，默认值为\n  startPartitionid<span class=\"token operator\">:</span> Int<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> ／／起始分 编号，默认值为\n  Map<span class=\"token punctuation\">[</span>Int<span class=\"token punctuation\">,</span> Seq<span class=\"token punctuation\">[</span>Int<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span> \n    val ret <span class=\"token operator\">=</span> mutable<span class=\"token punctuation\">.</span>Map<span class=\"token punctuation\">[</span>Int<span class=\"token punctuation\">,</span> Seg<span class=\"token punctuation\">[</span>Int<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> ／／保存分自己结果的集合\n    val brokerArray <span class=\"token operator\">=</span> brokerList<span class=\"token punctuation\">.</span>toArray <span class=\"token comment\" spellcheck=\"true\">//brokerid 的列表</span>\n    ／／如果起始索 fixedStartindex 小于<span class=\"token number\">0</span> ，则根据 broker 列表长度随机生成一个，以此来保证是\n    ／／；有效的 broker Id \n    val startIndex <span class=\"token operator\">=</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>fixedStartindex <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> fixedStartindex \n      <span class=\"token keyword\">else</span> rand<span class=\"token punctuation\">.</span><span class=\"token function\">nextint</span><span class=\"token punctuation\">(</span>brokerArray<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">)</span> \n    ／／确保起始分区号不小于<span class=\"token number\">0</span>\n    var currentPartitionId <span class=\"token operator\">=</span> math<span class=\"token punctuation\">.</span><span class=\"token function\">max</span><span class=\"token punctuation\">(</span>O <span class=\"token punctuation\">,</span> startPartitionid<span class=\"token punctuation\">)</span>\n    ／／指定了副本的间隔，目的是为了更均匀地将副本分配到不同的 broker\n    var nextReplicaShift <span class=\"token operator\">=</span> <span class=\"token keyword\">if</span> xedStartindex <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> fixedStartindex\n      <span class=\"token keyword\">else</span> rand<span class=\"token punctuation\">.</span><span class=\"token function\">nextint</span><span class=\"token punctuation\">(</span>brokerArray<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">)</span> \n    ／／轮询所有分区， 将每个分区的副本分配到不同的 broker\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>_ <span class=\"token operator\">&lt;</span><span class=\"token operator\">-</span> <span class=\"token number\">0</span> until nPartitions<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span> \n      <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>currentPartitionid <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>currentPartitonId <span class=\"token operator\">%</span> brokerArray<span class=\"token punctuation\">.</span> length <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span> \n      nextReplicaShift <span class=\"token operator\">+=</span> <span class=\"token number\">1</span> \n      val firstReplicaindex <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>currentPartitionid <span class=\"token operator\">+</span> startindex ）<span class=\"token operator\">%</span> brokerArray<span class=\"token punctuation\">.</span>length\n      val replicaBuffer <span class=\"token operator\">=</span> mutable <span class=\"token punctuation\">.</span> <span class=\"token function\">ArrayBuffer</span><span class=\"token punctuation\">(</span><span class=\"token function\">brokerArray</span><span class=\"token punctuation\">(</span>firstReplicaindex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> \n      ／／保存该分区所有副本分自己的 br oker集合\n      <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>j <span class=\"token operator\">&lt;</span><span class=\"token operator\">-</span> <span class=\"token number\">0</span> until replicatFactor <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> \n        replicaBuffer <span class=\"token operator\">+=</span> <span class=\"token function\">brokerArray</span> <span class=\"token punctuation\">(</span> \n        <span class=\"token function\">replicaIndex</span><span class=\"token punctuation\">(</span>firstReplicaIndex ，nextReplicaShift\n        j<span class=\"token punctuation\">,</span> brokerArray<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> ／／ 为其余的副本分配 broker\n        ／／保存该分区所有副本的分配信息\n        ret<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>currentPartitionid<span class=\"token punctuation\">,</span> replicaBuffer<span class=\"token punctuation\">)</span> \n        ／／继续为 下一个分区分配副本\n        currentPartitionid <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n      <span class=\"token punctuation\">}</span>\n    ret\n    <span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"查看主题\"><a href=\"#查看主题\" class=\"headerlink\" title=\"查看主题\"></a>查看主题</h2><p>kafka-topics. 脚本有4种指令类型： create list describe alter<br>其中list describe 指令可用来方便地查看主题信息</p>\n<p>增加 topics-with-overrides 参数可以找 所有 含覆盖配置 主题 它只会列出包含了与集群不一样配置的主题</p>\n<p>under-replicated-partitions 和 unavai able-partitions 参数可以找出有问题的分区。</p>\n<h2 id=\"修改主题\"><a href=\"#修改主题\" class=\"headerlink\" title=\"修改主题\"></a>修改主题</h2><p>当一个主题被创建之后 依然允许对其做一定的修改，比如修改分区个数、修改配置。这是由alert指令提供的</p>\n<p>增加主题的分区数目后，当主题中的消息包含 key 时（即 key 不为 null 根据 key计算分区的行为就会受到影响。</p>\n<h2 id=\"配置管理\"><a href=\"#配置管理\" class=\"headerlink\" title=\"配置管理\"></a>配置管理</h2><p>kafka-configs 脚本是专门用来对配置进行操作的，这里的操作是指在运行状态下修改原有的配置，如此可以达到动态变更的目的。</p>\n<p>kafka configs.sh 脚本不仅可以支持操作主题相关的配置，还支持操作broker 、用户和客户端这三个类型 配置。</p>\n<h2 id=\"主题端参数\"><a href=\"#主题端参数\" class=\"headerlink\" title=\"主题端参数\"></a>主题端参数</h2><p>与主题相关的所有配置参数在 broker 层面都有对应参数，<br>比如主题端参数 cleanup.policy 对应 broker 层面的 log.cleanup policy</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222237.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222301.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222336.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222348.png\" alt></p>\n<h2 id=\"删除主题\"><a href=\"#删除主题\" class=\"headerlink\" title=\"删除主题\"></a>删除主题</h2><p>kafka-topics.sh 脚本中的 delete 令就可以用来删除主题</p>\n<p>使用 kafka_topics.sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的 /admin/delete_topics 路径下 建一个与待删除主题同名的节点，以 标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由 Kafka 的控制器负责完成的。</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222536.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222544.png\" alt></p>\n<h1 id=\"初识-KafkaAdminClient\"><a href=\"#初识-KafkaAdminClient\" class=\"headerlink\" title=\"初识 KafkaAdminClient\"></a>初识 KafkaAdminClient</h1><h2 id=\"基本使用\"><a href=\"#基本使用\" class=\"headerlink\" title=\"基本使用\"></a>基本使用</h2><p>和脚本类似，可以使用Topicommand类创建主题等。</p>\n<ul>\n<li>创建主题 CreateTopicsResult createTopics(Collection<newtopic> newTopics)</newtopic></li>\n<li>删除主题 DeleteTopicsResult deleteTopics(Collection<string> topics)</string></li>\n<li>列出所有可用的主题： ListTopicsResult listTopics()</li>\n<li>查看主题的信息： DescribeTopicsResult describeTopics(Collection<string> topicNames)</string></li>\n<li>查询配置信息 escribeConfigsResult describeConfigs(Collection<configresource> resources)</configresource></li>\n<li>修改配置信息： AlterConfigsResult alterConfigs(Map&lt;ConfigResource, Config&gt; configs)</li>\n<li>增加分区 CreatePartitionsResult createPartitions(Map&lt;String, NewPartitions&gt; new Partitions)</li>\n</ul>\n<h2 id=\"主题合法性验证\"><a href=\"#主题合法性验证\" class=\"headerlink\" title=\"主题合法性验证\"></a>主题合法性验证</h2><p>Kafka broker 端有－个这样的参数 create.topic.policy.class.name，默认值为null<br>它提供了一个入口用来验证主题创建的合法性。使用方式很简单，只需要自定义实现org.apache.kafka.server.policy.CreateTopicPolicy 接口</p>\n<p>例：<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106223639.png\" alt></p>\n<h1 id=\"分区的管理\"><a href=\"#分区的管理\" class=\"headerlink\" title=\"分区的管理\"></a>分区的管理</h1><h2 id=\"优先副本的选举\"><a href=\"#优先副本的选举\" class=\"headerlink\" title=\"优先副本的选举\"></a>优先副本的选举</h2><p>分区使用多副本机制来提升可靠性，但只有 leader 副本对外提供读写服务，而 follower本只负责在内部进行消息的同步。</p>\n<p>优先副本选举是指通过一定的方法促使副本选举为 leader ，以此来促进集群负载均衡 行为 可以称为“分区平衡”</p>\n<p>Kafka 中可以提供分区自动平衡的功能，与此对应的 broker 端参数是 auto.leader.rebalance.enable ，此参数的默认值为 true。Kafka 的控制器会启动一个定时任务，默认5分钟执行一次，这个定时任务会轮询所有的 broker节点，计算每个 broker 节点的分区不平衡率是否超过默认值10%</p>\n<p>kafka-perferred-replica election.sh 脚本提供了对分区 leader 副本进行重新平衡的功能。</p>\n<h2 id=\"分区重分配\"><a href=\"#分区重分配\" class=\"headerlink\" title=\"分区重分配\"></a>分区重分配</h2><p>当集群中的一个节点突然若机下线时，如果节点上的分区是单副本的，那么这些分区就变得不可用了，在节点恢复前，相应的数据也就处于丢失状态；如果节点上的分区是多副本的，那么位于这个节点上的 leader 副本的角色会转交到集群的其他 follower 副本 。</p>\n<p>当集群中新增 roker 节点时，只有新创建的主题分区才有可能被分配到这个节点上，而之前的主题分区并不会自动分配到新加入的节点中，因为在它们被创建时还没有这个新节点，这样新节点的负载和原先节点的负载之间严重不均衡。</p>\n<p>Kafka提供了 kafka-reassin-partitions.sh 脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。</p>\n<h2 id=\"复制限流\"><a href=\"#复制限流\" class=\"headerlink\" title=\"复制限流\"></a>复制限流</h2><p>分区重分配本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终的目的。</p>\n<p>副本间的复制限流有两种实现方式： kafka-config.sh 脚本和 kafka-reassign-partitions.sh脚本</p>\n<ul>\n<li><p>kafka-config.sh脚本主要 以动态配置的方式来达到限流的目的，在 broker 级别有两个与复制限流相关的配置参数 follower.replication.throttled.rate 和 leader.replication.throttled.rate ，前者用于设置 follower 副本复制的速度，后者用于设置 leader 副本传输的速度，它们的单位都是B/s 。</p>\n</li>\n<li><p>kafka reassign-partitions.sh 脚本本身也提供了限流的功能，只需一个 throttle 参数即可，</p>\n</li>\n</ul>\n<h2 id=\"修改副本因子\"><a href=\"#修改副本因子\" class=\"headerlink\" title=\"修改副本因子\"></a>修改副本因子</h2><p>修改副本因子的功能也是通过重分配所使用的 kafka-reassign-partition.sh 脚本实现的</p>\n<h1 id=\"如何选择合适的分区数\"><a href=\"#如何选择合适的分区数\" class=\"headerlink\" title=\"如何选择合适的分区数\"></a>如何选择合适的分区数</h1><h2 id=\"性能测试工具\"><a href=\"#性能测试工具\" class=\"headerlink\" title=\"性能测试工具\"></a>性能测试工具</h2><p>Kafka 本身提供的用于生产者性能测试 kafka-producer-perf-test.sh 和用于消费者性能测试的kafka-consumer-perf-test.sh</p>\n<h2 id=\"分区数越多吞吐量就越高吗\"><a href=\"#分区数越多吞吐量就越高吗\" class=\"headerlink\" title=\"分区数越多吞吐量就越高吗\"></a>分区数越多吞吐量就越高吗</h2><p>对生产者而言，每一个分区的数据写入是完全可以并行<br>对消费者而言， Kafka 只允许单个分区中的消息被一个消费者线程消费， 一个消费组的消费并行度完全依赖于所消费的分区数</p>\n<p>消息中间件的性能 般是指吞吐量（广义来说还包括延迟）。抛开硬件资源的影响，消息<br>写入的吞吐量还会受到消息大小、消息压缩方式、消息发送方式（同步 异步）、消息确认类型<br>acks、副本因子等参数影 响， 消息消费 吞吐量还会受到应用逻辑、处理速度的影响</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106230140.png\" alt><br>分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量跟着上涨。一旦分区数超过了某个阔值之后，整体的吞吐量是不升反降的。</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106230222.png\" alt><br>随着分区数的增加，相应的吞吐量也会有所增长。一旦分区数超过了某个阈值之后，整体的吞吐量也是不升反降的</p>\n<h2 id=\"分区数的上限\"><a href=\"#分区数的上限\" class=\"headerlink\" title=\"分区数的上限\"></a>分区数的上限</h2><p>一味的增加分区数并不能使吞吐量一直得到提升，并且分区数也并不能一直增加，如果超默认配置值，还会引起 Kafka 进程的崩溃</p>\n<p>创建过多分区会有异常，最关键的信息是“Too many open flies ”，这是一种常见的 Linux 系统错误，通常意文件描述符不足，它一般发生在创建线程、创建 Socket 、打开文件这些场景下 Linux系统的默认设置下，这个 件描述符的个数不是很 ，通过 ulimit 命令可以查看。</p>\n<p>ulimit 是在系统允许的情况下，提供对特定 shell 可利用的资源的控制。-H和-S选项指定资源的硬限制和软限制</p>\n<h2 id=\"考量因素\"><a href=\"#考量因素\" class=\"headerlink\" title=\"考量因素\"></a>考量因素</h2><p>从吞吐方面考虑，增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求 则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。</p>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<p>分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。</p>\n<h1 id=\"主题的管理\"><a href=\"#主题的管理\" class=\"headerlink\" title=\"主题的管理\"></a>主题的管理</h1><p>主题的管理包括创建主题、 查看主题信息、修改主题和删除主题等操作。</p>\n<h2 id=\"创建主题\"><a href=\"#创建主题\" class=\"headerlink\" title=\"创建主题\"></a>创建主题</h2><p>如果 broker 端配置参数 auto.create.topics.enable 设置 true （默认值就是 true) , 那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数为 num.partitions（默认值为1 ）、副本因子为 default.replication.factor （默认值为1 ）的主题。</p>\n<p>例：</p>\n<pre><code>bin/kafka-top cs .sh - zookeeper localhost: 2181/kafka \n--create --topic top create --partitions 4 --replication-factor 2</code></pre><p>在执行完脚本之后， Kafka 会在 log.dir log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为／tmp/kafka-logs／<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030211533.png\" alt></p>\n<p>topic-create-0 topic-create-1对应了主题的两个分区，其余两个分区被创建到了别的节点<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030211753.png\" alt></p>\n<p>主题、分区、副本和 Log （日志）的关系如下<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030211824.png\" alt></p>\n<p>我们不仅可以通过日志文件的根目录来查看集群中各个 broker 的分区副本的分配情况，还可以通过 ZooKeeper 客户端来获取。<br>当创建一个主题时会在 zooKeeper 的／ brokers/topics/ 目录下创建一个同名的实节点，该节点记录了该主题的分区副本分配方案。<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221030212257.png\" alt></p>\n<p>示例数据中的 “2”：[1, 2] 表示分区2 分配了2个副本，分别在 brokerld 1和 brokerId 2节点中。</p>\n<p>kafka topics脚本中还提供了 replica-assignment 参数来手动指定分区副本的分配方案。<br>replica assignment 参数的用法归纳如下：<br><code>-- replica-assignment &lt;String : broker_id_ for_part1_replica1: broker_id for \npartl_replica2 , broker_id _for_part2_replica1: broker_ id_ for _part2_replica2 , ... &gt;</code><br>这种方式根据分区号的数值大小按照从小到大的顺序进行排列 分区与分区 逗号 “，”<br>隔开，分区内多个副本用冒号“：”隔开</p>\n<p>创建主题时不能存在同名的主题，如果指定参数<code>if-not-exists</code>则在冲突时不做处理。<br>内部主题一般以双下划线开头’__’</p>\n<h2 id=\"分区副本的分配\"><a href=\"#分区副本的分配\" class=\"headerlink\" title=\"分区副本的分配\"></a>分区副本的分配</h2><p>分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个 broker 中创建哪些分区的副本。</p>\n<p>在创建主题时，如果使用了 replica assignment 参数，那么就按照指定的方案来进分区副本的创建；如果没有使用 replica-assignment 参数，那么就需要按照内部的逻辑来计算分配方案了</p>\n<p>使用 kafka-topics.sh 脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略 朱指定机架信息和指定机架信息 如果集群中所有的 brok 节点都没有配置broker.rack 参数，或者使用 disable-rack aware 参数来 建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。</p>\n<pre><code class=\"java\">private def assignRepl casToBrokersRackUnaware(\n  nPartit ons: Int , ／／分区数\n  replicat on Factor: Int , ／／副本 因子\n  brokerList : “ q[Int] , ／／；集群中 broker 列表\n  fixedStartindex: Int , ／／起始索 引，即 一个副本分自己的位置，默认值为\n  startPartitionid: Int): ／／起始分 编号，默认值为\n  Map[Int, Seq[Int]] = { \n    val ret = mutable.Map[Int, Seg[Int]] () ／／保存分自己结果的集合\n    val brokerArray = brokerList.toArray //brokerid 的列表\n    ／／如果起始索 fixedStartindex 小于0 ，则根据 broker 列表长度随机生成一个，以此来保证是\n    ／／；有效的 broker Id \n    val startIndex = if (fixedStartindex &gt;= 0) fixedStartindex \n      else rand.nextint(brokerArray.length) \n    ／／确保起始分区号不小于0\n    var currentPartitionId = math.max(O , startPartitionid)\n    ／／指定了副本的间隔，目的是为了更均匀地将副本分配到不同的 broker\n    var nextReplicaShift = if xedStartindex &gt;= 0) fixedStartindex\n      else rand.nextint(brokerArray.length) \n    ／／轮询所有分区， 将每个分区的副本分配到不同的 broker\n    for (_ &lt;- 0 until nPartitions) ( \n      if (currentPartitionid &gt; 0 &amp;&amp; (currentPartitonId % brokerArray. length == 0) ) \n      nextReplicaShift += 1 \n      val firstReplicaindex = (currentPartitionid + startindex ）% brokerArray.length\n      val replicaBuffer = mutable . ArrayBuffer(brokerArray(firstReplicaindex)) \n      ／／保存该分区所有副本分自己的 br oker集合\n      for (j &lt;- 0 until replicatFactor - 1) \n        replicaBuffer += brokerArray ( \n        replicaIndex(firstReplicaIndex ，nextReplicaShift\n        j, brokerArray.length)) ／／ 为其余的副本分配 broker\n        ／／保存该分区所有副本的分配信息\n        ret.put(currentPartitionid, replicaBuffer) \n        ／／继续为 下一个分区分配副本\n        currentPartitionid += 1\n      }\n    ret\n    }</code></pre>\n<h2 id=\"查看主题\"><a href=\"#查看主题\" class=\"headerlink\" title=\"查看主题\"></a>查看主题</h2><p>kafka-topics. 脚本有4种指令类型： create list describe alter<br>其中list describe 指令可用来方便地查看主题信息</p>\n<p>增加 topics-with-overrides 参数可以找 所有 含覆盖配置 主题 它只会列出包含了与集群不一样配置的主题</p>\n<p>under-replicated-partitions 和 unavai able-partitions 参数可以找出有问题的分区。</p>\n<h2 id=\"修改主题\"><a href=\"#修改主题\" class=\"headerlink\" title=\"修改主题\"></a>修改主题</h2><p>当一个主题被创建之后 依然允许对其做一定的修改，比如修改分区个数、修改配置。这是由alert指令提供的</p>\n<p>增加主题的分区数目后，当主题中的消息包含 key 时（即 key 不为 null 根据 key计算分区的行为就会受到影响。</p>\n<h2 id=\"配置管理\"><a href=\"#配置管理\" class=\"headerlink\" title=\"配置管理\"></a>配置管理</h2><p>kafka-configs 脚本是专门用来对配置进行操作的，这里的操作是指在运行状态下修改原有的配置，如此可以达到动态变更的目的。</p>\n<p>kafka configs.sh 脚本不仅可以支持操作主题相关的配置，还支持操作broker 、用户和客户端这三个类型 配置。</p>\n<h2 id=\"主题端参数\"><a href=\"#主题端参数\" class=\"headerlink\" title=\"主题端参数\"></a>主题端参数</h2><p>与主题相关的所有配置参数在 broker 层面都有对应参数，<br>比如主题端参数 cleanup.policy 对应 broker 层面的 log.cleanup policy</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222237.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222301.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222336.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222348.png\" alt></p>\n<h2 id=\"删除主题\"><a href=\"#删除主题\" class=\"headerlink\" title=\"删除主题\"></a>删除主题</h2><p>kafka-topics.sh 脚本中的 delete 令就可以用来删除主题</p>\n<p>使用 kafka_topics.sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的 /admin/delete_topics 路径下 建一个与待删除主题同名的节点，以 标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由 Kafka 的控制器负责完成的。</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222536.png\" alt></p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106222544.png\" alt></p>\n<h1 id=\"初识-KafkaAdminClient\"><a href=\"#初识-KafkaAdminClient\" class=\"headerlink\" title=\"初识 KafkaAdminClient\"></a>初识 KafkaAdminClient</h1><h2 id=\"基本使用\"><a href=\"#基本使用\" class=\"headerlink\" title=\"基本使用\"></a>基本使用</h2><p>和脚本类似，可以使用Topicommand类创建主题等。</p>\n<ul>\n<li>创建主题 CreateTopicsResult createTopics(Collection<newtopic> newTopics)</newtopic></li>\n<li>删除主题 DeleteTopicsResult deleteTopics(Collection<string> topics)</string></li>\n<li>列出所有可用的主题： ListTopicsResult listTopics()</li>\n<li>查看主题的信息： DescribeTopicsResult describeTopics(Collection<string> topicNames)</string></li>\n<li>查询配置信息 escribeConfigsResult describeConfigs(Collection<configresource> resources)</configresource></li>\n<li>修改配置信息： AlterConfigsResult alterConfigs(Map&lt;ConfigResource, Config&gt; configs)</li>\n<li>增加分区 CreatePartitionsResult createPartitions(Map&lt;String, NewPartitions&gt; new Partitions)</li>\n</ul>\n<h2 id=\"主题合法性验证\"><a href=\"#主题合法性验证\" class=\"headerlink\" title=\"主题合法性验证\"></a>主题合法性验证</h2><p>Kafka broker 端有－个这样的参数 create.topic.policy.class.name，默认值为null<br>它提供了一个入口用来验证主题创建的合法性。使用方式很简单，只需要自定义实现org.apache.kafka.server.policy.CreateTopicPolicy 接口</p>\n<p>例：<br><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106223639.png\" alt></p>\n<h1 id=\"分区的管理\"><a href=\"#分区的管理\" class=\"headerlink\" title=\"分区的管理\"></a>分区的管理</h1><h2 id=\"优先副本的选举\"><a href=\"#优先副本的选举\" class=\"headerlink\" title=\"优先副本的选举\"></a>优先副本的选举</h2><p>分区使用多副本机制来提升可靠性，但只有 leader 副本对外提供读写服务，而 follower本只负责在内部进行消息的同步。</p>\n<p>优先副本选举是指通过一定的方法促使副本选举为 leader ，以此来促进集群负载均衡 行为 可以称为“分区平衡”</p>\n<p>Kafka 中可以提供分区自动平衡的功能，与此对应的 broker 端参数是 auto.leader.rebalance.enable ，此参数的默认值为 true。Kafka 的控制器会启动一个定时任务，默认5分钟执行一次，这个定时任务会轮询所有的 broker节点，计算每个 broker 节点的分区不平衡率是否超过默认值10%</p>\n<p>kafka-perferred-replica election.sh 脚本提供了对分区 leader 副本进行重新平衡的功能。</p>\n<h2 id=\"分区重分配\"><a href=\"#分区重分配\" class=\"headerlink\" title=\"分区重分配\"></a>分区重分配</h2><p>当集群中的一个节点突然若机下线时，如果节点上的分区是单副本的，那么这些分区就变得不可用了，在节点恢复前，相应的数据也就处于丢失状态；如果节点上的分区是多副本的，那么位于这个节点上的 leader 副本的角色会转交到集群的其他 follower 副本 。</p>\n<p>当集群中新增 roker 节点时，只有新创建的主题分区才有可能被分配到这个节点上，而之前的主题分区并不会自动分配到新加入的节点中，因为在它们被创建时还没有这个新节点，这样新节点的负载和原先节点的负载之间严重不均衡。</p>\n<p>Kafka提供了 kafka-reassin-partitions.sh 脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。</p>\n<h2 id=\"复制限流\"><a href=\"#复制限流\" class=\"headerlink\" title=\"复制限流\"></a>复制限流</h2><p>分区重分配本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终的目的。</p>\n<p>副本间的复制限流有两种实现方式： kafka-config.sh 脚本和 kafka-reassign-partitions.sh脚本</p>\n<ul>\n<li><p>kafka-config.sh脚本主要 以动态配置的方式来达到限流的目的，在 broker 级别有两个与复制限流相关的配置参数 follower.replication.throttled.rate 和 leader.replication.throttled.rate ，前者用于设置 follower 副本复制的速度，后者用于设置 leader 副本传输的速度，它们的单位都是B/s 。</p>\n</li>\n<li><p>kafka reassign-partitions.sh 脚本本身也提供了限流的功能，只需一个 throttle 参数即可，</p>\n</li>\n</ul>\n<h2 id=\"修改副本因子\"><a href=\"#修改副本因子\" class=\"headerlink\" title=\"修改副本因子\"></a>修改副本因子</h2><p>修改副本因子的功能也是通过重分配所使用的 kafka-reassign-partition.sh 脚本实现的</p>\n<h1 id=\"如何选择合适的分区数\"><a href=\"#如何选择合适的分区数\" class=\"headerlink\" title=\"如何选择合适的分区数\"></a>如何选择合适的分区数</h1><h2 id=\"性能测试工具\"><a href=\"#性能测试工具\" class=\"headerlink\" title=\"性能测试工具\"></a>性能测试工具</h2><p>Kafka 本身提供的用于生产者性能测试 kafka-producer-perf-test.sh 和用于消费者性能测试的kafka-consumer-perf-test.sh</p>\n<h2 id=\"分区数越多吞吐量就越高吗\"><a href=\"#分区数越多吞吐量就越高吗\" class=\"headerlink\" title=\"分区数越多吞吐量就越高吗\"></a>分区数越多吞吐量就越高吗</h2><p>对生产者而言，每一个分区的数据写入是完全可以并行<br>对消费者而言， Kafka 只允许单个分区中的消息被一个消费者线程消费， 一个消费组的消费并行度完全依赖于所消费的分区数</p>\n<p>消息中间件的性能 般是指吞吐量（广义来说还包括延迟）。抛开硬件资源的影响，消息<br>写入的吞吐量还会受到消息大小、消息压缩方式、消息发送方式（同步 异步）、消息确认类型<br>acks、副本因子等参数影 响， 消息消费 吞吐量还会受到应用逻辑、处理速度的影响</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106230140.png\" alt><br>分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量跟着上涨。一旦分区数超过了某个阔值之后，整体的吞吐量是不升反降的。</p>\n<p><img src=\"/2022/10/30/kafka-topic-and-partition/img-20221106230222.png\" alt><br>随着分区数的增加，相应的吞吐量也会有所增长。一旦分区数超过了某个阈值之后，整体的吞吐量也是不升反降的</p>\n<h2 id=\"分区数的上限\"><a href=\"#分区数的上限\" class=\"headerlink\" title=\"分区数的上限\"></a>分区数的上限</h2><p>一味的增加分区数并不能使吞吐量一直得到提升，并且分区数也并不能一直增加，如果超默认配置值，还会引起 Kafka 进程的崩溃</p>\n<p>创建过多分区会有异常，最关键的信息是“Too many open flies ”，这是一种常见的 Linux 系统错误，通常意文件描述符不足，它一般发生在创建线程、创建 Socket 、打开文件这些场景下 Linux系统的默认设置下，这个 件描述符的个数不是很 ，通过 ulimit 命令可以查看。</p>\n<p>ulimit 是在系统允许的情况下，提供对特定 shell 可利用的资源的控制。-H和-S选项指定资源的硬限制和软限制</p>\n<h2 id=\"考量因素\"><a href=\"#考量因素\" class=\"headerlink\" title=\"考量因素\"></a>考量因素</h2><p>从吞吐方面考虑，增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求 则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。</p>\n"},{"title":"浅析ovn LS流表设计","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-09-27T14:41:49.000Z","img":"/medias/files/ovn.jpg","summary":"基本的二层流表分析","password":null,"_content":"\nOVN通过引入逻辑交换机(Logical Switch)、逻辑交换机端口(Logical Switch Port)来组成虚拟网络拓扑。\n\n二层包含的拓扑主要是同主机和跨主机两种。用户在页面通过lsp将虚拟机连接到同一个ls；其对应数据面，则是虚拟机的网口通过ovs port连接到ovs，每个主机上的ovs为其提供了虚拟网络功能。\n```\n(host1)vm1 - lsp1 - ls1\n(host1)vm2 - lsp2 -\n(host2)vm3 - lsp3 -\n```\n\n\n\n\n**参考：**\nhttps://www.ovn.org/support/dist-docs/ovn-architecture.7.pdf\nhttps://www.cnblogs.com/laolieren/p/ovn-architecture.html","source":"_posts/ovn-ls-pipeline.md","raw":"---\ntitle: 浅析ovn LS流表设计\ntags:\n  - OVN\n  - LS\ncategories:\n  - Network\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-09-27 22:41:49\nimg: /medias/files/ovn.jpg\nsummary: 基本的二层流表分析\npassword:\n---\n\nOVN通过引入逻辑交换机(Logical Switch)、逻辑交换机端口(Logical Switch Port)来组成虚拟网络拓扑。\n\n二层包含的拓扑主要是同主机和跨主机两种。用户在页面通过lsp将虚拟机连接到同一个ls；其对应数据面，则是虚拟机的网口通过ovs port连接到ovs，每个主机上的ovs为其提供了虚拟网络功能。\n```\n(host1)vm1 - lsp1 - ls1\n(host1)vm2 - lsp2 -\n(host2)vm3 - lsp3 -\n```\n\n\n\n\n**参考：**\nhttps://www.ovn.org/support/dist-docs/ovn-architecture.7.pdf\nhttps://www.cnblogs.com/laolieren/p/ovn-architecture.html","slug":"ovn-ls-pipeline","published":1,"updated":"2022-10-16T05:11:08.141Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9x000gagvtu6pktrd9","content":"<p>OVN通过引入逻辑交换机(Logical Switch)、逻辑交换机端口(Logical Switch Port)来组成虚拟网络拓扑。</p>\n<p>二层包含的拓扑主要是同主机和跨主机两种。用户在页面通过lsp将虚拟机连接到同一个ls；其对应数据面，则是虚拟机的网口通过ovs port连接到ovs，每个主机上的ovs为其提供了虚拟网络功能。</p>\n<pre><code>(host1)vm1 - lsp1 - ls1\n(host1)vm2 - lsp2 -\n(host2)vm3 - lsp3 -</code></pre><p><strong>参考：</strong><br><a href=\"https://www.ovn.org/support/dist-docs/ovn-architecture.7.pdf\" target=\"_blank\" rel=\"noopener\">https://www.ovn.org/support/dist-docs/ovn-architecture.7.pdf</a><br><a href=\"https://www.cnblogs.com/laolieren/p/ovn-architecture.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/laolieren/p/ovn-architecture.html</a></p>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<p>OVN通过引入逻辑交换机(Logical Switch)、逻辑交换机端口(Logical Switch Port)来组成虚拟网络拓扑。</p>\n<p>二层包含的拓扑主要是同主机和跨主机两种。用户在页面通过lsp将虚拟机连接到同一个ls；其对应数据面，则是虚拟机的网口通过ovs port连接到ovs，每个主机上的ovs为其提供了虚拟网络功能。</p>\n<pre><code>(host1)vm1 - lsp1 - ls1\n(host1)vm2 - lsp2 -\n(host2)vm3 - lsp3 -</code></pre><p><strong>参考：</strong><br><a href=\"https://www.ovn.org/support/dist-docs/ovn-architecture.7.pdf\" target=\"_blank\" rel=\"noopener\">https://www.ovn.org/support/dist-docs/ovn-architecture.7.pdf</a><br><a href=\"https://www.cnblogs.com/laolieren/p/ovn-architecture.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/laolieren/p/ovn-architecture.html</a></p>\n"},{"title":"win-11 安装linux子系统并使用","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-06-25T13:09:00.000Z","img":"/medias/files/wsl.jpg","summary":"安装并使用linux子系统","password":null,"_content":"\n参考链接：https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-11-with-gui-support#1-overview\n\n\n# 确认环境\n\n- 确认操作系统版本\nwindows搜索 关于你的电脑 -> 操作系统版本\n操作系统版本需要大于22000\n\n![](win11_wsl/img-20220625215308.png)\n\n- 确认开启虚拟化功能\nwindows搜索 windows功能 - 虚拟机平台\n适用于linux的windows子系统和windows虚拟机监控程序平台也最好勾选，需要**重启生效**。\n![](win11_wsl/img-20220625215633.png)\n\n# 安装wsl和ubuntu\n\n\n- 在windows应用商店搜索`Windows Subsystem`，获取并且安装\n也可以使用其他方式下载wsl并安装。\n![](win11_wsl/img-20220625220014.png)\n\n- 使用wsl2\n执行`wsl --set-default-version 2`\n\n- 在windows应用商店搜索`ubuntu`，安装linux发行版\n也可以自己选择其他发行版安装。\n![](win11_wsl/img-20220625220129.png)\n\n- 最终可以使用\n![](win11_wsl/img-20220625221705.png)\n\n\n# 常用命令\n\n列出已安装wsl信息\n`wsl -l -v`\n\n启动wsl\n`wsl -d <自定义的系统名>`\n\n设置wsl版本为2\n`wsl --set-version <自定义的系统名> 2`\n\n关闭系统\n`wsl --shutdown -n <自定义的系统名>`\n\n# 常见问题\n\n- linux发行版启动时遇到报错`占位程序接收到错误数据`\n通过执行`netsh winsock reset`解决\n","source":"_posts/win11_wsl.md","raw":"---\ntitle: win-11 安装linux子系统并使用\ntags:\n  - WSL\ncategories:\n  - 工具\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-06-25 21:09:00\nimg: /medias/files/wsl.jpg\nsummary: 安装并使用linux子系统\npassword:\n---\n\n参考链接：https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-11-with-gui-support#1-overview\n\n\n# 确认环境\n\n- 确认操作系统版本\nwindows搜索 关于你的电脑 -> 操作系统版本\n操作系统版本需要大于22000\n\n![](win11_wsl/img-20220625215308.png)\n\n- 确认开启虚拟化功能\nwindows搜索 windows功能 - 虚拟机平台\n适用于linux的windows子系统和windows虚拟机监控程序平台也最好勾选，需要**重启生效**。\n![](win11_wsl/img-20220625215633.png)\n\n# 安装wsl和ubuntu\n\n\n- 在windows应用商店搜索`Windows Subsystem`，获取并且安装\n也可以使用其他方式下载wsl并安装。\n![](win11_wsl/img-20220625220014.png)\n\n- 使用wsl2\n执行`wsl --set-default-version 2`\n\n- 在windows应用商店搜索`ubuntu`，安装linux发行版\n也可以自己选择其他发行版安装。\n![](win11_wsl/img-20220625220129.png)\n\n- 最终可以使用\n![](win11_wsl/img-20220625221705.png)\n\n\n# 常用命令\n\n列出已安装wsl信息\n`wsl -l -v`\n\n启动wsl\n`wsl -d <自定义的系统名>`\n\n设置wsl版本为2\n`wsl --set-version <自定义的系统名> 2`\n\n关闭系统\n`wsl --shutdown -n <自定义的系统名>`\n\n# 常见问题\n\n- linux发行版启动时遇到报错`占位程序接收到错误数据`\n通过执行`netsh winsock reset`解决\n","slug":"win11_wsl","published":1,"updated":"2022-07-04T14:25:05.788Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9x000kagvtebzgef0d","content":"<p>参考链接：<a href=\"https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-11-with-gui-support#1-overview\" target=\"_blank\" rel=\"noopener\">https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-11-with-gui-support#1-overview</a></p>\n<h1 id=\"确认环境\"><a href=\"#确认环境\" class=\"headerlink\" title=\"确认环境\"></a>确认环境</h1><ul>\n<li>确认操作系统版本<br>windows搜索 关于你的电脑 -&gt; 操作系统版本<br>操作系统版本需要大于22000</li>\n</ul>\n<p><img src=\"/2022/06/25/win11-wsl/img-20220625215308.png\" alt></p>\n<ul>\n<li>确认开启虚拟化功能<br>windows搜索 windows功能 - 虚拟机平台<br>适用于linux的windows子系统和windows虚拟机监控程序平台也最好勾选，需要<strong>重启生效</strong>。<br><img src=\"/2022/06/25/win11-wsl/img-20220625215633.png\" alt></li>\n</ul>\n<h1 id=\"安装wsl和ubuntu\"><a href=\"#安装wsl和ubuntu\" class=\"headerlink\" title=\"安装wsl和ubuntu\"></a>安装wsl和ubuntu</h1><ul>\n<li><p>在windows应用商店搜索<code>Windows Subsystem</code>，获取并且安装<br>也可以使用其他方式下载wsl并安装。<br><img src=\"/2022/06/25/win11-wsl/img-20220625220014.png\" alt></p>\n</li>\n<li><p>使用wsl2<br>执行<code>wsl --set-default-version 2</code></p>\n</li>\n<li><p>在windows应用商店搜索<code>ubuntu</code>，安装linux发行版<br>也可以自己选择其他发行版安装。<br><img src=\"/2022/06/25/win11-wsl/img-20220625220129.png\" alt></p>\n</li>\n<li><p>最终可以使用<br><img src=\"/2022/06/25/win11-wsl/img-20220625221705.png\" alt></p>\n</li>\n</ul>\n<h1 id=\"常用命令\"><a href=\"#常用命令\" class=\"headerlink\" title=\"常用命令\"></a>常用命令</h1><p>列出已安装wsl信息<br><code>wsl -l -v</code></p>\n<p>启动wsl<br><code>wsl -d &lt;自定义的系统名&gt;</code></p>\n<p>设置wsl版本为2<br><code>wsl --set-version &lt;自定义的系统名&gt; 2</code></p>\n<p>关闭系统<br><code>wsl --shutdown -n &lt;自定义的系统名&gt;</code></p>\n<h1 id=\"常见问题\"><a href=\"#常见问题\" class=\"headerlink\" title=\"常见问题\"></a>常见问题</h1><ul>\n<li>linux发行版启动时遇到报错<code>占位程序接收到错误数据</code><br>通过执行<code>netsh winsock reset</code>解决</li>\n</ul>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<p>参考链接：<a href=\"https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-11-with-gui-support#1-overview\" target=\"_blank\" rel=\"noopener\">https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-11-with-gui-support#1-overview</a></p>\n<h1 id=\"确认环境\"><a href=\"#确认环境\" class=\"headerlink\" title=\"确认环境\"></a>确认环境</h1><ul>\n<li>确认操作系统版本<br>windows搜索 关于你的电脑 -&gt; 操作系统版本<br>操作系统版本需要大于22000</li>\n</ul>\n<p><img src=\"/2022/06/25/win11-wsl/img-20220625215308.png\" alt></p>\n<ul>\n<li>确认开启虚拟化功能<br>windows搜索 windows功能 - 虚拟机平台<br>适用于linux的windows子系统和windows虚拟机监控程序平台也最好勾选，需要<strong>重启生效</strong>。<br><img src=\"/2022/06/25/win11-wsl/img-20220625215633.png\" alt></li>\n</ul>\n<h1 id=\"安装wsl和ubuntu\"><a href=\"#安装wsl和ubuntu\" class=\"headerlink\" title=\"安装wsl和ubuntu\"></a>安装wsl和ubuntu</h1><ul>\n<li><p>在windows应用商店搜索<code>Windows Subsystem</code>，获取并且安装<br>也可以使用其他方式下载wsl并安装。<br><img src=\"/2022/06/25/win11-wsl/img-20220625220014.png\" alt></p>\n</li>\n<li><p>使用wsl2<br>执行<code>wsl --set-default-version 2</code></p>\n</li>\n<li><p>在windows应用商店搜索<code>ubuntu</code>，安装linux发行版<br>也可以自己选择其他发行版安装。<br><img src=\"/2022/06/25/win11-wsl/img-20220625220129.png\" alt></p>\n</li>\n<li><p>最终可以使用<br><img src=\"/2022/06/25/win11-wsl/img-20220625221705.png\" alt></p>\n</li>\n</ul>\n<h1 id=\"常用命令\"><a href=\"#常用命令\" class=\"headerlink\" title=\"常用命令\"></a>常用命令</h1><p>列出已安装wsl信息<br><code>wsl -l -v</code></p>\n<p>启动wsl<br><code>wsl -d &lt;自定义的系统名&gt;</code></p>\n<p>设置wsl版本为2<br><code>wsl --set-version &lt;自定义的系统名&gt; 2</code></p>\n<p>关闭系统<br><code>wsl --shutdown -n &lt;自定义的系统名&gt;</code></p>\n<h1 id=\"常见问题\"><a href=\"#常见问题\" class=\"headerlink\" title=\"常见问题\"></a>常见问题</h1><ul>\n<li>linux发行版启动时遇到报错<code>占位程序接收到错误数据</code><br>通过执行<code>netsh winsock reset</code>解决</li>\n</ul>\n"},{"title":"ovs port vlan处理研究","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-07-05T14:39:49.000Z","img":"/medias/files/ovs_vlan.jpg","summary":"参考链接：http://www.openvswitch.org/support/dist-docs/ovs-vswitchd.conf.db.5.html","password":null,"_content":"\n## vlan 模式\n\naccess、trunk、native-tagged、native-untagged\n\n### 收发包行为\n\nvlanid为0和没有vlan tag一样的处理。\nnative-tagged端口和native-untagged端口的native vlan即为port的tag值\n\n  {% pullquote mindmap mindmap-md %}\n- OVS vlan属性收发包\n  - access\n    - 收\n      - 没有vlan tag，接收，并打上端口vlan(tag=0不生效)\n      - 有vlan tag且vlanid非0，丢弃\n    - 发\n      - 发出去的报文不带vlan\n  - trunk\n    - 收\n      - trunk为空收：\n        - 报文带vlan，允许进入\n        - 报文不带vlan，允许进入\n      - trunk不为空收\n        - 报文带vlan tag，vlan id是否在允许之列，收\n        - 报文不带vlan tag，丢弃\n    - 发\n      - 带着原始vlan发出\n  - native-tagged\n    - 收\n      - 报文带vlan tag，vlan id是否在允许之列，收\n      - 报文不带vlan tag，接收，并打上端口的native vlan\n    - 发\n      - 带着原始vlan发出\n  - native-untagged\n    - 收\n      - 报文带vlan tag，vlan id是否在允许之列，收\n      - 报文不带vlan tag，接收，并打上端口的native vlan\n    - 发\n      - vid == native vlan，不带vlan，发出\n      - vid != native vlan，带原始vlan发出\n\n{% endpullquote %}\n\n当端口vlan_mode为native-tagged或native-untagged时，native vlan也在其对应的广播域中\n\n## 实验过程\n\n### 创建两个vm\n\n```\nip netns add vm1\nip link add vm1-vif type veth peer name vm1\nip link set vm1 netns vm1\nip netns exec vm1 ip link set vm1 address 00:00:00:00:00:03\nip netns exec vm1 ip addr add 10.10.10.2/24 dev vm1\nip netns exec vm1 ip link set vm1 up\nip link set vm1-vif up\n\nip netns add vm2\nip link add vm2-vif type veth peer name vm2\nip link set vm2 netns vm2\nip netns exec vm2 ip link set vm2 address 00:00:00:00:00:04\nip netns exec vm2 ip addr add 10.10.10.3/24 dev vm2\nip netns exec vm2 ip link set vm2 up\nip link set vm2-vif up\n```\n\n### 连接vm网卡和网桥\n\n```\novs-vsctl add-br -br-int\novs-vsctl add-port br-int vm1-vif\novs-vsctl add-port br-int vm2-vif\n```\n\n效果如图\n![](ovs-port-vlan/img-20220705225523.png)\n\n### 测试\n\n#### 抓包工具\n\ntcpdump和ovs-tcpdump工具可以抓到一路上OVS对vlan的处理。\n\n如果使用ovs-tcpdump，ovs-tcpdump在守护程序中创建交换机镜像端口，并执行以侦听这些端口。当实例退出时，它会清理它创建的镜像端口。\n\n如果用系统tcpdump抓包，抓的是经过vm网卡veth pair的流量。\n\n抓包点如下\n\n```\nvm1-eth0-(tcpdump)vm1-vif(ovs-tcpdump)-OVS Bridge-vm2-vif-vm2-eth0\n```\n\n### access模式\n收包：收包不带vlan/vlan为0，则打上tag，带vlan，则丢弃\n发包：只会发vlan为端口vlan的包，发包不带vlan\n\n#### tag=0\n\ntag=0时不生效，抓到的包并没有打上vlanid为0的tag(处理收包时也类似，vlan_id为0则表示当作没有vlan处理)\n\n```\novs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=0\novs-vsctl set Port vm2-vif tag=0\n```\n![](ovs-port-vlan/img-20220707221449.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的包，vm1-vif port access tag=0处理后还是不带vlan\n![](ovs-port-vlan/img-20220707222722.png)\n![](ovs-port-vlan/img-20220707222806.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan0的包, vm1-vif处理后不带vlan\n![](ovs-port-vlan/img-20220711222809.png)\n\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的包，vm1-vif port access tag=0处理后丢弃\n![](ovs-port-vlan/img-20220711222511.png)\n![](ovs-port-vlan/img-20220711222607.png)\n\n\n**发包 不带vlan**\n- vm2-vif通过不带vlan的包，以不带vlan转发\n![](ovs-port-vlan/img-20220711223215.png)\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式tag为11，，vm2-vif access模式保持tag=0\n- 带vlan 11的数据包不会被转发到vm2-vif口\n![](ovs-port-vlan/img-20220713200925.png)\n\n\n#### tag!=0\n\n```\novs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif tag=10\n```\n![](ovs-port-vlan/img-20220707222905.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的包，vm1-vif port access tag=10处理后，带上vlan 10\n![](ovs-port-vlan/img-20220707223104.png)\n\n\n**收包 带vlan 0**\n设置linux 子接口\n```\nip netns exec vm1 vconfig add vm1 0\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.0 10.10.10.2\n```\n- vm1 发出vlan 0的数据包，vm1-vif port access 处理后，带上vlan 10\n![](ovs-port-vlan/img-20220710224012.png)\n![](ovs-port-vlan/img-20220710224207.png)\n\n\n**收包带vlan 10**\n设置linux 子接口\n```\nip netns exec vm1 vconfig add vm1 10\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.10 10.10.10.2\n```\n- vm1发出带vlan 10的包，vm1-vif port access 处理后，被丢弃\n![](ovs-port-vlan/img-20220710223431.png)\n![](ovs-port-vlan/img-20220710223519.png)\n\n\n**收包 带vlan11**\n```\nip netns exec vm1 vconfig add vm1 11\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.11 10.10.10.2\n```\n- vm1发出带vlan 11的数据包，vm1-vif port处理后，被丢弃\n![](ovs-port-vlan/img-20220713201315.png)\n\n\n**发包 不带vlan**\n- vm1-vif设置trunk模式且trunks为空，vm2-vif设置access模式tag=10，vm1-vif接收不带vlan的包后没有被转发到vm2-vif\n![](ovs-port-vlan/img-20220713201940.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- vm1-vif设置access模式tag=10，vm2-vif设置access模式tag=10\n- vm1-vif port将vlan 10的数据包转发到vm2-vif，vm2-vif处理后以不带vlan转发\n![](ovs-port-vlan/img-20220713203016.png)\n\n\n**发包 带vlan 11**\n- vm1-vif设置access模式tag=11， vm2-vif设置access模式tag=10\n- vm1-vif port收到vlan 11的数据包后没有转发到vm2-vif\n![](ovs-port-vlan/img-20220713203212.png)\n\n\n### trunk模式\ntrunks为空\n收包：收包不带vlan或者带vlan或者vlanid为0(进入后不带vlan)，允许进入\n发包：带着原始vlan转发\ntrunks不为空\n收包：带vlan且在vlan_range中，才允许进入\n发包：在vlan_range中，会带着原始vlan转发\n\n##### trunks为空\n在不配置vlan时，ovs port默认是trunk all的，可以抓包看到对应的数据包没有带vlan，也都被允许通过了。\n\n```\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm2-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[]\novs-vsctl set Port vm2-vif trunks=[]\n```\n![](ovs-port-vlan/img-20220713213515.png)\n\n**收到不带vlan的包**\n- vm1发出不带vlan的数据包，vm1-vif处理后继续不带vlan\n![](ovs-port-vlan/img-20220713203933.png)\n\n\n**收到带vlan 0的包**\n- vm1 发出带vlan 0的包，vm1-vif处理后不带vlan，且允许通过。\n![](ovs-port-vlan/img-20220710225805.png)\n![](ovs-port-vlan/img-20220710225731.png)\n\n\n**收到带vlan 10的包**\n- vm1发出带vlan 10的包，vm1-vif 处理后带着原vlan转发，\n![](ovs-port-vlan/img-20220710230349.png)\n![](ovs-port-vlan/img-20220713204049.png)\n\n\n**发包 不带vlan**\n- vm1-vif转发不带vlan的包到vm2-vif\n- vm2-vif继续以不带vlan转发vm2\n![](ovs-port-vlan/img-20220713204432.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- 设置vm1-vif 为access模式tag=10\n- vm1-vif收到vlan 10的数据包转发到vm2-vif， vm2-vif以原vlan转发到vm2\n![](ovs-port-vlan/img-20220713204647.png)\n\n\n##### trunks不为空\n在配置vlan后，ovs port只能收在trunk范围的包\n```\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm2-vif trunks=[10]\n```\n![](ovs-port-vlan/img-20220713213553.png)\n\n**收到不带vlan的包**\n- vm1 发出不带vlan的包，vm1-vif处理后，被丢弃\n![](ovs-port-vlan/img-20220710231215.png)\n\n\n**收到带vlan 0的包**\n- vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃\n![](ovs-port-vlan/img-20220710231542.png)\n\n\n**收到带vlan 10的包**\n- vm1 发出带vlan10的包，vm1-vif处理后允许通过，vm2-vif允许通过，vm2收到带vlan10的包后丢弃\n![](ovs-port-vlan/img-20220710231015.png)\n\n\n**收到带vlan 11的包**\n- vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃\n![](ovs-port-vlan/img-20220710231738.png)\n\n\n**发包 不带vlan**\n- 设置vm1-vif trunk模式，trunks=[]\n- vm1-vif处理不带vlan的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713205845.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif处理vlan 10的数据包转发到vm2-vif，vm2-vif以vlan 10转发\n![](ovs-port-vlan/img-20220713210045.png)\n\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif处理vlan 11的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713210138.png)\n\n### native-tagged模式\nnative-vlan设置即tag列\n收包：报文不带vlan，则打上native vlan进入，报文带vlan且在允许之列，则进入\n发包：带着原始vlan发出\n\n\n\n#### native vlan和trunks重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10\n```\n![](ovs-port-vlan/img-20220713213626.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后带上native vlan 10\n![](ovs-port-vlan/img-20220713211909.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后带上native vlan 10\n![](ovs-port-vlan/img-20220713212047.png)\n\n\n**收包 带vlan 10**\n- vm1发出带vlan 10的数据包，vm1-vif允许带着原始vlan进入\n![](ovs-port-vlan/img-20220713212213.png)\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的数据包，不在允许之列，vm1-vif丢弃\n![](ovs-port-vlan/img-20220713212418.png)\n\n\n**发包 不带vlan**\n- vm1-vif设置trunk模式，trunks=[]\n- vm1-vif收到不带vlan的数据包后没有向vm2-vif转发\n![](ovs-port-vlan/img-20220713212741.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif收到vlan 10的数据包转发到vm2-vif，vm2-vif处理后以原始vlan转发\n![](ovs-port-vlan/img-20220713212843.png)\n\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式，tag=11\n- vm1-vif收到vlan 11的数据包没有转发到vm2-vif\n![](ovs-port-vlan/img-20220713213027.png)\n\n\n#### native vlan和trunks不重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11\n```\n![](ovs-port-vlan/img-20220713213656.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后带vlan 11\n![](ovs-port-vlan/img-20220713213800.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 11\n![](ovs-port-vlan/img-20220713213923.png)\n\n\n**收包 带vlan 10**\n- vm1 发出带vlan 10的数据包，vm1-vif处理后带着原始vlan进入\n![](ovs-port-vlan/img-20220713214019.png)\n\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的数据包，vm1-vif处理后带着原始vlan进入\n![](ovs-port-vlan/img-20220713214125.png)\n\n\n**发包 带vlan 12**\n- vm1 发出带vlan 12的数据包，vm1-vif处理不在允许之列丢弃\n![](ovs-port-vlan/img-20220713214218.png)\n\n\n**发包 不带vlan**\n- vm1设置trunk模式，trunks=[]\n- vm1收到不带vlan的数据包，没有向vm2-vif转发\n![](ovs-port-vlan/img-20220713214451.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n**发包 带vlan 10**\n- vm1设置access模式，tag=10\n- vm1-vif 收到带vlan 10的数据包，转发到vm2-vif，vm2-vif以原始vlan转发\n![](ovs-port-vlan/img-20220713214701.png)\n\n**发包 带vlan 11**\n- vm1设置access模式，tag=11\n- vm1-vif收到带vlan 11的数据包，转发到vm2-vif，vm2-vif以原始vlan转发\n![](ovs-port-vlan/img-20220713214834.png)\n\n**发包 带vlan 12**\n- vm1设置access模式，tag=12\n- vm1-vif收到带vlan 12的数据包，没有转发到vm2-vif\n![](ovs-port-vlan/img-20220713214945.png)\n\n### native-untagged模式\nnative vlan即tag列\n收包：收包不带vlan，则打上native vlan进入，收包带vlan且在允许之列，则进入\n发包：发包和native vlan相同，则去掉vlan转发，否则带着原始vlan转发\n\n#### native vlan和trunks重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10\n```\n![](ovs-port-vlan/img-20220713215316.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后带vlan 10\n![](ovs-port-vlan/img-20220713215402.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 10\n![](ovs-port-vlan/img-20220713215454.png)\n\n\n**收包 带vlan 10**\n- vm1 发出带vlan 10的数据包，vm1-vif处理后带原始vlan 进入\n![](ovs-port-vlan/img-20220713215625.png)\n\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的数据包，vm1-vif处理后不在允许之列，丢弃\n![](ovs-port-vlan/img-20220713215748.png)\n\n\n**发包 不带vlan**\n- 设置vm1-vif trunk模式，trunks=[]\n- vm1-vif收到不带vlan的数据包后不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713220011.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n**发包 带vlan 10**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif收到带vlan 10的数据包转发到vm2-vif,vm2-vif处理后去掉vlan转发到vm2\n![](ovs-port-vlan/img-20220713220151.png)\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式，tag=11\n- vm1-vif收到带vlan 11的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713220356.png)\n\n#### native vlan和trunks不重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11\n```\n![](ovs-port-vlan/img-20220713220442.png)\n\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后打上vlan 11\n![](ovs-port-vlan/img-20220713220628.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后打上vlan 11\n![](ovs-port-vlan/img-20220713220741.png)\n\n\n**收包 带vlan 10**\n- vm1发出带vlan 10的数据包，vm1-vif处理后带着原始vlan 进入\n![](ovs-port-vlan/img-20220713220829.png)\n\n\n**收包 带vlan 11**\n- vm1发出带vlan 11的数据包，vm1-vif处理后带着原始vlan 进入\n![](ovs-port-vlan/img-20220713220933.png)\n\n\n**发包 带vlan 12**\n- vm1发出带vlan 11的数据包，vm1-vif处理后不在允许范围内丢弃\n![](ovs-port-vlan/img-20220713221021.png)\n\n\n**发包 不带vlan**\n- vm1-vif设置trunk模式 trunks=0\n- vm1-vif收到不带vlan的数据包，不会向vm2-vif转发\n![](ovs-port-vlan/img-20220713221252.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n**发包 带vlan 10**\n- vm1-vif设置access模式 tag=10\n- vm1-vif收到带vlan 10的数据包转发到vm2-vif，vm2-vif处理后带着原始vlan转发到vm2\n![](ovs-port-vlan/img-20220713221436.png)\n\n\n**发包 带vlan 11**\n- vm1-vif设置access模式 tag=11\n- vm1-vif收到带vlan 11的数据包转发到vm2-vif，vm2-vif处理后去掉vlan转发到vm2\n![](ovs-port-vlan/img-20220713221610.png)\n\n\n**发包 带vlan 12**\n- vm1-vif设置access模式 tag=12\n- vm1-vif收到带vlan 12的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713221726.png)\n\n\n\n**参考：**\n思维导插件`npm install hexo-simple-mindmap`\novs-tcpdump `https://docs.openvswitch.org/en/latest/ref/ovs-tcpdump.8/`","source":"_posts/ovs-port-vlan.md","raw":"---\ntitle: ovs port vlan处理研究\ntags:\n  - OVS\n  - VLAN\n  - ACCESS\n  - TRUNK\ncategories:\n  - NetWork\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-07-05 22:39:49\nimg: /medias/files/ovs_vlan.jpg\nsummary: 参考链接：http://www.openvswitch.org/support/dist-docs/ovs-vswitchd.conf.db.5.html\npassword:\n---\n\n## vlan 模式\n\naccess、trunk、native-tagged、native-untagged\n\n### 收发包行为\n\nvlanid为0和没有vlan tag一样的处理。\nnative-tagged端口和native-untagged端口的native vlan即为port的tag值\n\n  {% pullquote mindmap mindmap-md %}\n- OVS vlan属性收发包\n  - access\n    - 收\n      - 没有vlan tag，接收，并打上端口vlan(tag=0不生效)\n      - 有vlan tag且vlanid非0，丢弃\n    - 发\n      - 发出去的报文不带vlan\n  - trunk\n    - 收\n      - trunk为空收：\n        - 报文带vlan，允许进入\n        - 报文不带vlan，允许进入\n      - trunk不为空收\n        - 报文带vlan tag，vlan id是否在允许之列，收\n        - 报文不带vlan tag，丢弃\n    - 发\n      - 带着原始vlan发出\n  - native-tagged\n    - 收\n      - 报文带vlan tag，vlan id是否在允许之列，收\n      - 报文不带vlan tag，接收，并打上端口的native vlan\n    - 发\n      - 带着原始vlan发出\n  - native-untagged\n    - 收\n      - 报文带vlan tag，vlan id是否在允许之列，收\n      - 报文不带vlan tag，接收，并打上端口的native vlan\n    - 发\n      - vid == native vlan，不带vlan，发出\n      - vid != native vlan，带原始vlan发出\n\n{% endpullquote %}\n\n当端口vlan_mode为native-tagged或native-untagged时，native vlan也在其对应的广播域中\n\n## 实验过程\n\n### 创建两个vm\n\n```\nip netns add vm1\nip link add vm1-vif type veth peer name vm1\nip link set vm1 netns vm1\nip netns exec vm1 ip link set vm1 address 00:00:00:00:00:03\nip netns exec vm1 ip addr add 10.10.10.2/24 dev vm1\nip netns exec vm1 ip link set vm1 up\nip link set vm1-vif up\n\nip netns add vm2\nip link add vm2-vif type veth peer name vm2\nip link set vm2 netns vm2\nip netns exec vm2 ip link set vm2 address 00:00:00:00:00:04\nip netns exec vm2 ip addr add 10.10.10.3/24 dev vm2\nip netns exec vm2 ip link set vm2 up\nip link set vm2-vif up\n```\n\n### 连接vm网卡和网桥\n\n```\novs-vsctl add-br -br-int\novs-vsctl add-port br-int vm1-vif\novs-vsctl add-port br-int vm2-vif\n```\n\n效果如图\n![](ovs-port-vlan/img-20220705225523.png)\n\n### 测试\n\n#### 抓包工具\n\ntcpdump和ovs-tcpdump工具可以抓到一路上OVS对vlan的处理。\n\n如果使用ovs-tcpdump，ovs-tcpdump在守护程序中创建交换机镜像端口，并执行以侦听这些端口。当实例退出时，它会清理它创建的镜像端口。\n\n如果用系统tcpdump抓包，抓的是经过vm网卡veth pair的流量。\n\n抓包点如下\n\n```\nvm1-eth0-(tcpdump)vm1-vif(ovs-tcpdump)-OVS Bridge-vm2-vif-vm2-eth0\n```\n\n### access模式\n收包：收包不带vlan/vlan为0，则打上tag，带vlan，则丢弃\n发包：只会发vlan为端口vlan的包，发包不带vlan\n\n#### tag=0\n\ntag=0时不生效，抓到的包并没有打上vlanid为0的tag(处理收包时也类似，vlan_id为0则表示当作没有vlan处理)\n\n```\novs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=0\novs-vsctl set Port vm2-vif tag=0\n```\n![](ovs-port-vlan/img-20220707221449.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的包，vm1-vif port access tag=0处理后还是不带vlan\n![](ovs-port-vlan/img-20220707222722.png)\n![](ovs-port-vlan/img-20220707222806.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan0的包, vm1-vif处理后不带vlan\n![](ovs-port-vlan/img-20220711222809.png)\n\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的包，vm1-vif port access tag=0处理后丢弃\n![](ovs-port-vlan/img-20220711222511.png)\n![](ovs-port-vlan/img-20220711222607.png)\n\n\n**发包 不带vlan**\n- vm2-vif通过不带vlan的包，以不带vlan转发\n![](ovs-port-vlan/img-20220711223215.png)\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式tag为11，，vm2-vif access模式保持tag=0\n- 带vlan 11的数据包不会被转发到vm2-vif口\n![](ovs-port-vlan/img-20220713200925.png)\n\n\n#### tag!=0\n\n```\novs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif tag=10\n```\n![](ovs-port-vlan/img-20220707222905.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的包，vm1-vif port access tag=10处理后，带上vlan 10\n![](ovs-port-vlan/img-20220707223104.png)\n\n\n**收包 带vlan 0**\n设置linux 子接口\n```\nip netns exec vm1 vconfig add vm1 0\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.0 10.10.10.2\n```\n- vm1 发出vlan 0的数据包，vm1-vif port access 处理后，带上vlan 10\n![](ovs-port-vlan/img-20220710224012.png)\n![](ovs-port-vlan/img-20220710224207.png)\n\n\n**收包带vlan 10**\n设置linux 子接口\n```\nip netns exec vm1 vconfig add vm1 10\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.10 10.10.10.2\n```\n- vm1发出带vlan 10的包，vm1-vif port access 处理后，被丢弃\n![](ovs-port-vlan/img-20220710223431.png)\n![](ovs-port-vlan/img-20220710223519.png)\n\n\n**收包 带vlan11**\n```\nip netns exec vm1 vconfig add vm1 11\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.11 10.10.10.2\n```\n- vm1发出带vlan 11的数据包，vm1-vif port处理后，被丢弃\n![](ovs-port-vlan/img-20220713201315.png)\n\n\n**发包 不带vlan**\n- vm1-vif设置trunk模式且trunks为空，vm2-vif设置access模式tag=10，vm1-vif接收不带vlan的包后没有被转发到vm2-vif\n![](ovs-port-vlan/img-20220713201940.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- vm1-vif设置access模式tag=10，vm2-vif设置access模式tag=10\n- vm1-vif port将vlan 10的数据包转发到vm2-vif，vm2-vif处理后以不带vlan转发\n![](ovs-port-vlan/img-20220713203016.png)\n\n\n**发包 带vlan 11**\n- vm1-vif设置access模式tag=11， vm2-vif设置access模式tag=10\n- vm1-vif port收到vlan 11的数据包后没有转发到vm2-vif\n![](ovs-port-vlan/img-20220713203212.png)\n\n\n### trunk模式\ntrunks为空\n收包：收包不带vlan或者带vlan或者vlanid为0(进入后不带vlan)，允许进入\n发包：带着原始vlan转发\ntrunks不为空\n收包：带vlan且在vlan_range中，才允许进入\n发包：在vlan_range中，会带着原始vlan转发\n\n##### trunks为空\n在不配置vlan时，ovs port默认是trunk all的，可以抓包看到对应的数据包没有带vlan，也都被允许通过了。\n\n```\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm2-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[]\novs-vsctl set Port vm2-vif trunks=[]\n```\n![](ovs-port-vlan/img-20220713213515.png)\n\n**收到不带vlan的包**\n- vm1发出不带vlan的数据包，vm1-vif处理后继续不带vlan\n![](ovs-port-vlan/img-20220713203933.png)\n\n\n**收到带vlan 0的包**\n- vm1 发出带vlan 0的包，vm1-vif处理后不带vlan，且允许通过。\n![](ovs-port-vlan/img-20220710225805.png)\n![](ovs-port-vlan/img-20220710225731.png)\n\n\n**收到带vlan 10的包**\n- vm1发出带vlan 10的包，vm1-vif 处理后带着原vlan转发，\n![](ovs-port-vlan/img-20220710230349.png)\n![](ovs-port-vlan/img-20220713204049.png)\n\n\n**发包 不带vlan**\n- vm1-vif转发不带vlan的包到vm2-vif\n- vm2-vif继续以不带vlan转发vm2\n![](ovs-port-vlan/img-20220713204432.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- 设置vm1-vif 为access模式tag=10\n- vm1-vif收到vlan 10的数据包转发到vm2-vif， vm2-vif以原vlan转发到vm2\n![](ovs-port-vlan/img-20220713204647.png)\n\n\n##### trunks不为空\n在配置vlan后，ovs port只能收在trunk范围的包\n```\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm2-vif trunks=[10]\n```\n![](ovs-port-vlan/img-20220713213553.png)\n\n**收到不带vlan的包**\n- vm1 发出不带vlan的包，vm1-vif处理后，被丢弃\n![](ovs-port-vlan/img-20220710231215.png)\n\n\n**收到带vlan 0的包**\n- vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃\n![](ovs-port-vlan/img-20220710231542.png)\n\n\n**收到带vlan 10的包**\n- vm1 发出带vlan10的包，vm1-vif处理后允许通过，vm2-vif允许通过，vm2收到带vlan10的包后丢弃\n![](ovs-port-vlan/img-20220710231015.png)\n\n\n**收到带vlan 11的包**\n- vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃\n![](ovs-port-vlan/img-20220710231738.png)\n\n\n**发包 不带vlan**\n- 设置vm1-vif trunk模式，trunks=[]\n- vm1-vif处理不带vlan的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713205845.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif处理vlan 10的数据包转发到vm2-vif，vm2-vif以vlan 10转发\n![](ovs-port-vlan/img-20220713210045.png)\n\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif处理vlan 11的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713210138.png)\n\n### native-tagged模式\nnative-vlan设置即tag列\n收包：报文不带vlan，则打上native vlan进入，报文带vlan且在允许之列，则进入\n发包：带着原始vlan发出\n\n\n\n#### native vlan和trunks重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10\n```\n![](ovs-port-vlan/img-20220713213626.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后带上native vlan 10\n![](ovs-port-vlan/img-20220713211909.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后带上native vlan 10\n![](ovs-port-vlan/img-20220713212047.png)\n\n\n**收包 带vlan 10**\n- vm1发出带vlan 10的数据包，vm1-vif允许带着原始vlan进入\n![](ovs-port-vlan/img-20220713212213.png)\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的数据包，不在允许之列，vm1-vif丢弃\n![](ovs-port-vlan/img-20220713212418.png)\n\n\n**发包 不带vlan**\n- vm1-vif设置trunk模式，trunks=[]\n- vm1-vif收到不带vlan的数据包后没有向vm2-vif转发\n![](ovs-port-vlan/img-20220713212741.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n\n**发包 带vlan 10**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif收到vlan 10的数据包转发到vm2-vif，vm2-vif处理后以原始vlan转发\n![](ovs-port-vlan/img-20220713212843.png)\n\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式，tag=11\n- vm1-vif收到vlan 11的数据包没有转发到vm2-vif\n![](ovs-port-vlan/img-20220713213027.png)\n\n\n#### native vlan和trunks不重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11\n```\n![](ovs-port-vlan/img-20220713213656.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后带vlan 11\n![](ovs-port-vlan/img-20220713213800.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 11\n![](ovs-port-vlan/img-20220713213923.png)\n\n\n**收包 带vlan 10**\n- vm1 发出带vlan 10的数据包，vm1-vif处理后带着原始vlan进入\n![](ovs-port-vlan/img-20220713214019.png)\n\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的数据包，vm1-vif处理后带着原始vlan进入\n![](ovs-port-vlan/img-20220713214125.png)\n\n\n**发包 带vlan 12**\n- vm1 发出带vlan 12的数据包，vm1-vif处理不在允许之列丢弃\n![](ovs-port-vlan/img-20220713214218.png)\n\n\n**发包 不带vlan**\n- vm1设置trunk模式，trunks=[]\n- vm1收到不带vlan的数据包，没有向vm2-vif转发\n![](ovs-port-vlan/img-20220713214451.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n**发包 带vlan 10**\n- vm1设置access模式，tag=10\n- vm1-vif 收到带vlan 10的数据包，转发到vm2-vif，vm2-vif以原始vlan转发\n![](ovs-port-vlan/img-20220713214701.png)\n\n**发包 带vlan 11**\n- vm1设置access模式，tag=11\n- vm1-vif收到带vlan 11的数据包，转发到vm2-vif，vm2-vif以原始vlan转发\n![](ovs-port-vlan/img-20220713214834.png)\n\n**发包 带vlan 12**\n- vm1设置access模式，tag=12\n- vm1-vif收到带vlan 12的数据包，没有转发到vm2-vif\n![](ovs-port-vlan/img-20220713214945.png)\n\n### native-untagged模式\nnative vlan即tag列\n收包：收包不带vlan，则打上native vlan进入，收包带vlan且在允许之列，则进入\n发包：发包和native vlan相同，则去掉vlan转发，否则带着原始vlan转发\n\n#### native vlan和trunks重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10\n```\n![](ovs-port-vlan/img-20220713215316.png)\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后带vlan 10\n![](ovs-port-vlan/img-20220713215402.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 10\n![](ovs-port-vlan/img-20220713215454.png)\n\n\n**收包 带vlan 10**\n- vm1 发出带vlan 10的数据包，vm1-vif处理后带原始vlan 进入\n![](ovs-port-vlan/img-20220713215625.png)\n\n\n**收包 带vlan 11**\n- vm1 发出带vlan 11的数据包，vm1-vif处理后不在允许之列，丢弃\n![](ovs-port-vlan/img-20220713215748.png)\n\n\n**发包 不带vlan**\n- 设置vm1-vif trunk模式，trunks=[]\n- vm1-vif收到不带vlan的数据包后不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713220011.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n**发包 带vlan 10**\n- 设置vm1-vif access模式，tag=10\n- vm1-vif收到带vlan 10的数据包转发到vm2-vif,vm2-vif处理后去掉vlan转发到vm2\n![](ovs-port-vlan/img-20220713220151.png)\n\n**发包 带vlan 11**\n- 设置vm1-vif access模式，tag=11\n- vm1-vif收到带vlan 11的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713220356.png)\n\n#### native vlan和trunks不重合\n```\novs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11\n```\n![](ovs-port-vlan/img-20220713220442.png)\n\n\n**收包 不带vlan**\n- vm1发出不带vlan的数据包，vm1-vif处理后打上vlan 11\n![](ovs-port-vlan/img-20220713220628.png)\n\n\n**收包 带vlan 0**\n- vm1发出带vlan 0的数据包，vm1-vif处理后打上vlan 11\n![](ovs-port-vlan/img-20220713220741.png)\n\n\n**收包 带vlan 10**\n- vm1发出带vlan 10的数据包，vm1-vif处理后带着原始vlan 进入\n![](ovs-port-vlan/img-20220713220829.png)\n\n\n**收包 带vlan 11**\n- vm1发出带vlan 11的数据包，vm1-vif处理后带着原始vlan 进入\n![](ovs-port-vlan/img-20220713220933.png)\n\n\n**发包 带vlan 12**\n- vm1发出带vlan 11的数据包，vm1-vif处理后不在允许范围内丢弃\n![](ovs-port-vlan/img-20220713221021.png)\n\n\n**发包 不带vlan**\n- vm1-vif设置trunk模式 trunks=0\n- vm1-vif收到不带vlan的数据包，不会向vm2-vif转发\n![](ovs-port-vlan/img-20220713221252.png)\n\n\n**发包 带vlan 0**\n带vlan 0的数据包无法进入\n\n**发包 带vlan 10**\n- vm1-vif设置access模式 tag=10\n- vm1-vif收到带vlan 10的数据包转发到vm2-vif，vm2-vif处理后带着原始vlan转发到vm2\n![](ovs-port-vlan/img-20220713221436.png)\n\n\n**发包 带vlan 11**\n- vm1-vif设置access模式 tag=11\n- vm1-vif收到带vlan 11的数据包转发到vm2-vif，vm2-vif处理后去掉vlan转发到vm2\n![](ovs-port-vlan/img-20220713221610.png)\n\n\n**发包 带vlan 12**\n- vm1-vif设置access模式 tag=12\n- vm1-vif收到带vlan 12的数据包不会转发到vm2-vif\n![](ovs-port-vlan/img-20220713221726.png)\n\n\n\n**参考：**\n思维导插件`npm install hexo-simple-mindmap`\novs-tcpdump `https://docs.openvswitch.org/en/latest/ref/ovs-tcpdump.8/`","slug":"ovs-port-vlan","published":1,"updated":"2022-09-27T14:34:06.756Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg8yre9x000magvtw1nlgy8p","content":"<h2 id=\"vlan-模式\"><a href=\"#vlan-模式\" class=\"headerlink\" title=\"vlan 模式\"></a>vlan 模式</h2><p>access、trunk、native-tagged、native-untagged</p>\n<h3 id=\"收发包行为\"><a href=\"#收发包行为\" class=\"headerlink\" title=\"收发包行为\"></a>收发包行为</h3><p>vlanid为0和没有vlan tag一样的处理。<br>native-tagged端口和native-untagged端口的native vlan即为port的tag值</p>\n  <blockquote class=\"pullquote mindmap mindmap-md\"><ul>\n<li>OVS vlan属性收发包<ul>\n<li>access<ul>\n<li>收<ul>\n<li>没有vlan tag，接收，并打上端口vlan(tag=0不生效)</li>\n<li>有vlan tag且vlanid非0，丢弃</li>\n</ul>\n</li>\n<li>发<ul>\n<li>发出去的报文不带vlan</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>trunk<ul>\n<li>收<ul>\n<li>trunk为空收：<ul>\n<li>报文带vlan，允许进入</li>\n<li>报文不带vlan，允许进入</li>\n</ul>\n</li>\n<li>trunk不为空收<ul>\n<li>报文带vlan tag，vlan id是否在允许之列，收</li>\n<li>报文不带vlan tag，丢弃</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>发<ul>\n<li>带着原始vlan发出</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>native-tagged<ul>\n<li>收<ul>\n<li>报文带vlan tag，vlan id是否在允许之列，收</li>\n<li>报文不带vlan tag，接收，并打上端口的native vlan</li>\n</ul>\n</li>\n<li>发<ul>\n<li>带着原始vlan发出</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>native-untagged<ul>\n<li>收<ul>\n<li>报文带vlan tag，vlan id是否在允许之列，收</li>\n<li>报文不带vlan tag，接收，并打上端口的native vlan</li>\n</ul>\n</li>\n<li>发<ul>\n<li>vid == native vlan，不带vlan，发出</li>\n<li>vid != native vlan，带原始vlan发出</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n\n<p>当端口vlan_mode为native-tagged或native-untagged时，native vlan也在其对应的广播域中</p>\n<h2 id=\"实验过程\"><a href=\"#实验过程\" class=\"headerlink\" title=\"实验过程\"></a>实验过程</h2><h3 id=\"创建两个vm\"><a href=\"#创建两个vm\" class=\"headerlink\" title=\"创建两个vm\"></a>创建两个vm</h3><pre><code>ip netns add vm1\nip link add vm1-vif type veth peer name vm1\nip link set vm1 netns vm1\nip netns exec vm1 ip link set vm1 address 00:00:00:00:00:03\nip netns exec vm1 ip addr add 10.10.10.2/24 dev vm1\nip netns exec vm1 ip link set vm1 up\nip link set vm1-vif up\n\nip netns add vm2\nip link add vm2-vif type veth peer name vm2\nip link set vm2 netns vm2\nip netns exec vm2 ip link set vm2 address 00:00:00:00:00:04\nip netns exec vm2 ip addr add 10.10.10.3/24 dev vm2\nip netns exec vm2 ip link set vm2 up\nip link set vm2-vif up</code></pre><h3 id=\"连接vm网卡和网桥\"><a href=\"#连接vm网卡和网桥\" class=\"headerlink\" title=\"连接vm网卡和网桥\"></a>连接vm网卡和网桥</h3><pre><code>ovs-vsctl add-br -br-int\novs-vsctl add-port br-int vm1-vif\novs-vsctl add-port br-int vm2-vif</code></pre><p>效果如图<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220705225523.png\" alt></p>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><h4 id=\"抓包工具\"><a href=\"#抓包工具\" class=\"headerlink\" title=\"抓包工具\"></a>抓包工具</h4><p>tcpdump和ovs-tcpdump工具可以抓到一路上OVS对vlan的处理。</p>\n<p>如果使用ovs-tcpdump，ovs-tcpdump在守护程序中创建交换机镜像端口，并执行以侦听这些端口。当实例退出时，它会清理它创建的镜像端口。</p>\n<p>如果用系统tcpdump抓包，抓的是经过vm网卡veth pair的流量。</p>\n<p>抓包点如下</p>\n<pre><code>vm1-eth0-(tcpdump)vm1-vif(ovs-tcpdump)-OVS Bridge-vm2-vif-vm2-eth0</code></pre><h3 id=\"access模式\"><a href=\"#access模式\" class=\"headerlink\" title=\"access模式\"></a>access模式</h3><p>收包：收包不带vlan/vlan为0，则打上tag，带vlan，则丢弃<br>发包：只会发vlan为端口vlan的包，发包不带vlan</p>\n<h4 id=\"tag-0\"><a href=\"#tag-0\" class=\"headerlink\" title=\"tag=0\"></a>tag=0</h4><p>tag=0时不生效，抓到的包并没有打上vlanid为0的tag(处理收包时也类似，vlan_id为0则表示当作没有vlan处理)</p>\n<pre><code>ovs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=0\novs-vsctl set Port vm2-vif tag=0</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220707221449.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的包，vm1-vif port access tag=0处理后还是不带vlan<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220707222722.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220707222806.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan0的包, vm1-vif处理后不带vlan<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711222809.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的包，vm1-vif port access tag=0处理后丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711222511.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711222607.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm2-vif通过不带vlan的包，以不带vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711223215.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式tag为11，，vm2-vif access模式保持tag=0</li>\n<li>带vlan 11的数据包不会被转发到vm2-vif口<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713200925.png\" alt></li>\n</ul>\n<h4 id=\"tag-0-1\"><a href=\"#tag-0-1\" class=\"headerlink\" title=\"tag!=0\"></a>tag!=0</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif tag=10</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220707222905.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的包，vm1-vif port access tag=10处理后，带上vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220707223104.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong><br>设置linux 子接口</p>\n<pre><code>ip netns exec vm1 vconfig add vm1 0\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.0 10.10.10.2</code></pre><ul>\n<li>vm1 发出vlan 0的数据包，vm1-vif port access 处理后，带上vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710224012.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710224207.png\" alt></li>\n</ul>\n<p><strong>收包带vlan 10</strong><br>设置linux 子接口</p>\n<pre><code>ip netns exec vm1 vconfig add vm1 10\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.10 10.10.10.2</code></pre><ul>\n<li>vm1发出带vlan 10的包，vm1-vif port access 处理后，被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710223431.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710223519.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan11</strong></p>\n<pre><code>ip netns exec vm1 vconfig add vm1 11\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.11 10.10.10.2</code></pre><ul>\n<li>vm1发出带vlan 11的数据包，vm1-vif port处理后，被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713201315.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif设置trunk模式且trunks为空，vm2-vif设置access模式tag=10，vm1-vif接收不带vlan的包后没有被转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713201940.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>vm1-vif设置access模式tag=10，vm2-vif设置access模式tag=10</li>\n<li>vm1-vif port将vlan 10的数据包转发到vm2-vif，vm2-vif处理后以不带vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713203016.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>vm1-vif设置access模式tag=11， vm2-vif设置access模式tag=10</li>\n<li>vm1-vif port收到vlan 11的数据包后没有转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713203212.png\" alt></li>\n</ul>\n<h3 id=\"trunk模式\"><a href=\"#trunk模式\" class=\"headerlink\" title=\"trunk模式\"></a>trunk模式</h3><p>trunks为空<br>收包：收包不带vlan或者带vlan或者vlanid为0(进入后不带vlan)，允许进入<br>发包：带着原始vlan转发<br>trunks不为空<br>收包：带vlan且在vlan_range中，才允许进入<br>发包：在vlan_range中，会带着原始vlan转发</p>\n<h5 id=\"trunks为空\"><a href=\"#trunks为空\" class=\"headerlink\" title=\"trunks为空\"></a>trunks为空</h5><p>在不配置vlan时，ovs port默认是trunk all的，可以抓包看到对应的数据包没有带vlan，也都被允许通过了。</p>\n<pre><code>ovs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm2-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[]\novs-vsctl set Port vm2-vif trunks=[]</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213515.png\" alt></p>\n<p><strong>收到不带vlan的包</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后继续不带vlan<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713203933.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 0的包</strong></p>\n<ul>\n<li>vm1 发出带vlan 0的包，vm1-vif处理后不带vlan，且允许通过。<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710225805.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710225731.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 10的包</strong></p>\n<ul>\n<li>vm1发出带vlan 10的包，vm1-vif 处理后带着原vlan转发，<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710230349.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713204049.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif转发不带vlan的包到vm2-vif</li>\n<li>vm2-vif继续以不带vlan转发vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713204432.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif 为access模式tag=10</li>\n<li>vm1-vif收到vlan 10的数据包转发到vm2-vif， vm2-vif以原vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713204647.png\" alt></li>\n</ul>\n<h5 id=\"trunks不为空\"><a href=\"#trunks不为空\" class=\"headerlink\" title=\"trunks不为空\"></a>trunks不为空</h5><p>在配置vlan后，ovs port只能收在trunk范围的包</p>\n<pre><code>ovs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm2-vif trunks=[10]</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213553.png\" alt></p>\n<p><strong>收到不带vlan的包</strong></p>\n<ul>\n<li>vm1 发出不带vlan的包，vm1-vif处理后，被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231215.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 0的包</strong></p>\n<ul>\n<li>vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231542.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 10的包</strong></p>\n<ul>\n<li>vm1 发出带vlan10的包，vm1-vif处理后允许通过，vm2-vif允许通过，vm2收到带vlan10的包后丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231015.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 11的包</strong></p>\n<ul>\n<li>vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231738.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>设置vm1-vif trunk模式，trunks=[]</li>\n<li>vm1-vif处理不带vlan的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713205845.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif处理vlan 10的数据包转发到vm2-vif，vm2-vif以vlan 10转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713210045.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif处理vlan 11的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713210138.png\" alt></li>\n</ul>\n<h3 id=\"native-tagged模式\"><a href=\"#native-tagged模式\" class=\"headerlink\" title=\"native-tagged模式\"></a>native-tagged模式</h3><p>native-vlan设置即tag列<br>收包：报文不带vlan，则打上native vlan进入，报文带vlan且在允许之列，则进入<br>发包：带着原始vlan发出</p>\n<h4 id=\"native-vlan和trunks重合\"><a href=\"#native-vlan和trunks重合\" class=\"headerlink\" title=\"native vlan和trunks重合\"></a>native vlan和trunks重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213626.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后带上native vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713211909.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后带上native vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212047.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1发出带vlan 10的数据包，vm1-vif允许带着原始vlan进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212213.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的数据包，不在允许之列，vm1-vif丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212418.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif设置trunk模式，trunks=[]</li>\n<li>vm1-vif收到不带vlan的数据包后没有向vm2-vif转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212741.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif收到vlan 10的数据包转发到vm2-vif，vm2-vif处理后以原始vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212843.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=11</li>\n<li>vm1-vif收到vlan 11的数据包没有转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213027.png\" alt></li>\n</ul>\n<h4 id=\"native-vlan和trunks不重合\"><a href=\"#native-vlan和trunks不重合\" class=\"headerlink\" title=\"native vlan和trunks不重合\"></a>native vlan和trunks不重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213656.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后带vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213800.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213923.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1 发出带vlan 10的数据包，vm1-vif处理后带着原始vlan进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214019.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的数据包，vm1-vif处理后带着原始vlan进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214125.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1 发出带vlan 12的数据包，vm1-vif处理不在允许之列丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214218.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1设置trunk模式，trunks=[]</li>\n<li>vm1收到不带vlan的数据包，没有向vm2-vif转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214451.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>vm1设置access模式，tag=10</li>\n<li>vm1-vif 收到带vlan 10的数据包，转发到vm2-vif，vm2-vif以原始vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214701.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>vm1设置access模式，tag=11</li>\n<li>vm1-vif收到带vlan 11的数据包，转发到vm2-vif，vm2-vif以原始vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214834.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1设置access模式，tag=12</li>\n<li>vm1-vif收到带vlan 12的数据包，没有转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214945.png\" alt></li>\n</ul>\n<h3 id=\"native-untagged模式\"><a href=\"#native-untagged模式\" class=\"headerlink\" title=\"native-untagged模式\"></a>native-untagged模式</h3><p>native vlan即tag列<br>收包：收包不带vlan，则打上native vlan进入，收包带vlan且在允许之列，则进入<br>发包：发包和native vlan相同，则去掉vlan转发，否则带着原始vlan转发</p>\n<h4 id=\"native-vlan和trunks重合-1\"><a href=\"#native-vlan和trunks重合-1\" class=\"headerlink\" title=\"native vlan和trunks重合\"></a>native vlan和trunks重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215316.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后带vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215402.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215454.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1 发出带vlan 10的数据包，vm1-vif处理后带原始vlan 进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215625.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的数据包，vm1-vif处理后不在允许之列，丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215748.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>设置vm1-vif trunk模式，trunks=[]</li>\n<li>vm1-vif收到不带vlan的数据包后不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220011.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif收到带vlan 10的数据包转发到vm2-vif,vm2-vif处理后去掉vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220151.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=11</li>\n<li>vm1-vif收到带vlan 11的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220356.png\" alt></li>\n</ul>\n<h4 id=\"native-vlan和trunks不重合-1\"><a href=\"#native-vlan和trunks不重合-1\" class=\"headerlink\" title=\"native vlan和trunks不重合\"></a>native vlan和trunks不重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220442.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后打上vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220628.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后打上vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220741.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1发出带vlan 10的数据包，vm1-vif处理后带着原始vlan 进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220829.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1发出带vlan 11的数据包，vm1-vif处理后带着原始vlan 进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220933.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1发出带vlan 11的数据包，vm1-vif处理后不在允许范围内丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221021.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif设置trunk模式 trunks=0</li>\n<li>vm1-vif收到不带vlan的数据包，不会向vm2-vif转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221252.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>vm1-vif设置access模式 tag=10</li>\n<li>vm1-vif收到带vlan 10的数据包转发到vm2-vif，vm2-vif处理后带着原始vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221436.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>vm1-vif设置access模式 tag=11</li>\n<li>vm1-vif收到带vlan 11的数据包转发到vm2-vif，vm2-vif处理后去掉vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221610.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1-vif设置access模式 tag=12</li>\n<li>vm1-vif收到带vlan 12的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221726.png\" alt></li>\n</ul>\n<p><strong>参考：</strong><br>思维导插件<code>npm install hexo-simple-mindmap</code><br>ovs-tcpdump <code>https://docs.openvswitch.org/en/latest/ref/ovs-tcpdump.8/</code></p>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"知乎专栏","url":"https://zhuanlan.zhihu.com/godweiyang","title":"访问主页","introduction":"算法码上来","avatar":"/medias/avatars/myzhihu.png"}]}},"excerpt":"","more":"<h2 id=\"vlan-模式\"><a href=\"#vlan-模式\" class=\"headerlink\" title=\"vlan 模式\"></a>vlan 模式</h2><p>access、trunk、native-tagged、native-untagged</p>\n<h3 id=\"收发包行为\"><a href=\"#收发包行为\" class=\"headerlink\" title=\"收发包行为\"></a>收发包行为</h3><p>vlanid为0和没有vlan tag一样的处理。<br>native-tagged端口和native-untagged端口的native vlan即为port的tag值</p>\n  <blockquote class=\"pullquote mindmap mindmap-md\"><ul>\n<li>OVS vlan属性收发包<ul>\n<li>access<ul>\n<li>收<ul>\n<li>没有vlan tag，接收，并打上端口vlan(tag=0不生效)</li>\n<li>有vlan tag且vlanid非0，丢弃</li>\n</ul>\n</li>\n<li>发<ul>\n<li>发出去的报文不带vlan</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>trunk<ul>\n<li>收<ul>\n<li>trunk为空收：<ul>\n<li>报文带vlan，允许进入</li>\n<li>报文不带vlan，允许进入</li>\n</ul>\n</li>\n<li>trunk不为空收<ul>\n<li>报文带vlan tag，vlan id是否在允许之列，收</li>\n<li>报文不带vlan tag，丢弃</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>发<ul>\n<li>带着原始vlan发出</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>native-tagged<ul>\n<li>收<ul>\n<li>报文带vlan tag，vlan id是否在允许之列，收</li>\n<li>报文不带vlan tag，接收，并打上端口的native vlan</li>\n</ul>\n</li>\n<li>发<ul>\n<li>带着原始vlan发出</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>native-untagged<ul>\n<li>收<ul>\n<li>报文带vlan tag，vlan id是否在允许之列，收</li>\n<li>报文不带vlan tag，接收，并打上端口的native vlan</li>\n</ul>\n</li>\n<li>发<ul>\n<li>vid == native vlan，不带vlan，发出</li>\n<li>vid != native vlan，带原始vlan发出</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n\n<p>当端口vlan_mode为native-tagged或native-untagged时，native vlan也在其对应的广播域中</p>\n<h2 id=\"实验过程\"><a href=\"#实验过程\" class=\"headerlink\" title=\"实验过程\"></a>实验过程</h2><h3 id=\"创建两个vm\"><a href=\"#创建两个vm\" class=\"headerlink\" title=\"创建两个vm\"></a>创建两个vm</h3><pre><code>ip netns add vm1\nip link add vm1-vif type veth peer name vm1\nip link set vm1 netns vm1\nip netns exec vm1 ip link set vm1 address 00:00:00:00:00:03\nip netns exec vm1 ip addr add 10.10.10.2/24 dev vm1\nip netns exec vm1 ip link set vm1 up\nip link set vm1-vif up\n\nip netns add vm2\nip link add vm2-vif type veth peer name vm2\nip link set vm2 netns vm2\nip netns exec vm2 ip link set vm2 address 00:00:00:00:00:04\nip netns exec vm2 ip addr add 10.10.10.3/24 dev vm2\nip netns exec vm2 ip link set vm2 up\nip link set vm2-vif up</code></pre><h3 id=\"连接vm网卡和网桥\"><a href=\"#连接vm网卡和网桥\" class=\"headerlink\" title=\"连接vm网卡和网桥\"></a>连接vm网卡和网桥</h3><pre><code>ovs-vsctl add-br -br-int\novs-vsctl add-port br-int vm1-vif\novs-vsctl add-port br-int vm2-vif</code></pre><p>效果如图<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220705225523.png\" alt></p>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><h4 id=\"抓包工具\"><a href=\"#抓包工具\" class=\"headerlink\" title=\"抓包工具\"></a>抓包工具</h4><p>tcpdump和ovs-tcpdump工具可以抓到一路上OVS对vlan的处理。</p>\n<p>如果使用ovs-tcpdump，ovs-tcpdump在守护程序中创建交换机镜像端口，并执行以侦听这些端口。当实例退出时，它会清理它创建的镜像端口。</p>\n<p>如果用系统tcpdump抓包，抓的是经过vm网卡veth pair的流量。</p>\n<p>抓包点如下</p>\n<pre><code>vm1-eth0-(tcpdump)vm1-vif(ovs-tcpdump)-OVS Bridge-vm2-vif-vm2-eth0</code></pre><h3 id=\"access模式\"><a href=\"#access模式\" class=\"headerlink\" title=\"access模式\"></a>access模式</h3><p>收包：收包不带vlan/vlan为0，则打上tag，带vlan，则丢弃<br>发包：只会发vlan为端口vlan的包，发包不带vlan</p>\n<h4 id=\"tag-0\"><a href=\"#tag-0\" class=\"headerlink\" title=\"tag=0\"></a>tag=0</h4><p>tag=0时不生效，抓到的包并没有打上vlanid为0的tag(处理收包时也类似，vlan_id为0则表示当作没有vlan处理)</p>\n<pre><code>ovs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=0\novs-vsctl set Port vm2-vif tag=0</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220707221449.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的包，vm1-vif port access tag=0处理后还是不带vlan<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220707222722.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220707222806.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan0的包, vm1-vif处理后不带vlan<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711222809.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的包，vm1-vif port access tag=0处理后丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711222511.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711222607.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm2-vif通过不带vlan的包，以不带vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220711223215.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式tag为11，，vm2-vif access模式保持tag=0</li>\n<li>带vlan 11的数据包不会被转发到vm2-vif口<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713200925.png\" alt></li>\n</ul>\n<h4 id=\"tag-0-1\"><a href=\"#tag-0-1\" class=\"headerlink\" title=\"tag!=0\"></a>tag!=0</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=access\novs-vsctl set Port vm2-vif vlan_mode=access\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif tag=10</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220707222905.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的包，vm1-vif port access tag=10处理后，带上vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220707223104.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong><br>设置linux 子接口</p>\n<pre><code>ip netns exec vm1 vconfig add vm1 0\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.0 10.10.10.2</code></pre><ul>\n<li>vm1 发出vlan 0的数据包，vm1-vif port access 处理后，带上vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710224012.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710224207.png\" alt></li>\n</ul>\n<p><strong>收包带vlan 10</strong><br>设置linux 子接口</p>\n<pre><code>ip netns exec vm1 vconfig add vm1 10\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.10 10.10.10.2</code></pre><ul>\n<li>vm1发出带vlan 10的包，vm1-vif port access 处理后，被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710223431.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710223519.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan11</strong></p>\n<pre><code>ip netns exec vm1 vconfig add vm1 11\nip netns exec vm1 ifconfig vm1 0.0.0.0\nip netns exec vm1 ifconfig vm1.11 10.10.10.2</code></pre><ul>\n<li>vm1发出带vlan 11的数据包，vm1-vif port处理后，被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713201315.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif设置trunk模式且trunks为空，vm2-vif设置access模式tag=10，vm1-vif接收不带vlan的包后没有被转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713201940.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>vm1-vif设置access模式tag=10，vm2-vif设置access模式tag=10</li>\n<li>vm1-vif port将vlan 10的数据包转发到vm2-vif，vm2-vif处理后以不带vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713203016.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>vm1-vif设置access模式tag=11， vm2-vif设置access模式tag=10</li>\n<li>vm1-vif port收到vlan 11的数据包后没有转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713203212.png\" alt></li>\n</ul>\n<h3 id=\"trunk模式\"><a href=\"#trunk模式\" class=\"headerlink\" title=\"trunk模式\"></a>trunk模式</h3><p>trunks为空<br>收包：收包不带vlan或者带vlan或者vlanid为0(进入后不带vlan)，允许进入<br>发包：带着原始vlan转发<br>trunks不为空<br>收包：带vlan且在vlan_range中，才允许进入<br>发包：在vlan_range中，会带着原始vlan转发</p>\n<h5 id=\"trunks为空\"><a href=\"#trunks为空\" class=\"headerlink\" title=\"trunks为空\"></a>trunks为空</h5><p>在不配置vlan时，ovs port默认是trunk all的，可以抓包看到对应的数据包没有带vlan，也都被允许通过了。</p>\n<pre><code>ovs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm2-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[]\novs-vsctl set Port vm2-vif trunks=[]</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213515.png\" alt></p>\n<p><strong>收到不带vlan的包</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后继续不带vlan<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713203933.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 0的包</strong></p>\n<ul>\n<li>vm1 发出带vlan 0的包，vm1-vif处理后不带vlan，且允许通过。<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710225805.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710225731.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 10的包</strong></p>\n<ul>\n<li>vm1发出带vlan 10的包，vm1-vif 处理后带着原vlan转发，<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710230349.png\" alt><br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713204049.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif转发不带vlan的包到vm2-vif</li>\n<li>vm2-vif继续以不带vlan转发vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713204432.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif 为access模式tag=10</li>\n<li>vm1-vif收到vlan 10的数据包转发到vm2-vif， vm2-vif以原vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713204647.png\" alt></li>\n</ul>\n<h5 id=\"trunks不为空\"><a href=\"#trunks不为空\" class=\"headerlink\" title=\"trunks不为空\"></a>trunks不为空</h5><p>在配置vlan后，ovs port只能收在trunk范围的包</p>\n<pre><code>ovs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif vlan_mode=trunk\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm2-vif trunks=[10]</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213553.png\" alt></p>\n<p><strong>收到不带vlan的包</strong></p>\n<ul>\n<li>vm1 发出不带vlan的包，vm1-vif处理后，被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231215.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 0的包</strong></p>\n<ul>\n<li>vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231542.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 10的包</strong></p>\n<ul>\n<li>vm1 发出带vlan10的包，vm1-vif处理后允许通过，vm2-vif允许通过，vm2收到带vlan10的包后丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231015.png\" alt></li>\n</ul>\n<p><strong>收到带vlan 11的包</strong></p>\n<ul>\n<li>vm1 发出带vlan 0的包，vm1-vif处理后不在允许范围内被丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220710231738.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>设置vm1-vif trunk模式，trunks=[]</li>\n<li>vm1-vif处理不带vlan的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713205845.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif处理vlan 10的数据包转发到vm2-vif，vm2-vif以vlan 10转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713210045.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif处理vlan 11的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713210138.png\" alt></li>\n</ul>\n<h3 id=\"native-tagged模式\"><a href=\"#native-tagged模式\" class=\"headerlink\" title=\"native-tagged模式\"></a>native-tagged模式</h3><p>native-vlan设置即tag列<br>收包：报文不带vlan，则打上native vlan进入，报文带vlan且在允许之列，则进入<br>发包：带着原始vlan发出</p>\n<h4 id=\"native-vlan和trunks重合\"><a href=\"#native-vlan和trunks重合\" class=\"headerlink\" title=\"native vlan和trunks重合\"></a>native vlan和trunks重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213626.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后带上native vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713211909.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后带上native vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212047.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1发出带vlan 10的数据包，vm1-vif允许带着原始vlan进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212213.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的数据包，不在允许之列，vm1-vif丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212418.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif设置trunk模式，trunks=[]</li>\n<li>vm1-vif收到不带vlan的数据包后没有向vm2-vif转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212741.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif收到vlan 10的数据包转发到vm2-vif，vm2-vif处理后以原始vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713212843.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=11</li>\n<li>vm1-vif收到vlan 11的数据包没有转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213027.png\" alt></li>\n</ul>\n<h4 id=\"native-vlan和trunks不重合\"><a href=\"#native-vlan和trunks不重合\" class=\"headerlink\" title=\"native vlan和trunks不重合\"></a>native vlan和trunks不重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-tagged\novs-vsctl set Port vm2-vif vlan_mode=native-tagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213656.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后带vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213800.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713213923.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1 发出带vlan 10的数据包，vm1-vif处理后带着原始vlan进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214019.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的数据包，vm1-vif处理后带着原始vlan进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214125.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1 发出带vlan 12的数据包，vm1-vif处理不在允许之列丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214218.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1设置trunk模式，trunks=[]</li>\n<li>vm1收到不带vlan的数据包，没有向vm2-vif转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214451.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>vm1设置access模式，tag=10</li>\n<li>vm1-vif 收到带vlan 10的数据包，转发到vm2-vif，vm2-vif以原始vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214701.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>vm1设置access模式，tag=11</li>\n<li>vm1-vif收到带vlan 11的数据包，转发到vm2-vif，vm2-vif以原始vlan转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214834.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1设置access模式，tag=12</li>\n<li>vm1-vif收到带vlan 12的数据包，没有转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713214945.png\" alt></li>\n</ul>\n<h3 id=\"native-untagged模式\"><a href=\"#native-untagged模式\" class=\"headerlink\" title=\"native-untagged模式\"></a>native-untagged模式</h3><p>native vlan即tag列<br>收包：收包不带vlan，则打上native vlan进入，收包带vlan且在允许之列，则进入<br>发包：发包和native vlan相同，则去掉vlan转发，否则带着原始vlan转发</p>\n<h4 id=\"native-vlan和trunks重合-1\"><a href=\"#native-vlan和trunks重合-1\" class=\"headerlink\" title=\"native vlan和trunks重合\"></a>native vlan和trunks重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=10\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=10</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215316.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后带vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215402.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后带vlan 10<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215454.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1 发出带vlan 10的数据包，vm1-vif处理后带原始vlan 进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215625.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1 发出带vlan 11的数据包，vm1-vif处理后不在允许之列，丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713215748.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>设置vm1-vif trunk模式，trunks=[]</li>\n<li>vm1-vif收到不带vlan的数据包后不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220011.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=10</li>\n<li>vm1-vif收到带vlan 10的数据包转发到vm2-vif,vm2-vif处理后去掉vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220151.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>设置vm1-vif access模式，tag=11</li>\n<li>vm1-vif收到带vlan 11的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220356.png\" alt></li>\n</ul>\n<h4 id=\"native-vlan和trunks不重合-1\"><a href=\"#native-vlan和trunks不重合-1\" class=\"headerlink\" title=\"native vlan和trunks不重合\"></a>native vlan和trunks不重合</h4><pre><code>ovs-vsctl set Port vm1-vif vlan_mode=native-untagged\novs-vsctl set Port vm2-vif vlan_mode=native-untagged\novs-vsctl set Port vm1-vif trunks=[10]\novs-vsctl set Port vm1-vif tag=11\novs-vsctl set Port vm2-vif trunks=[10]\novs-vsctl set Port vm2-vif tag=11</code></pre><p><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220442.png\" alt></p>\n<p><strong>收包 不带vlan</strong></p>\n<ul>\n<li>vm1发出不带vlan的数据包，vm1-vif处理后打上vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220628.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 0</strong></p>\n<ul>\n<li>vm1发出带vlan 0的数据包，vm1-vif处理后打上vlan 11<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220741.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 10</strong></p>\n<ul>\n<li>vm1发出带vlan 10的数据包，vm1-vif处理后带着原始vlan 进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220829.png\" alt></li>\n</ul>\n<p><strong>收包 带vlan 11</strong></p>\n<ul>\n<li>vm1发出带vlan 11的数据包，vm1-vif处理后带着原始vlan 进入<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713220933.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1发出带vlan 11的数据包，vm1-vif处理后不在允许范围内丢弃<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221021.png\" alt></li>\n</ul>\n<p><strong>发包 不带vlan</strong></p>\n<ul>\n<li>vm1-vif设置trunk模式 trunks=0</li>\n<li>vm1-vif收到不带vlan的数据包，不会向vm2-vif转发<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221252.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 0</strong><br>带vlan 0的数据包无法进入</p>\n<p><strong>发包 带vlan 10</strong></p>\n<ul>\n<li>vm1-vif设置access模式 tag=10</li>\n<li>vm1-vif收到带vlan 10的数据包转发到vm2-vif，vm2-vif处理后带着原始vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221436.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 11</strong></p>\n<ul>\n<li>vm1-vif设置access模式 tag=11</li>\n<li>vm1-vif收到带vlan 11的数据包转发到vm2-vif，vm2-vif处理后去掉vlan转发到vm2<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221610.png\" alt></li>\n</ul>\n<p><strong>发包 带vlan 12</strong></p>\n<ul>\n<li>vm1-vif设置access模式 tag=12</li>\n<li>vm1-vif收到带vlan 12的数据包不会转发到vm2-vif<br><img src=\"/2022/07/05/ovs-port-vlan/img-20220713221726.png\" alt></li>\n</ul>\n<p><strong>参考：</strong><br>思维导插件<code>npm install hexo-simple-mindmap</code><br>ovs-tcpdump <code>https://docs.openvswitch.org/en/latest/ref/ovs-tcpdump.8/</code></p>\n"}],"PostAsset":[{"_id":"source/_posts/kafka-producer-consumer/img-20221016191323.png","slug":"img-20221016191323.png","post":"clg8yre9h000cagvtstpma2s5","modified":1,"renderable":0},{"_id":"source/_posts/kafka-producer-consumer/img-20221030190716.png","slug":"img-20221030190716.png","post":"clg8yre9h000cagvtstpma2s5","modified":1,"renderable":0},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030211753.png","slug":"img-20221030211753.png","post":"clg8yre9x000fagvtqfxgev52","modified":1,"renderable":0},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030211824.png","slug":"img-20221030211824.png","post":"clg8yre9x000fagvtqfxgev52","modified":1,"renderable":0},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222348.png","slug":"img-20221106222348.png","post":"clg8yre9x000fagvtqfxgev52","modified":1,"renderable":0},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222536.png","slug":"img-20221106222536.png","post":"clg8yre9x000fagvtqfxgev52","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220710225805.png","slug":"img-20220710225805.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220710230349.png","slug":"img-20220710230349.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220711222511.png","slug":"img-20220711222511.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713200925.png","slug":"img-20220713200925.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713203933.png","slug":"img-20220713203933.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713205845.png","slug":"img-20220713205845.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713212741.png","slug":"img-20220713212741.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713220011.png","slug":"img-20220713220011.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/kafka-producer-consumer/img-20221030200350.png","slug":"img-20221030200350.png","post":"clg8yre9h000cagvtstpma2s5","modified":1,"renderable":0},{"_id":"source/_posts/kafka-producer-consumer/img-20221030193459.png","slug":"img-20221030193459.png","post":"clg8yre9h000cagvtstpma2s5","modified":1,"renderable":0},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222237.png","slug":"img-20221106222237.png","post":"clg8yre9x000fagvtqfxgev52","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220710225731.png","slug":"img-20220710225731.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220710231015.png","slug":"img-20220710231015.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713201315.png","slug":"img-20220713201315.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713203212.png","slug":"img-20220713203212.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713210138.png","slug":"img-20220713210138.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713211909.png","slug":"img-20220713211909.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713212414.png","slug":"img-20220713212414.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713212418.png","slug":"img-20220713212418.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713213027.png","slug":"img-20220713213027.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713214218.png","slug":"img-20220713214218.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713214451.png","slug":"img-20220713214451.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713214945.png","slug":"img-20220713214945.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713215748.png","slug":"img-20220713215748.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713220356.png","slug":"img-20220713220356.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713221021.png","slug":"img-20220713221021.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713221726.png","slug":"img-20220713221726.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220710231738.png","slug":"img-20220710231738.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220711222809.png","slug":"img-20220711222809.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713212047.png","slug":"img-20220713212047.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713212213.png","slug":"img-20220713212213.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713213800.png","slug":"img-20220713213800.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713214125.png","slug":"img-20220713214125.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/win11_wsl/img-20220625215308.png","post":"clg8yre9x000kagvtebzgef0d","slug":"img-20220625215308.png","modified":1,"renderable":1},{"_id":"source/_posts/win11_wsl/img-20220625215633.png","post":"clg8yre9x000kagvtebzgef0d","slug":"img-20220625215633.png","modified":1,"renderable":1},{"_id":"source/_posts/win11_wsl/img-20220625220014.png","post":"clg8yre9x000kagvtebzgef0d","slug":"img-20220625220014.png","modified":1,"renderable":1},{"_id":"source/_posts/win11_wsl/img-20220625220129.png","post":"clg8yre9x000kagvtebzgef0d","slug":"img-20220625220129.png","modified":1,"renderable":1},{"_id":"source/_posts/win11_wsl/img-20220625221705.png","post":"clg8yre9x000kagvtebzgef0d","slug":"img-20220625221705.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-producer-consumer/img-20221030201350.png","post":"clg8yre9h000cagvtstpma2s5","slug":"img-20221030201350.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-producer-consumer/img-20221030202942.png","slug":"img-20221030202942.png","post":"clg8yre9h000cagvtstpma2s5","modified":1,"renderable":0},{"_id":"source/_posts/kafka-producer-consumer/img-20221030202957.png","slug":"img-20221030202957.png","post":"clg8yre9h000cagvtstpma2s5","modified":1,"renderable":0},{"_id":"source/_posts/kafka-producer-consumer/producer-structure.jpg","post":"clg8yre9h000cagvtstpma2s5","slug":"producer-structure.jpg","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713215625.png","slug":"img-20220713215625.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030211533.png","post":"clg8yre9x000fagvtqfxgev52","slug":"img-20221030211533.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-topic-and-partition/img-20221030212257.png","post":"clg8yre9x000fagvtqfxgev52","slug":"img-20221030212257.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222301.png","slug":"img-20221106222301.png","post":"clg8yre9x000fagvtqfxgev52","modified":1,"renderable":0},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222336.png","post":"clg8yre9x000fagvtqfxgev52","slug":"img-20221106222336.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106222544.png","post":"clg8yre9x000fagvtqfxgev52","slug":"img-20221106222544.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106223639.png","post":"clg8yre9x000fagvtqfxgev52","slug":"img-20221106223639.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106230140.png","post":"clg8yre9x000fagvtqfxgev52","slug":"img-20221106230140.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka-topic-and-partition/img-20221106230222.png","post":"clg8yre9x000fagvtqfxgev52","slug":"img-20221106230222.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713220741.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713220741.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713220933.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713220933.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713220829.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713220829.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713221252.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713221252.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713210045.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713210045.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713214019.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713214019.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220705225523.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220705225523.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220706221734.png","slug":"img-20220706221734.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220707221449.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220707221449.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220707222722.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220707222722.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220707222806.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220707222806.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220707222905.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220707222905.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220707223104.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220707223104.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220710223431.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220710223431.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220710223519.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220710223519.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220710224012.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220710224012.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220710224207.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220710224207.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220710231215.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220710231215.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220710231542.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220710231542.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220711222607.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220711222607.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220711223215.png","slug":"img-20220711223215.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713201940.png","slug":"img-20220713201940.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713203016.png","slug":"img-20220713203016.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713204049.png","slug":"img-20220713204049.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713204432.png","slug":"img-20220713204432.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713204647.png","slug":"img-20220713204647.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713212843.png","slug":"img-20220713212843.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713213515.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713213515.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713213553.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713213553.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713213626.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713213626.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713213656.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713213656.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713213923.png","slug":"img-20220713213923.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713214701.png","slug":"img-20220713214701.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713214834.png","slug":"img-20220713214834.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713215316.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713215316.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713215402.png","slug":"img-20220713215402.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713215454.png","slug":"img-20220713215454.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713220151.png","slug":"img-20220713220151.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713220442.png","post":"clg8yre9x000magvtw1nlgy8p","slug":"img-20220713220442.png","modified":1,"renderable":1},{"_id":"source/_posts/ovs-port-vlan/img-20220713220628.png","slug":"img-20220713220628.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713221436.png","slug":"img-20220713221436.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0},{"_id":"source/_posts/ovs-port-vlan/img-20220713221610.png","slug":"img-20220713221610.png","post":"clg8yre9x000magvtw1nlgy8p","modified":1,"renderable":0}],"PostCategory":[{"post_id":"clg8yre9h000aagvtaxknxyi2","category_id":"clg8yre9h0005agvtyeznptzk","_id":"clg8yre9x000hagvtt3bb8i2w"},{"post_id":"clg8yre9h000cagvtstpma2s5","category_id":"clg8yre9h0005agvtyeznptzk","_id":"clg8yre9x000lagvt88xzdc58"},{"post_id":"clg8yre9x000fagvtqfxgev52","category_id":"clg8yre9h0005agvtyeznptzk","_id":"clg8yre9x000nagvt2epeiz39"},{"post_id":"clg8yre9h0008agvtiuu84svp","category_id":"clg8yre9x000iagvt1ntrjqsl","_id":"clg8yre9x000ragvt3i1hknnf"},{"post_id":"clg8yre920002agvtfhggbhzy","category_id":"clg8yre9h0005agvtyeznptzk","_id":"clg8yre9x000xagvt3wrxloj7"},{"post_id":"clg8yre920002agvtfhggbhzy","category_id":"clg8yre9x000oagvt9y9za8fo","_id":"clg8yre9x000zagvt8hczpfaf"},{"post_id":"clg8yre9h0004agvtk8jmc69n","category_id":"clg8yre9h0005agvtyeznptzk","_id":"clg8yre9x0010agvtjz0y3w2n"},{"post_id":"clg8yre9h0004agvtk8jmc69n","category_id":"clg8yre9x000oagvt9y9za8fo","_id":"clg8yread0013agvtq0iyh5kl"},{"post_id":"clg8yre9x000gagvtu6pktrd9","category_id":"clg8yre9x000wagvt1i4objj8","_id":"clg8yread0016agvttznu0ubw"},{"post_id":"clg8yre9x000kagvtebzgef0d","category_id":"clg8yread0011agvtsathc0lj","_id":"clg8yread001bagvtfks3havt"},{"post_id":"clg8yre9x000magvtw1nlgy8p","category_id":"clg8yread0017agvtrxqmv4xx","_id":"clg8yread001eagvthiaiu4io"}],"PostTag":[{"post_id":"clg8yre920002agvtfhggbhzy","tag_id":"clg8yre9h0006agvtrkq201q4","_id":"clg8yre9x000qagvt10u6z3cw"},{"post_id":"clg8yre920002agvtfhggbhzy","tag_id":"clg8yre9x000eagvt541owyte","_id":"clg8yre9x000sagvtloto28zh"},{"post_id":"clg8yre920002agvtfhggbhzy","tag_id":"clg8yre9x000jagvtbobthuzq","_id":"clg8yre9x000vagvtra0lpf01"},{"post_id":"clg8yre9h0004agvtk8jmc69n","tag_id":"clg8yre9h0006agvtrkq201q4","_id":"clg8yread0014agvty7j54wp4"},{"post_id":"clg8yre9h0004agvtk8jmc69n","tag_id":"clg8yre9x000eagvt541owyte","_id":"clg8yread0015agvtiyue9luy"},{"post_id":"clg8yre9h0004agvtk8jmc69n","tag_id":"clg8yre9x000yagvthksdjfzi","_id":"clg8yread0019agvtk1ikkfye"},{"post_id":"clg8yre9h0008agvtiuu84svp","tag_id":"clg8yread0012agvtj815wqrm","_id":"clg8yread001aagvtuehwd4tj"},{"post_id":"clg8yre9h000aagvtaxknxyi2","tag_id":"clg8yread0018agvta5a7qdn9","_id":"clg8yread001dagvtvdoigtj9"},{"post_id":"clg8yre9h000cagvtstpma2s5","tag_id":"clg8yre9h0006agvtrkq201q4","_id":"clg8yread001gagvtvk6x2mon"},{"post_id":"clg8yre9h000cagvtstpma2s5","tag_id":"clg8yread001cagvtwmi27fi9","_id":"clg8yread001hagvtoobuo3ve"},{"post_id":"clg8yre9x000fagvtqfxgev52","tag_id":"clg8yre9h0006agvtrkq201q4","_id":"clg8yread001jagvtu21623hh"},{"post_id":"clg8yre9x000fagvtqfxgev52","tag_id":"clg8yread001cagvtwmi27fi9","_id":"clg8yread001kagvttef2oxcr"},{"post_id":"clg8yre9x000gagvtu6pktrd9","tag_id":"clg8yread001iagvtds9jcjda","_id":"clg8yread001nagvtgokyccnl"},{"post_id":"clg8yre9x000gagvtu6pktrd9","tag_id":"clg8yread001lagvtcgxn1c2z","_id":"clg8yread001oagvtmg5gvpjx"},{"post_id":"clg8yre9x000kagvtebzgef0d","tag_id":"clg8yread001magvt5db8kakv","_id":"clg8yread001qagvt31utrvk0"},{"post_id":"clg8yre9x000magvtw1nlgy8p","tag_id":"clg8yread001pagvtdh1o0gkw","_id":"clg8yreb4001uagvt98568mqt"},{"post_id":"clg8yre9x000magvtw1nlgy8p","tag_id":"clg8yread001ragvte8zz1f3f","_id":"clg8yreb4001vagvteon7yb99"},{"post_id":"clg8yre9x000magvtw1nlgy8p","tag_id":"clg8yreas001sagvtpr0vhwww","_id":"clg8yreb8001wagvt0c3h78nt"},{"post_id":"clg8yre9x000magvtw1nlgy8p","tag_id":"clg8yreas001tagvthza22mwb","_id":"clg8yreb8001xagvtf3srcfm8"}],"Tag":[{"name":"博客","_id":"clg8yre9h0006agvtrkq201q4"},{"name":"算法","_id":"clg8yre9x000eagvt541owyte"},{"name":"动态规划","_id":"clg8yre9x000jagvtbobthuzq"},{"name":"链表","_id":"clg8yre9x000yagvthksdjfzi"},{"name":"Go","_id":"clg8yread0012agvtj815wqrm"},{"name":"Hexo","_id":"clg8yread0018agvta5a7qdn9"},{"name":"Kafka","_id":"clg8yread001cagvtwmi27fi9"},{"name":"OVN","_id":"clg8yread001iagvtds9jcjda"},{"name":"LS","_id":"clg8yread001lagvtcgxn1c2z"},{"name":"WSL","_id":"clg8yread001magvt5db8kakv"},{"name":"OVS","_id":"clg8yread001pagvtdh1o0gkw"},{"name":"VLAN","_id":"clg8yread001ragvte8zz1f3f"},{"name":"ACCESS","_id":"clg8yreas001sagvtpr0vhwww"},{"name":"TRUNK","_id":"clg8yreas001tagvthza22mwb"}]}}